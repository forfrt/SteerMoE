!_TAG_FILE_FORMAT	2	/extended format; --format=1 will not append ;" to lines/
!_TAG_FILE_SORTED	1	/0=unsorted, 1=sorted, 2=foldcase/
!_TAG_OUTPUT_EXCMD	mixed	/number, pattern, mixed, or combineV2/
!_TAG_OUTPUT_FILESEP	slash	/slash or backslash/
!_TAG_OUTPUT_MODE	u-ctags	/u-ctags or e-ctags/
!_TAG_PATTERN_LENGTH_LIMIT	96	/0 for no limit/
!_TAG_PROC_CWD	/mnt/f/Job/SteerMoE/	//
!_TAG_PROGRAM_AUTHOR	Universal Ctags Team	//
!_TAG_PROGRAM_NAME	Universal Ctags	/Derived from Exuberant Ctags/
!_TAG_PROGRAM_URL	https://ctags.io/	/official site/
!_TAG_PROGRAM_VERSION	5.9.0	/b5cd9f4e/
**Current Implementation (Post-encoder):**	analysis_layer_wise_vs_post_encoder.md	/^### **Current Implementation (Post-encoder):**$/;"	S	section:Analysis: Layer-wise Steering vs Post-encoder Steering""2. Layer-wise Steering vs Post-encoder Steering
**Discrete Tokens Benefits:**	analysis_layer_wise_vs_post_encoder.md	/^### **Discrete Tokens Benefits:**$/;"	S	section:Analysis: Layer-wise Steering vs Post-encoder Steering""1. Kimi-Audio "Adapter" Analysis
**Layer-wise Steering (New):**	analysis_layer_wise_vs_post_encoder.md	/^### **Layer-wise Steering (New):**$/;"	S	section:Analysis: Layer-wise Steering vs Post-encoder Steering""8. Code Implementation
**Phase 1: Baseline Comparison**	analysis_layer_wise_vs_post_encoder.md	/^### **Phase 1: Baseline Comparison**$/;"	S	section:Analysis: Layer-wise Steering vs Post-encoder Steering""9. Experimental Design
**Phase 2: Layer Analysis**	analysis_layer_wise_vs_post_encoder.md	/^### **Phase 2: Layer Analysis**$/;"	S	section:Analysis: Layer-wise Steering vs Post-encoder Steering""9. Experimental Design
**Phase 3: Ablation Studies**	analysis_layer_wise_vs_post_encoder.md	/^### **Phase 3: Ablation Studies**$/;"	S	section:Analysis: Layer-wise Steering vs Post-encoder Steering""9. Experimental Design
**Post-encoder Steering (Current):**	analysis_layer_wise_vs_post_encoder.md	/^### **Post-encoder Steering (Current):**$/;"	S	section:Analysis: Layer-wise Steering vs Post-encoder Steering""8. Code Implementation
**Recommended Approach:**	analysis_layer_wise_vs_post_encoder.md	/^### **Recommended Approach:**$/;"	S	section:Analysis: Layer-wise Steering vs Post-encoder Steering""7. Implementation Strategy
**When Layer-wise Steering Would Perform Better:**	analysis_layer_wise_vs_post_encoder.md	/^### **When Layer-wise Steering Would Perform Better:**$/;"	S	section:Analysis: Layer-wise Steering vs Post-encoder Steering""6. Performance Predictions
**When Post-encoder Steering Would Perform Better:**	analysis_layer_wise_vs_post_encoder.md	/^### **When Post-encoder Steering Would Perform Better:**$/;"	S	section:Analysis: Layer-wise Steering vs Post-encoder Steering""6. Performance Predictions
**Your Proposed Implementation (Layer-wise):**	analysis_layer_wise_vs_post_encoder.md	/^### **Your Proposed Implementation (Layer-wise):**$/;"	S	section:Analysis: Layer-wise Steering vs Post-encoder Steering""2. Layer-wise Steering vs Post-encoder Steering
**a) Computational Cost:**	analysis_layer_wise_vs_post_encoder.md	/^### **a) Computational Cost:**$/;"	S	section:Analysis: Layer-wise Steering vs Post-encoder Steering""5. Theoretical Disadvantages
**a) Fine-grained Adaptation:**	analysis_layer_wise_vs_post_encoder.md	/^### **a) Fine-grained Adaptation:**$/;"	S	section:Analysis: Layer-wise Steering vs Post-encoder Steering""4. Theoretical Advantages of Layer-wise Steering
**b) Interpretability:**	analysis_layer_wise_vs_post_encoder.md	/^### **b) Interpretability:**$/;"	S	section:Analysis: Layer-wise Steering vs Post-encoder Steering""4. Theoretical Advantages of Layer-wise Steering
**b) Training Complexity:**	analysis_layer_wise_vs_post_encoder.md	/^### **b) Training Complexity:**$/;"	S	section:Analysis: Layer-wise Steering vs Post-encoder Steering""5. Theoretical Disadvantages
**c) Adaptive Processing:**	analysis_layer_wise_vs_post_encoder.md	/^### **c) Adaptive Processing:**$/;"	S	section:Analysis: Layer-wise Steering vs Post-encoder Steering""4. Theoretical Advantages of Layer-wise Steering
**c) Implementation Complexity:**	analysis_layer_wise_vs_post_encoder.md	/^### **c) Implementation Complexity:**$/;"	S	section:Analysis: Layer-wise Steering vs Post-encoder Steering""5. Theoretical Disadvantages
1. EfficientLayerWiseSteeringWhisperEncoder	steer_moe/implementation_summary.md	/^### 1. EfficientLayerWiseSteeringWhisperEncoder$/;"	S	section:SteerMoE Current Implementation Summary""Architecture Components
1. EfficientLayerWiseSteeringWhisperEncoder (`efficient_layer_wise_whisper.py`)	steer_moe/current_implementation_analysis.md	/^### 1. EfficientLayerWiseSteeringWhisperEncoder (`efficient_layer_wise_whisper.py`)$/;"	S	section:Current SteerMoE Implementation Analysis""Component Analysis
1. Feature Space Alignment	cross_modal_steer/router_analysis_and_cross_modal_steering.md	/^#### 1. Feature Space Alignment$/;"	t	subsection:Router Implementation Analysis and Cross-Modal Steering Analysis""2. Cross-Modal Attention Steering Analysis""Better Cross-Modal Steering Approaches
1. Kimi-Audio "Adapter" Analysis	analysis_layer_wise_vs_post_encoder.md	/^## 1. Kimi-Audio "Adapter" Analysis$/;"	s	chapter:Analysis: Layer-wise Steering vs Post-encoder Steering
1. Original SteerMoE Model	README.md	/^### 1. Original SteerMoE Model$/;"	S	section:SteerMoE""Model Variants
1. Router Implementation Comparison	cross_modal_steer/router_analysis_and_cross_modal_steering.md	/^## 1. Router Implementation Comparison$/;"	s	chapter:Router Implementation Analysis and Cross-Modal Steering Analysis
1. Single Router Efficiency	steer_moe/current_implementation_analysis.md	/^### 1. Single Router Efficiency$/;"	S	section:Current SteerMoE Implementation Analysis""Key Features
1. Steering Analysis Callback	steer_moe/implementation_summary.md	/^### 1. Steering Analysis Callback$/;"	S	section:SteerMoE Current Implementation Summary""Training Features
10. Conclusion	analysis_layer_wise_vs_post_encoder.md	/^## 10. Conclusion$/;"	s	chapter:Analysis: Layer-wise Steering vs Post-encoder Steering
2. Cross-Modal Attention Steering Analysis	cross_modal_steer/router_analysis_and_cross_modal_steering.md	/^## 2. Cross-Modal Attention Steering Analysis$/;"	s	chapter:Router Implementation Analysis and Cross-Modal Steering Analysis
2. Gradient Clipping Callback	steer_moe/implementation_summary.md	/^### 2. Gradient Clipping Callback$/;"	S	section:SteerMoE Current Implementation Summary""Training Features
2. Layer-wise Steering	steer_moe/current_implementation_analysis.md	/^### 2. Layer-wise Steering$/;"	S	section:Current SteerMoE Implementation Analysis""Key Features
2. Layer-wise Steering vs Post-encoder Steering	analysis_layer_wise_vs_post_encoder.md	/^## 2. Layer-wise Steering vs Post-encoder Steering$/;"	s	chapter:Analysis: Layer-wise Steering vs Post-encoder Steering
2. Modality-Specific Steering with Fusion	cross_modal_steer/router_analysis_and_cross_modal_steering.md	/^#### 2. Modality-Specific Steering with Fusion$/;"	t	subsection:Router Implementation Analysis and Cross-Modal Steering Analysis""2. Cross-Modal Attention Steering Analysis""Better Cross-Modal Steering Approaches
2. SteerMoE Hybrid Model	README.md	/^### 2. SteerMoE Hybrid Model$/;"	S	section:SteerMoE""Model Variants
2. SteerMoEEfficientLayerWiseModel	steer_moe/implementation_summary.md	/^### 2. SteerMoEEfficientLayerWiseModel$/;"	S	section:SteerMoE Current Implementation Summary""Architecture Components
2. SteerMoEEfficientLayerWiseModel (`models.py`)	steer_moe/current_implementation_analysis.md	/^### 2. SteerMoEEfficientLayerWiseModel (`models.py`)$/;"	S	section:Current SteerMoE Implementation Analysis""Component Analysis
3. Adapter-Based Cross-Modal Alignment	cross_modal_steer/router_analysis_and_cross_modal_steering.md	/^#### 3. Adapter-Based Cross-Modal Alignment$/;"	t	subsection:Router Implementation Analysis and Cross-Modal Steering Analysis""2. Cross-Modal Attention Steering Analysis""Better Cross-Modal Steering Approaches
3. Detailed Comparison	analysis_layer_wise_vs_post_encoder.md	/^## 3. Detailed Comparison$/;"	s	chapter:Analysis: Layer-wise Steering vs Post-encoder Steering
3. Frozen Components	steer_moe/current_implementation_analysis.md	/^### 3. Frozen Components$/;"	S	section:Current SteerMoE Implementation Analysis""Key Features
3. Layer-wise Optimizer	steer_moe/implementation_summary.md	/^### 3. Layer-wise Optimizer$/;"	S	section:SteerMoE Current Implementation Summary""Training Features
3. Recommendations	cross_modal_steer/router_analysis_and_cross_modal_steering.md	/^## 3. Recommendations$/;"	s	chapter:Router Implementation Analysis and Cross-Modal Steering Analysis
4. Early Stopping	steer_moe/implementation_summary.md	/^### 4. Early Stopping$/;"	S	section:SteerMoE Current Implementation Summary""Training Features
4. Theoretical Advantages of Layer-wise Steering	analysis_layer_wise_vs_post_encoder.md	/^## 4. Theoretical Advantages of Layer-wise Steering$/;"	s	chapter:Analysis: Layer-wise Steering vs Post-encoder Steering
5. Theoretical Disadvantages	analysis_layer_wise_vs_post_encoder.md	/^## 5. Theoretical Disadvantages$/;"	s	chapter:Analysis: Layer-wise Steering vs Post-encoder Steering
6. Performance Predictions	analysis_layer_wise_vs_post_encoder.md	/^## 6. Performance Predictions$/;"	s	chapter:Analysis: Layer-wise Steering vs Post-encoder Steering
7. Implementation Strategy	analysis_layer_wise_vs_post_encoder.md	/^## 7. Implementation Strategy$/;"	s	chapter:Analysis: Layer-wise Steering vs Post-encoder Steering
8. Code Implementation	analysis_layer_wise_vs_post_encoder.md	/^## 8. Code Implementation$/;"	s	chapter:Analysis: Layer-wise Steering vs Post-encoder Steering
9. Experimental Design	analysis_layer_wise_vs_post_encoder.md	/^## 9. Experimental Design$/;"	s	chapter:Analysis: Layer-wise Steering vs Post-encoder Steering
AUDIO_FORMAT_SETS	steer_moe/tokenizer/glm4/cosyvoice/dataset/processor.py	/^AUDIO_FORMAT_SETS = set(['flac', 'mp3', 'm4a', 'ogg', 'opus', 'wav', 'wma'])$/;"	v
AbsolutePositionalEmbedding	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer.py	/^class AbsolutePositionalEmbedding(nn.Module):$/;"	c
AbsolutePositionalEmbedding	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer_use_mask.py	/^class AbsolutePositionalEmbedding(nn.Module):$/;"	c
Acknowledgements	steer_moe/tokenizer/glm4/README.md	/^## Acknowledgements$/;"	s	chapter:GLM-4-Voice
Acknowledgements	steer_moe/tokenizer/glm4/README_en.md	/^## Acknowledgements$/;"	s	chapter:GLM-4-Voice
Acknowledgements	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/README.md	/^## Acknowledgements$/;"	s	chapter:üçµ Matcha-TTS: A fast TTS architecture with conditional flow matching
Acknowledgements	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/hifigan/README.md	/^## Acknowledgements$/;"	s	chapter:HiFi-GAN: Generative Adversarial Networks for Efficient and High Fidelity Speech Synthesis
AdaRMSNorm	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/blocks.py	/^class AdaRMSNorm(nn.Module):$/;"	c
Advanced Training with Evaluation	README.md	/^### Advanced Training with Evaluation$/;"	S	section:SteerMoE""Training
Advantages of Current Implementation	steer_moe/current_implementation_analysis.md	/^## Advantages of Current Implementation$/;"	s	chapter:Current SteerMoE Implementation Analysis
Aligner Mechanics	README.md	/^## Aligner Mechanics$/;"	s	chapter:SteerMoE
Analysis	steer_moe/implementation_summary.md	/^### Analysis$/;"	S	section:SteerMoE Current Implementation Summary""Usage Examples
Analysis: Layer-wise Steering vs Post-encoder Steering	analysis_layer_wise_vs_post_encoder.md	/^# Analysis: Layer-wise Steering vs Post-encoder Steering$/;"	c
Architecture	README.md	/^## Architecture$/;"	s	chapter:SteerMoE
Architecture Components	steer_moe/implementation_summary.md	/^## Architecture Components$/;"	s	chapter:SteerMoE Current Implementation Summary
Attention	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^class Attention(nn.Module):$/;"	c
Attention	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer.py	/^class Attention(nn.Module):$/;"	c
Attention	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer_use_mask.py	/^class Attention(nn.Module):$/;"	c
AttentionBase	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^class AttentionBase(nn.Module):$/;"	c
AttentionBasedRouter	cross_modal_steer/router_comparison.py	/^class AttentionBasedRouter(nn.Module):$/;"	c
AttrDict	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/hifigan/env.py	/^class AttrDict(dict):$/;"	c
AudioDecoder	steer_moe/tokenizer/glm4/flow_inference.py	/^class AudioDecoder:$/;"	c
AudioStreamProcessor	steer_moe/tokenizer/glm4/audio_process.py	/^class AudioStreamProcessor:$/;"	c
AudioToText	steer_moe/al_models.py	/^class AudioToText(nn.Module):$/;"	c
BASECFM	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/components/flow_matching.py	/^class BASECFM(torch.nn.Module, ABC):$/;"	c
BaseEncoder	steer_moe/tokenizer/glm4/cosyvoice/transformer/encoder.py	/^class BaseEncoder(torch.nn.Module):$/;"	c
BaseLightningClass	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/baselightningmodule.py	/^class BaseLightningClass(LightningModule, ABC):$/;"	c
BaseSubsampling	steer_moe/tokenizer/glm4/cosyvoice/transformer/subsampling.py	/^class BaseSubsampling(torch.nn.Module):$/;"	c
Basic Training	README.md	/^### Basic Training$/;"	S	section:SteerMoE""Training
BasicTransformerBlock	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/components/transformer.py	/^class BasicTransformerBlock(nn.Module):$/;"	c
BatchedSynthesisDataset	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/cli.py	/^class BatchedSynthesisDataset(torch.utils.data.Dataset):$/;"	c
Before submitting	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/.github/PULL_REQUEST_TEMPLATE.md	/^## Before submitting$/;"	s
Better Cross-Modal Steering Approaches	cross_modal_steer/router_analysis_and_cross_modal_steering.md	/^### Better Cross-Modal Steering Approaches$/;"	S	section:Router Implementation Analysis and Cross-Modal Steering Analysis""2. Cross-Modal Attention Steering Analysis
BiTransformerDecoder	steer_moe/tokenizer/glm4/cosyvoice/transformer/decoder.py	/^class BiTransformerDecoder(torch.nn.Module):$/;"	c
Block1D	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/components/decoder.py	/^class Block1D(torch.nn.Module):$/;"	c
BlockConformerEncoder	steer_moe/tokenizer/glm4/cosyvoice/transformer/encoder.py	/^class BlockConformerEncoder(BaseEncoder):$/;"	c
BlockRelPositionMultiHeadedAttention	steer_moe/tokenizer/glm4/cosyvoice/transformer/attention.py	/^class BlockRelPositionMultiHeadedAttention(MultiHeadedAttention):$/;"	c
BottleneckBlock1d	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^class BottleneckBlock1d(nn.Module):$/;"	c
CFM	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/components/flow_matching.py	/^class CFM(BASECFM):$/;"	c
CHUNK_LENGTH	steer_moe/tokenizer/whisper_Lv3/whisper.py	/^CHUNK_LENGTH = 30$/;"	v
CLI Arguments	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/README.md	/^### CLI Arguments$/;"	S	section:üçµ Matcha-TTS: A fast TTS architecture with conditional flow matching""Installation
COSYVOICE_ACTIVATION_CLASSES	steer_moe/tokenizer/glm4/cosyvoice/utils/class_utils.py	/^COSYVOICE_ACTIVATION_CLASSES = {$/;"	v
COSYVOICE_ATTENTION_CLASSES	steer_moe/tokenizer/glm4/cosyvoice/utils/class_utils.py	/^COSYVOICE_ATTENTION_CLASSES = {$/;"	v
COSYVOICE_EMB_CLASSES	steer_moe/tokenizer/glm4/cosyvoice/utils/class_utils.py	/^COSYVOICE_EMB_CLASSES = {$/;"	v
COSYVOICE_SUBSAMPLE_CLASSES	steer_moe/tokenizer/glm4/cosyvoice/utils/class_utils.py	/^COSYVOICE_SUBSAMPLE_CLASSES = {$/;"	v
CURRENTLY_LOADED_MODEL	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/app.py	/^CURRENTLY_LOADED_MODEL = args.model$/;"	v
Cases	steer_moe/tokenizer/glm4/README.md	/^## Cases$/;"	s	chapter:GLM-4-Voice
CausalConv1d	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^class CausalConv1d(nn.Conv1d):$/;"	c
Citation	steer_moe/tokenizer/glm4/README_en.md	/^## Citation$/;"	s	chapter:GLM-4-Voice
Citation information	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/README.md	/^## Citation information$/;"	s	chapter:üçµ Matcha-TTS: A fast TTS architecture with conditional flow matching
Code Reuse	README.md	/^## Code Reuse$/;"	s	chapter:SteerMoE
Component Analysis	steer_moe/current_implementation_analysis.md	/^## Component Analysis$/;"	s	chapter:Current SteerMoE Implementation Analysis
ConditionalCFM	steer_moe/tokenizer/glm4/cosyvoice/flow/flow_matching.py	/^class ConditionalCFM(BASECFM):$/;"	c
ConditionalCFM	steer_moe/tokenizer/glm4/cosyvoice/flow/flow_matching_dit.py	/^class ConditionalCFM(BASECFM):$/;"	c
ConditionalDecoder	steer_moe/tokenizer/glm4/cosyvoice/flow/decoder.py	/^class ConditionalDecoder(nn.Module):$/;"	c
ConditionedSequential	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^class ConditionedSequential(nn.Module):$/;"	c
Configuration	README.md	/^## Configuration$/;"	s	chapter:SteerMoE
Configuration	steer_moe/implementation_summary.md	/^### Configuration$/;"	S	section:SteerMoE Current Implementation Summary""Training Process
ConformerEncoder	steer_moe/tokenizer/glm4/cosyvoice/transformer/encoder.py	/^class ConformerEncoder(BaseEncoder):$/;"	c
ConformerEncoderLayer	steer_moe/tokenizer/glm4/cosyvoice/transformer/encoder_layer.py	/^class ConformerEncoderLayer(nn.Module):$/;"	c
ConformerModule	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer.py	/^class ConformerModule(nn.Module):$/;"	c
ConformerModule	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer_use_mask.py	/^class ConformerModule(nn.Module):$/;"	c
ConformerWrapper	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/components/decoder.py	/^class ConformerWrapper(ConformerBlock):$/;"	c
ConstantLR	steer_moe/tokenizer/glm4/cosyvoice/utils/scheduler.py	/^class ConstantLR(_LRScheduler):$/;"	c
ContinuousTransformer	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer.py	/^class ContinuousTransformer(nn.Module):$/;"	c
ContinuousTransformer	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer_use_mask.py	/^class ContinuousTransformer(nn.Module):$/;"	c
ContinuousTransformer_mask	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/dit.py	/^from .transformer_use_mask import ContinuousTransformer as ContinuousTransformer_mask$/;"	x	nameref:unknown:ContinuousTransformer
Conv1d	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^class Conv1d(nn.Conv1d):$/;"	c
Conv1dSubsampling2	steer_moe/tokenizer/glm4/cosyvoice/transformer/subsampling.py	/^class Conv1dSubsampling2(BaseSubsampling):$/;"	c
Conv2dSubsampling4	steer_moe/tokenizer/glm4/cosyvoice/transformer/subsampling.py	/^class Conv2dSubsampling4(BaseSubsampling):$/;"	c
Conv2dSubsampling6	steer_moe/tokenizer/glm4/cosyvoice/transformer/subsampling.py	/^class Conv2dSubsampling6(BaseSubsampling):$/;"	c
Conv2dSubsampling8	steer_moe/tokenizer/glm4/cosyvoice/transformer/subsampling.py	/^class Conv2dSubsampling8(BaseSubsampling):$/;"	c
ConvBlock1d	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^class ConvBlock1d(nn.Module):$/;"	c
ConvRNNF0Predictor	steer_moe/tokenizer/glm4/cosyvoice/hifigan/f0_predictor.py	/^class ConvRNNF0Predictor(nn.Module):$/;"	c
ConvReluNorm	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/components/text_encoder.py	/^class ConvReluNorm(nn.Module):$/;"	c
ConvTranspose1d	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^class ConvTranspose1d(nn.ConvTranspose1d):$/;"	c
ConvolutionModule	steer_moe/tokenizer/glm4/cosyvoice/transformer/convolution.py	/^class ConvolutionModule(nn.Module):$/;"	c
CosineAnnealing	steer_moe/tokenizer/glm4/cosyvoice/utils/scheduler.py	/^class CosineAnnealing(WarmupAnnealHoldPolicy):$/;"	c
CosyVoice	steer_moe/tokenizer/glm4/cosyvoice/cli/cosyvoice.py	/^class CosyVoice:$/;"	c
CosyVoiceFrontEnd	steer_moe/tokenizer/glm4/cosyvoice/cli/frontend.py	/^class CosyVoiceFrontEnd:$/;"	c
CosyVoiceModel	steer_moe/tokenizer/glm4/cosyvoice/cli/model.py	/^class CosyVoiceModel:$/;"	c
CrossModalAdapter	cross_modal_steer/cross_modal_steering.py	/^class CrossModalAdapter(nn.Module):$/;"	c
CrossModalFeatureAligner	cross_modal_steer/cross_modal_steering.py	/^class CrossModalFeatureAligner(nn.Module):$/;"	c
Current Implementation (SteerMoE Aligner)	cross_modal_steer/router_analysis_and_cross_modal_steering.md	/^### Current Implementation (SteerMoE Aligner)$/;"	S	section:Router Implementation Analysis and Cross-Modal Steering Analysis""1. Router Implementation Comparison
Current SteerMoE Implementation Analysis	steer_moe/current_implementation_analysis.md	/^# Current SteerMoE Implementation Analysis$/;"	c
Current Training Script (`scripts/train.py`)	steer_moe/current_implementation_analysis.md	/^### Current Training Script (`scripts\/train.py`)$/;"	S	section:Current SteerMoE Implementation Analysis""Training Process
CurrentRouter	cross_modal_steer/router_comparison.py	/^class CurrentRouter(nn.Module):$/;"	c
CustomDatasetIterator	whisper_train/main_word_correct_clips.py	/^class CustomDatasetIterator:$/;"	c
DDP	whisper_train/main_word_correct_clips.py	/^from torch.nn.parallel import DistributedDataParallel as DDP$/;"	x	nameref:unknown:DistributedDataParallel
DEFAULT_CALLBACKS	whisper_train/main_word_correct_clips.py	/^DEFAULT_CALLBACKS = [DefaultFlowCallback]$/;"	v
DEFAULT_OPSET	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/onnx/export.py	/^DEFAULT_OPSET = 15$/;"	v
DEFAULT_PROGRESS_CALLBACK	whisper_train/main_word_correct_clips.py	/^    DEFAULT_PROGRESS_CALLBACK = NotebookProgressCallback$/;"	v
DEFAULT_PROGRESS_CALLBACK	whisper_train/main_word_correct_clips.py	/^DEFAULT_PROGRESS_CALLBACK = ProgressCallback$/;"	v
DataList	steer_moe/tokenizer/glm4/cosyvoice/dataset/dataset.py	/^class DataList(IterableDataset):$/;"	c
Dataset	steer_moe/tokenizer/glm4/cosyvoice/dataset/dataset.py	/^def Dataset(data_list_file,$/;"	f
Dataset Loading	README.md	/^## Dataset Loading$/;"	s	chapter:SteerMoE
Decoder	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/components/decoder.py	/^class Decoder(nn.Module):$/;"	c
DecoderLayer	steer_moe/tokenizer/glm4/cosyvoice/transformer/decoder_layer.py	/^class DecoderLayer(nn.Module):$/;"	c
Denoiser	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/hifigan/denoiser.py	/^class Denoiser(torch.nn.Module):$/;"	c
Detailed Workflow:	steer_moe/current_implementation_analysis.md	/^### Detailed Workflow:$/;"	S	section:Current SteerMoE Implementation Analysis""Workflow Summary
Did you have fun?	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/.github/PULL_REQUEST_TEMPLATE.md	/^## Did you have fun?$/;"	s
DiffusionTransformer	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/dit.py	/^class DiffusionTransformer(nn.Module):$/;"	c
DiffusionTransformerV2	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/dit_v2.py	/^class DiffusionTransformerV2(nn.Module):$/;"	c
DiscriminatorP	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/hifigan/models.py	/^class DiscriminatorP(torch.nn.Module):$/;"	c
DiscriminatorS	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/hifigan/models.py	/^class DiscriminatorS(torch.nn.Module):$/;"	c
Distributed Training with DeepSpeed	README.md	/^### Distributed Training with DeepSpeed$/;"	S	section:SteerMoE""Training
DistributedSampler	steer_moe/tokenizer/glm4/cosyvoice/dataset/dataset.py	/^class DistributedSampler:$/;"	c
Downsample1D	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/components/decoder.py	/^class Downsample1D(nn.Module):$/;"	c
Downsample1d	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^def Downsample1d($/;"	f	typeref:typename:nn.Module
Downsample1d	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/blocks.py	/^class Downsample1d(nn.Module):$/;"	c
Downsample1d_2	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/blocks.py	/^def Downsample1d_2($/;"	f	typeref:typename:nn.Module
DownsampleBlock1d	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^class DownsampleBlock1d(nn.Module):$/;"	c
DurationPredictor	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/components/text_encoder.py	/^class DurationPredictor(nn.Module):$/;"	c
EfficientLayerWiseSteeringWhisperEncoder	steer_moe/efficient_layer_wise_whisper.py	/^class EfficientLayerWiseSteeringWhisperEncoder(nn.Module):$/;"	c
EmbedinigNoSubsampling	steer_moe/tokenizer/glm4/cosyvoice/transformer/subsampling.py	/^class EmbedinigNoSubsampling(BaseSubsampling):$/;"	c
EnNormalizer	steer_moe/tokenizer/glm4/cosyvoice/cli/frontend.py	/^    from tn.english.normalizer import Normalizer as EnNormalizer$/;"	x	nameref:unknown:Normalizer
Encoder	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/components/text_encoder.py	/^class Encoder(nn.Module):$/;"	c
EspnetRelPositionalEncoding	steer_moe/tokenizer/glm4/cosyvoice/transformer/embedding.py	/^class EspnetRelPositionalEncoding(torch.nn.Module):$/;"	c
Evaluation	steer_moe/implementation_summary.md	/^### Evaluation$/;"	S	section:SteerMoE Current Implementation Summary""Usage Examples
Evaluation Metrics	README.md	/^## Evaluation Metrics$/;"	s	chapter:SteerMoE
Examples	steer_moe/tokenizer/glm4/README_en.md	/^## Examples$/;"	s	chapter:GLM-4-Voice
Executive Summary	analysis_layer_wise_vs_post_encoder.md	/^## Executive Summary$/;"	s	chapter:Analysis: Layer-wise Steering vs Post-encoder Steering
Executor	steer_moe/tokenizer/glm4/cosyvoice/utils/executor.py	/^class Executor:$/;"	c
F	cross_modal_steer/cross_modal_steering.py	/^import torch.nn.functional as F$/;"	I	nameref:module:torch.nn.functional
F	cross_modal_steer/router_comparison.py	/^import torch.nn.functional as F$/;"	I	nameref:module:torch.nn.functional
F	steer_moe/aligner.py	/^import torch.nn.functional as F$/;"	I	nameref:module:torch.nn.functional
F	steer_moe/efficient_layer_wise_whisper.py	/^import torch.nn.functional as F$/;"	I	nameref:module:torch.nn.functional
F	steer_moe/layer_wise_aligner.py	/^import torch.nn.functional as F$/;"	I	nameref:module:torch.nn.functional
F	steer_moe/layer_wise_whisper.py	/^import torch.nn.functional as F$/;"	I	nameref:module:torch.nn.functional
F	steer_moe/shared_router_implementation.py	/^import torch.nn.functional as F$/;"	I	nameref:module:torch.nn.functional
F	steer_moe/tokenizer/glm4/cosyvoice/dataset/processor.py	/^import torch.nn.functional as F$/;"	I	nameref:module:torch.nn.functional
F	steer_moe/tokenizer/glm4/cosyvoice/flow/flow.py	/^from torch.nn import functional as F$/;"	x	nameref:unknown:functional
F	steer_moe/tokenizer/glm4/cosyvoice/flow/flow_gradtts.py	/^from torch.nn import functional as F$/;"	x	nameref:unknown:functional
F	steer_moe/tokenizer/glm4/cosyvoice/flow/flow_matching.py	/^import torch.nn.functional as F$/;"	I	nameref:module:torch.nn.functional
F	steer_moe/tokenizer/glm4/cosyvoice/flow/flow_matching_dit.py	/^import torch.nn.functional as F$/;"	I	nameref:module:torch.nn.functional
F	steer_moe/tokenizer/glm4/cosyvoice/flow/length_regulator.py	/^from torch.nn import functional as F$/;"	x	nameref:unknown:functional
F	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^from torch.nn import functional as F$/;"	x	nameref:unknown:functional
F	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/blocks.py	/^from torch.nn import functional as F$/;"	x	nameref:unknown:functional
F	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/dit.py	/^from torch.nn import functional as F$/;"	x	nameref:unknown:functional
F	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/dit_v2.py	/^from torch.nn import functional as F$/;"	x	nameref:unknown:functional
F	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/stable_diffusion.py	/^from torch.nn import functional as F$/;"	x	nameref:unknown:functional
F	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/stable_diffusion_test.py	/^from torch.nn import functional as F$/;"	x	nameref:unknown:functional
F	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer.py	/^import torch.nn.functional as F$/;"	I	nameref:module:torch.nn.functional
F	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer_use_mask.py	/^import torch.nn.functional as F$/;"	I	nameref:module:torch.nn.functional
F	steer_moe/tokenizer/glm4/cosyvoice/hifigan/generator.py	/^import torch.nn.functional as F$/;"	I	nameref:module:torch.nn.functional
F	steer_moe/tokenizer/glm4/cosyvoice/llm/llm.py	/^import torch.nn.functional as F$/;"	I	nameref:module:torch.nn.functional
F	steer_moe/tokenizer/glm4/cosyvoice/transformer/embedding.py	/^import torch.nn.functional as F$/;"	I	nameref:module:torch.nn.functional
F	steer_moe/tokenizer/glm4/speech_tokenizer/generation_whisper.py	/^import torch.nn.functional as F$/;"	I	nameref:module:torch.nn.functional
F	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/hifigan/models.py	/^import torch.nn.functional as F$/;"	I	nameref:module:torch.nn.functional
F	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/components/decoder.py	/^import torch.nn.functional as F$/;"	I	nameref:module:torch.nn.functional
F	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/components/flow_matching.py	/^import torch.nn.functional as F$/;"	I	nameref:module:torch.nn.functional
F	steer_moe/tokenizer/whisper_Lv3/whisper.py	/^import torch.nn.functional as F$/;"	I	nameref:module:torch.nn.functional
FFN	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/components/text_encoder.py	/^class FFN(nn.Module):$/;"	c
FeedForward	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^def FeedForward(features: int, multiplier: int) -> nn.Module:$/;"	f	typeref:typename:nn.Module
FeedForward	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer.py	/^class FeedForward(nn.Module):$/;"	c
FeedForward	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer_use_mask.py	/^class FeedForward(nn.Module):$/;"	c
FeedForward	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/components/transformer.py	/^class FeedForward(nn.Module):$/;"	c
Fine-Tuning	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/hifigan/README.md	/^## Fine-Tuning$/;"	s	chapter:HiFi-GAN: Generative Adversarial Networks for Efficient and High Fidelity Speech Synthesis
FixedEmbedding	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^class FixedEmbedding(nn.Module):$/;"	c
For Cross-Modal Alignment:	cross_modal_steer/router_analysis_and_cross_modal_steering.md	/^### For Cross-Modal Alignment:$/;"	S	section:Router Implementation Analysis and Cross-Modal Steering Analysis""3. Recommendations
For Layer-Wise Steering:	cross_modal_steer/router_analysis_and_cross_modal_steering.md	/^### For Layer-Wise Steering:$/;"	S	section:Router Implementation Analysis and Cross-Modal Steering Analysis""3. Recommendations
ForcedWNConv1d	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/blocks.py	/^class ForcedWNConv1d(nn.Module):$/;"	c
FourierFeatures	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/blocks.py	/^class FourierFeatures(nn.Module):$/;"	c
Future Improvements	steer_moe/implementation_summary.md	/^## Future Improvements$/;"	s	chapter:SteerMoE Current Implementation Summary
GLM-4-Voice	steer_moe/tokenizer/glm4/README.md	/^# GLM-4-Voice$/;"	c
GLM-4-Voice	steer_moe/tokenizer/glm4/README_en.md	/^# GLM-4-Voice$/;"	c
GLU	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer.py	/^class GLU(nn.Module):$/;"	c
GLU	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer_use_mask.py	/^class GLU(nn.Module):$/;"	c
GPT_SPK_EMBEDDING	steer_moe/tokenizer/glm4/cosyvoice/dataset/processor.py	/^    GPT_SPK_EMBEDDING=torch.load("\/workspace\/audio_checkpoints\/flow_model\/spk_embedding\/090/;"	v
GPT_SPK_EMBEDDING	steer_moe/tokenizer/glm4/cosyvoice/dataset/processor.py	/^    GPT_SPK_EMBEDDING=torch.zeros(1,192)$/;"	v
Generator	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/hifigan/models.py	/^class Generator(torch.nn.Module):$/;"	c
Glm4Tokenizer	steer_moe/tokenizer/glm4_tokenizer.py	/^class Glm4Tokenizer(nn.Module):$/;"	c
GradientClippingCallback	scripts/train_layer_wise.py	/^class GradientClippingCallback:$/;"	c
HOP_LENGTH	steer_moe/tokenizer/whisper_Lv3/whisper.py	/^HOP_LENGTH = 160$/;"	v
HiFTGenerator	steer_moe/tokenizer/glm4/cosyvoice/hifigan/generator.py	/^class HiFTGenerator(nn.Module):$/;"	c
HiFi-GAN: Generative Adversarial Networks for Efficient and High Fidelity Speech Synthesis	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/hifigan/README.md	/^# HiFi-GAN: Generative Adversarial Networks for Efficient and High Fidelity Speech Synthesis$/;"	c
HiFiGAN	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/cli.py	/^from matcha.hifigan.models import Generator as HiFiGAN$/;"	x	nameref:unknown:Generator
Hierarchical Router Design	cross_modal_steer/router_analysis_and_cross_modal_steering.md	/^### Hierarchical Router Design$/;"	S	section:Router Implementation Analysis and Cross-Modal Steering Analysis""1. Router Implementation Comparison
HierarchicalRouter	cross_modal_steer/router_comparison.py	/^class HierarchicalRouter(nn.Module):$/;"	c
IGNORE_ID	steer_moe/tokenizer/glm4/cosyvoice/utils/common.py	/^IGNORE_ID = -1$/;"	v
IS_SAGEMAKER_MP_POST_1_10	whisper_train/main_word_correct_clips.py	/^    IS_SAGEMAKER_MP_POST_1_10 = version.parse(SMP_VERSION) >= version.parse("1.10")$/;"	v
Inference for end-to-end speech synthesis	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/hifigan/README.md	/^## Inference for end-to-end speech synthesis$/;"	s	chapter:HiFi-GAN: Generative Adversarial Networks for Efficient and High Fidelity Speech Synthesis
Inference from wav file	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/hifigan/README.md	/^## Inference from wav file$/;"	s	chapter:HiFi-GAN: Generative Adversarial Networks for Efficient and High Fidelity Speech Synthesis
Installation	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/README.md	/^## Installation$/;"	s	chapter:üçµ Matcha-TTS: A fast TTS architecture with conditional flow matching
InterpolateRegulator	steer_moe/tokenizer/glm4/cosyvoice/flow/length_regulator.py	/^class InterpolateRegulator(nn.Module):$/;"	c
Jungil Kong, Jaehyeon Kim, Jaekyoung Bae	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/hifigan/README.md	/^### Jungil Kong, Jaehyeon Kim, Jaekyoung Bae$/;"	S	chapter:HiFi-GAN: Generative Adversarial Networks for Efficient and High Fidelity Speech Synthesis
K	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/sampling.py	/^import k_diffusion as K$/;"	I	nameref:module:k_diffusion
Key Advantages	steer_moe/implementation_summary.md	/^## Key Advantages$/;"	s	chapter:SteerMoE Current Implementation Summary
Key Features	README.md	/^## Key Features$/;"	s	chapter:SteerMoE
Key Features	steer_moe/current_implementation_analysis.md	/^## Key Features$/;"	s	chapter:Current SteerMoE Implementation Analysis
Key Insights:	cross_modal_steer/router_analysis_and_cross_modal_steering.md	/^### Key Insights:$/;"	S	section:Router Implementation Analysis and Cross-Modal Steering Analysis""3. Recommendations
Known Issues	steer_moe/tokenizer/glm4/README.md	/^### Known Issues$/;"	S	section:GLM-4-Voice""Usage
Known Issues	steer_moe/tokenizer/glm4/README_en.md	/^### Known Issues$/;"	S	section:GLM-4-Voice""Usage
L	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/train.py	/^import lightning as L$/;"	I	nameref:module:lightning
LOCATION	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/app.py	/^LOCATION = Path(get_user_data_dir())$/;"	v
LOGO_URL	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/app.py	/^LOGO_URL = "https:\/\/shivammehta25.github.io\/Matcha-TTS\/images\/logo.png"$/;"	v
LRELU_SLOPE	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/hifigan/models.py	/^LRELU_SLOPE = 0.1$/;"	v
LabelSmoothingLoss	steer_moe/tokenizer/glm4/cosyvoice/transformer/label_smoothing_loss.py	/^class LabelSmoothingLoss(nn.Module):$/;"	c
Launch Web Demo	steer_moe/tokenizer/glm4/README.md	/^### Launch Web Demo$/;"	S	section:GLM-4-Voice""Usage
Launch Web Demo	steer_moe/tokenizer/glm4/README_en.md	/^### Launch Web Demo$/;"	S	section:GLM-4-Voice""Usage
LayerNorm	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer.py	/^class LayerNorm(nn.Module):$/;"	c
LayerNorm	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer_use_mask.py	/^class LayerNorm(nn.Module):$/;"	c
LayerNorm	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/components/text_encoder.py	/^class LayerNorm(nn.Module):$/;"	c
LayerWiseSteerMoEAligner	steer_moe/layer_wise_aligner.py	/^class LayerWiseSteerMoEAligner(nn.Module):$/;"	c
LayerWiseSteeringWhisperEncoder	steer_moe/layer_wise_whisper.py	/^class LayerWiseSteeringWhisperEncoder(nn.Module):$/;"	c
LearnablePositionalEncoding	steer_moe/tokenizer/glm4/cosyvoice/transformer/embedding.py	/^class LearnablePositionalEncoding(PositionalEncoding):$/;"	c
LearnedPositionalEmbedding	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^class LearnedPositionalEmbedding(nn.Module):$/;"	c
LegacyLinearNoSubsampling	steer_moe/tokenizer/glm4/cosyvoice/transformer/subsampling.py	/^class LegacyLinearNoSubsampling(BaseSubsampling):$/;"	c
License Agreement	steer_moe/tokenizer/glm4/README_en.md	/^## License Agreement$/;"	s	chapter:GLM-4-Voice
Limitations	steer_moe/current_implementation_analysis.md	/^## Limitations$/;"	s	chapter:Current SteerMoE Implementation Analysis
Limitations and Considerations	steer_moe/implementation_summary.md	/^## Limitations and Considerations$/;"	s	chapter:SteerMoE Current Implementation Summary
LinearGEGLU	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/blocks.py	/^class LinearGEGLU(nn.Linear):$/;"	c
LinearNoSubsampling	steer_moe/tokenizer/glm4/cosyvoice/transformer/subsampling.py	/^class LinearNoSubsampling(BaseSubsampling):$/;"	c
Load Model	README.md	/^### Load Model$/;"	S	section:SteerMoE""Model Saving and Loading
Logged_Seq2SeqTrainer	whisper_train/main_word_correct_clips.py	/^class Logged_Seq2SeqTrainer(Logged_Traniner):$/;"	c
Logged_Traniner	whisper_train/main_word_correct_clips.py	/^class Logged_Traniner(Trainer):$/;"	c
MATCHA_TTS_LOC	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/app.py	/^def MATCHA_TTS_LOC(x):$/;"	f
MATCHA_URLS	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/cli.py	/^MATCHA_URLS = {$/;"	v
MAX_WAV_VALUE	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/hifigan/meldataset.py	/^MAX_WAV_VALUE = 32768.0$/;"	v
MAX_WAV_VALUE	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/utils/audio.py	/^MAX_WAV_VALUE = 32768.0$/;"	v
MMTar	steer_moe/tokenizer/glm4/cosyvoice/dataset/processor.py	/^class MMTar:$/;"	c
MULTISPEAKER_MODEL	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/cli.py	/^MULTISPEAKER_MODEL = {$/;"	v
MappingToScaleShift	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^class MappingToScaleShift(nn.Module):$/;"	c
MaskedDiffWithXvec	steer_moe/tokenizer/glm4/cosyvoice/flow/flow.py	/^class MaskedDiffWithXvec(torch.nn.Module):$/;"	c
MaskedDiffWithXvec	steer_moe/tokenizer/glm4/cosyvoice/flow/flow_gradtts.py	/^class MaskedDiffWithXvec(torch.nn.Module):$/;"	c
MatchaTTS	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/matcha_tts.py	/^class MatchaTTS(BaseLightningClass):  # üçµ$/;"	c
MatchaWithVocoder	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/onnx/export.py	/^class MatchaWithVocoder(LightningModule):$/;"	c
MelDataset	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/hifigan/meldataset.py	/^class MelDataset(torch.utils.data.Dataset):$/;"	c
MoEFFNLayer	steer_moe/tokenizer/glm4/cosyvoice/transformer/positionwise_feed_forward.py	/^class MoEFFNLayer(torch.nn.Module):$/;"	c
ModalitySpecificSteering	cross_modal_steer/cross_modal_steering.py	/^class ModalitySpecificSteering(nn.Module):$/;"	c
Model Architecture	steer_moe/tokenizer/glm4/README.md	/^## Model Architecture$/;"	s	chapter:GLM-4-Voice
Model Architecture	steer_moe/tokenizer/glm4/README_en.md	/^## Model Architecture$/;"	s	chapter:GLM-4-Voice
Model List	steer_moe/tokenizer/glm4/README.md	/^## Model List$/;"	s	chapter:GLM-4-Voice
Model List	steer_moe/tokenizer/glm4/README_en.md	/^## Model List$/;"	s	chapter:GLM-4-Voice
Model Saving and Loading	README.md	/^## Model Saving and Loading$/;"	s	chapter:SteerMoE
Model Variants	README.md	/^## Model Variants$/;"	s	chapter:SteerMoE
ModelWorker	steer_moe/tokenizer/glm4/model_server.py	/^class ModelWorker:$/;"	c
Monitoring and Analysis	steer_moe/implementation_summary.md	/^## Monitoring and Analysis$/;"	s	chapter:SteerMoE Current Implementation Summary
MultiHeadAttention	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/components/text_encoder.py	/^class MultiHeadAttention(nn.Module):$/;"	c
MultiHeadedAttention	steer_moe/tokenizer/glm4/cosyvoice/transformer/attention.py	/^class MultiHeadedAttention(nn.Module):$/;"	c
MultiPeriodDiscriminator	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/hifigan/models.py	/^class MultiPeriodDiscriminator(torch.nn.Module):$/;"	c
MultiScaleDiscriminator	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/hifigan/models.py	/^class MultiScaleDiscriminator(torch.nn.Module):$/;"	c
MultipleRoutersLayerWiseSteeringWhisperEncoder	steer_moe/shared_router_implementation.py	/^class MultipleRoutersLayerWiseSteeringWhisperEncoder(nn.Module):$/;"	c
N_FFT	steer_moe/tokenizer/whisper_Lv3/whisper.py	/^N_FFT = 400$/;"	v
N_MELS	steer_moe/tokenizer/whisper_Lv3/whisper.py	/^N_MELS = 120$/;"	v
N_SAMPLES	steer_moe/tokenizer/whisper_Lv3/whisper.py	/^N_SAMPLES = CHUNK_LENGTH * SAMPLE_RATE  # 480000 samples in a 30-second chunk$/;"	v
NoPositionalEncoding	steer_moe/tokenizer/glm4/cosyvoice/transformer/embedding.py	/^class NoPositionalEncoding(torch.nn.Module):$/;"	c
NoamAnnealing	steer_moe/tokenizer/glm4/cosyvoice/utils/scheduler.py	/^class NoamAnnealing(_LRScheduler):$/;"	c
NoamHoldAnnealing	steer_moe/tokenizer/glm4/cosyvoice/utils/scheduler.py	/^class NoamHoldAnnealing(WarmupHoldPolicy):$/;"	c
NumberEmbedder	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^class NumberEmbedder(nn.Module):$/;"	c
ONNX Inference	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/README.md	/^### ONNX Inference$/;"	S	section:üçµ Matcha-TTS: A fast TTS architecture with conditional flow matching""ONNX support
ONNX export	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/README.md	/^### ONNX export$/;"	S	section:üçµ Matcha-TTS: A fast TTS architecture with conditional flow matching""ONNX support
ONNX support	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/README.md	/^## ONNX support$/;"	s	chapter:üçµ Matcha-TTS: A fast TTS architecture with conditional flow matching
OPTIMIZER_NAME	whisper_train/main_word_correct_clips.py	/^OPTIMIZER_NAME = "optimizer.pt"$/;"	v
OPTIMIZER_NAME_BIN	whisper_train/main_word_correct_clips.py	/^OPTIMIZER_NAME_BIN = "optimizer.bin"$/;"	v
Overview	steer_moe/current_implementation_analysis.md	/^## Overview$/;"	s	chapter:Current SteerMoE Implementation Analysis
Overview	steer_moe/implementation_summary.md	/^## Overview$/;"	s	chapter:SteerMoE Current Implementation Summary
Patcher	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^class Patcher(nn.Module):$/;"	c
PositionalEncoding	steer_moe/tokenizer/glm4/cosyvoice/transformer/embedding.py	/^class PositionalEncoding(torch.nn.Module):$/;"	c
PositionwiseFeedForward	steer_moe/tokenizer/glm4/cosyvoice/transformer/positionwise_feed_forward.py	/^class PositionwiseFeedForward(torch.nn.Module):$/;"	c
Pre-requisites	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/hifigan/README.md	/^## Pre-requisites$/;"	s	chapter:HiFi-GAN: Generative Adversarial Networks for Efficient and High Fidelity Speech Synthesis
Preparation	steer_moe/tokenizer/glm4/README.md	/^### Preparation$/;"	S	section:GLM-4-Voice""Usage
Preparation	steer_moe/tokenizer/glm4/README_en.md	/^### Preparation$/;"	S	section:GLM-4-Voice""Usage
Pretrained Model	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/hifigan/README.md	/^## Pretrained Model$/;"	s	chapter:HiFi-GAN: Generative Adversarial Networks for Efficient and High Fidelity Speech Synthesis
Processor	steer_moe/tokenizer/glm4/cosyvoice/dataset/dataset.py	/^class Processor(IterableDataset):$/;"	c
Progressive Router Design	cross_modal_steer/router_analysis_and_cross_modal_steering.md	/^### Progressive Router Design$/;"	S	section:Router Implementation Analysis and Cross-Modal Steering Analysis""1. Router Implementation Comparison
ProgressiveCrossModalSteering	cross_modal_steer/cross_modal_steering.py	/^class ProgressiveCrossModalSteering(nn.Module):$/;"	c
ProgressiveRouter	cross_modal_steer/router_comparison.py	/^class ProgressiveRouter(nn.Module):$/;"	c
Project Structure	README.md	/^## Project Structure$/;"	s	chapter:SteerMoE
Push to HuggingFace Hub	README.md	/^### Push to HuggingFace Hub$/;"	S	section:SteerMoE""Model Saving and Loading
QuantizedBaseModelOutput	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^class QuantizedBaseModelOutput(BaseModelOutput):$/;"	c
RADIO_OPTIONS	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/app.py	/^RADIO_OPTIONS = {$/;"	v
README	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/setup.py	/^    README = readme_file.read()$/;"	v
RMSNorm	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/blocks.py	/^class RMSNorm(nn.Module):$/;"	c
Recommendations for Training Updates	steer_moe/current_implementation_analysis.md	/^## Recommendations for Training Updates$/;"	s	chapter:Current SteerMoE Implementation Analysis
RelPositionMultiHeadedAttention	steer_moe/tokenizer/glm4/cosyvoice/transformer/attention.py	/^class RelPositionMultiHeadedAttention(MultiHeadedAttention):$/;"	c
RelPositionalEncoding	steer_moe/tokenizer/glm4/cosyvoice/transformer/embedding.py	/^class RelPositionalEncoding(PositionalEncoding):$/;"	c
ResBlock	steer_moe/tokenizer/glm4/cosyvoice/hifigan/generator.py	/^class ResBlock(torch.nn.Module):$/;"	c
ResBlock1	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/hifigan/models.py	/^class ResBlock1(torch.nn.Module):$/;"	c
ResBlock2	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/hifigan/models.py	/^class ResBlock2(torch.nn.Module):$/;"	c
ResConvBlock	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/blocks.py	/^class ResConvBlock(ResidualBlock):$/;"	c
ResidualBlock	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/blocks.py	/^class ResidualBlock(nn.Module):$/;"	c
ResnetBlock1D	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/components/decoder.py	/^class ResnetBlock1D(torch.nn.Module):$/;"	c
ResnetBlock1d	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^class ResnetBlock1d(nn.Module):$/;"	c
RotaryEmbedding	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer.py	/^class RotaryEmbedding(nn.Module):$/;"	c
RotaryEmbedding	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer_use_mask.py	/^class RotaryEmbedding(nn.Module):$/;"	c
RotaryPositionalEmbeddings	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/components/text_encoder.py	/^class RotaryPositionalEmbeddings(nn.Module):$/;"	c
Router Implementation Analysis and Cross-Modal Steering Analysis	cross_modal_steer/router_analysis_and_cross_modal_steering.md	/^# Router Implementation Analysis and Cross-Modal Steering Analysis$/;"	c
SAMPLE_RATE	steer_moe/tokenizer/whisper_Lv3/whisper.py	/^SAMPLE_RATE = 16000$/;"	v
SCALER_NAME	whisper_train/main_word_correct_clips.py	/^SCALER_NAME = "scaler.pt"$/;"	v
SCHEDULER_NAME	whisper_train/main_word_correct_clips.py	/^SCHEDULER_NAME = "scheduler.pt"$/;"	v
SEED	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/onnx/export.py	/^SEED = 1234$/;"	v
SINGLESPEAKER_MODEL	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/cli.py	/^SINGLESPEAKER_MODEL = {"matcha_ljspeech": {"vocoder": "hifigan_T2_v1", "speaking_rate": 0.95, "s/;"	v
SMP_VERSION	whisper_train/main_word_correct_clips.py	/^    from smdistributed.modelparallel import __version__ as SMP_VERSION$/;"	x	nameref:unknown:__version__
SPACE_ID	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/text/symbols.py	/^SPACE_ID = symbols.index(" ")$/;"	v
STFT	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^class STFT(nn.Module):$/;"	c
Save Model	README.md	/^### Save Model$/;"	S	section:SteerMoE""Model Saving and Loading
SavePeftModelCallback	whisper_train/main_word_correct_clips.py	/^    class SavePeftModelCallback(TrainerCallback):$/;"	c	function:train_lora	file:
SavePeftModelCallback	whisper_train/main_word_correct_clips.py	/^    class SavePeftModelCallback(TrainerCallback):$/;"	c	function:train_lora_in_8bit	file:
ScaledSinusoidalEmbedding	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer.py	/^class ScaledSinusoidalEmbedding(nn.Module):$/;"	c
ScaledSinusoidalEmbedding	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer_use_mask.py	/^class ScaledSinusoidalEmbedding(nn.Module):$/;"	c
SelfAttention1d	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/blocks.py	/^class SelfAttention1d(nn.Module):$/;"	c
SharedRouterLayerWiseSteeringWhisperEncoder	steer_moe/efficient_layer_wise_whisper.py	/^class SharedRouterLayerWiseSteeringWhisperEncoder(nn.Module):$/;"	c
SharedRouterLayerWiseSteeringWhisperEncoder	steer_moe/shared_router_implementation.py	/^class SharedRouterLayerWiseSteeringWhisperEncoder(nn.Module):$/;"	c
SineGen	steer_moe/tokenizer/glm4/cosyvoice/hifigan/generator.py	/^class SineGen(torch.nn.Module):$/;"	c
SinusoidalEmbedding	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^class SinusoidalEmbedding(nn.Module):$/;"	c
SinusoidalPosEmb	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/components/decoder.py	/^class SinusoidalPosEmb(torch.nn.Module):$/;"	c
SkipBlock	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/blocks.py	/^class SkipBlock(nn.Module):$/;"	c
Snake	steer_moe/tokenizer/glm4/cosyvoice/transformer/activation.py	/^class Snake(nn.Module):$/;"	c
SnakeBeta	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/blocks.py	/^class SnakeBeta(nn.Module):$/;"	c
SnakeBeta	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/components/transformer.py	/^class SnakeBeta(nn.Module):$/;"	c
SourceModuleHnNSF	steer_moe/tokenizer/glm4/cosyvoice/hifigan/generator.py	/^class SourceModuleHnNSF(torch.nn.Module):$/;"	c
SquareAnnealing	steer_moe/tokenizer/glm4/cosyvoice/utils/scheduler.py	/^class SquareAnnealing(WarmupPolicy):$/;"	c
SquareRootAnnealing	steer_moe/tokenizer/glm4/cosyvoice/utils/scheduler.py	/^class SquareRootAnnealing(WarmupPolicy):$/;"	c
SquareRootConstantPolicy	steer_moe/tokenizer/glm4/cosyvoice/utils/scheduler.py	/^class SquareRootConstantPolicy(_LRScheduler):$/;"	c
Stable_Diffusion	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/stable_diffusion.py	/^class Stable_Diffusion(BaseModule):$/;"	c
Stable_Diffusion	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/stable_diffusion_test.py	/^class Stable_Diffusion(BaseModule):$/;"	c
SteerMoE	README.md	/^# SteerMoE$/;"	c
SteerMoE Current Implementation Summary	steer_moe/implementation_summary.md	/^# SteerMoE Current Implementation Summary$/;"	c
SteerMoEAligner	steer_moe/aligner.py	/^class SteerMoEAligner(nn.Module):$/;"	c
SteerMoEEfficientLayerWiseModel	steer_moe/models.py	/^class SteerMoEEfficientLayerWiseModel(nn.Module):$/;"	c
SteerMoEHybridModel	steer_moe/models.py	/^class SteerMoEHybridModel(nn.Module):$/;"	c
SteerMoELayerWiseModel	steer_moe/models.py	/^class SteerMoELayerWiseModel(nn.Module):$/;"	c
SteerMoEModel	steer_moe/models.py	/^class SteerMoEModel(nn.Module):$/;"	c
Steering Analysis	steer_moe/implementation_summary.md	/^### Steering Analysis$/;"	S	section:SteerMoE Current Implementation Summary""Monitoring and Analysis
SteeringAnalysisCallback	scripts/train_layer_wise.py	/^class SteeringAnalysisCallback:$/;"	c
Swish	steer_moe/tokenizer/glm4/cosyvoice/transformer/activation.py	/^class Swish(torch.nn.Module):$/;"	c
T	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^T = TypeVar("T")$/;"	v
TRAINER_STATE_NAME	whisper_train/main_word_correct_clips.py	/^TRAINER_STATE_NAME = "trainer_state.json"$/;"	v
TRAINING_ARGS_NAME	whisper_train/main_word_correct_clips.py	/^TRAINING_ARGS_NAME = "training_args.bin"$/;"	v
Tar	steer_moe/tokenizer/glm4/cosyvoice/dataset/processor.py	/^class Tar:$/;"	c
TarHeader	steer_moe/tokenizer/glm4/cosyvoice/dataset/processor.py	/^TarHeader = collections.namedtuple($/;"	v
Teaser video	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/README.md	/^## Teaser video$/;"	s	chapter:üçµ Matcha-TTS: A fast TTS architecture with conditional flow matching
TextEncoder	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/components/text_encoder.py	/^class TextEncoder(nn.Module):$/;"	c
TextMelBatchCollate	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/data/text_mel_datamodule.py	/^class TextMelBatchCollate:$/;"	c
TextMelDataModule	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/data/text_mel_datamodule.py	/^class TextMelDataModule(LightningDataModule):$/;"	c
TextMelDataset	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/data/text_mel_datamodule.py	/^class TextMelDataset(torch.utils.data.Dataset):$/;"	c
TimePositionalEmbedding	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^def TimePositionalEmbedding(dim: int, out_features: int) -> nn.Module:$/;"	f	typeref:typename:nn.Module
TimestepEmbedding	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/components/decoder.py	/^class TimestepEmbedding(nn.Module):$/;"	c
TokenStreamer	steer_moe/tokenizer/glm4/model_server.py	/^class TokenStreamer(BaseStreamer):$/;"	c
Train with your own dataset	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/README.md	/^## Train with your own dataset$/;"	s	chapter:üçµ Matcha-TTS: A fast TTS architecture with conditional flow matching
Training	README.md	/^## Training$/;"	s	chapter:SteerMoE
Training	steer_moe/implementation_summary.md	/^### Training$/;"	S	section:SteerMoE Current Implementation Summary""Usage Examples
Training	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/hifigan/README.md	/^## Training$/;"	s	chapter:HiFi-GAN: Generative Adversarial Networks for Efficient and High Fidelity Speech Synthesis
Training Features	steer_moe/implementation_summary.md	/^## Training Features$/;"	s	chapter:SteerMoE Current Implementation Summary
Training Process	steer_moe/current_implementation_analysis.md	/^## Training Process$/;"	s	chapter:Current SteerMoE Implementation Analysis
Training Process	steer_moe/implementation_summary.md	/^## Training Process$/;"	s	chapter:SteerMoE Current Implementation Summary
Transformer1d	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^class Transformer1d(nn.Module):$/;"	c
TransformerBlock	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^class TransformerBlock(nn.Module):$/;"	c
TransformerBlock	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer.py	/^class TransformerBlock(nn.Module):$/;"	c
TransformerBlock	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer_use_mask.py	/^class TransformerBlock(nn.Module):$/;"	c
TransformerDecoder	steer_moe/tokenizer/glm4/cosyvoice/transformer/decoder.py	/^class TransformerDecoder(torch.nn.Module):$/;"	c
TransformerEncoder	steer_moe/tokenizer/glm4/cosyvoice/transformer/encoder.py	/^class TransformerEncoder(BaseEncoder):$/;"	c
TransformerEncoderLayer	steer_moe/tokenizer/glm4/cosyvoice/transformer/encoder_layer.py	/^class TransformerEncoderLayer(nn.Module):$/;"	c
TransformerLM	steer_moe/tokenizer/glm4/cosyvoice/llm/llm.py	/^class TransformerLM(torch.nn.Module):$/;"	c
UNet1d	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^class UNet1d(nn.Module):$/;"	c
UNetAll1d	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^class UNetAll1d(UNetCFG1d, UNetNCCA1d):$/;"	c
UNetCFG1d	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^class UNetCFG1d(UNet1d):$/;"	c
UNetNCCA1d	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^class UNetNCCA1d(UNet1d):$/;"	c
Unpatcher	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^class Unpatcher(nn.Module):$/;"	c
Updated Training Script	steer_moe/implementation_summary.md	/^### Updated Training Script$/;"	S	section:SteerMoE Current Implementation Summary""Training Process
Upsample1D	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/components/decoder.py	/^class Upsample1D(nn.Module):$/;"	c
Upsample1d	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^def Upsample1d($/;"	f	typeref:typename:nn.Module
Upsample1d	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/blocks.py	/^class Upsample1d(nn.Module):$/;"	c
Upsample1d_2	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/blocks.py	/^def Upsample1d_2($/;"	f	typeref:typename:nn.Module
UpsampleBlock1d	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^class UpsampleBlock1d(nn.Module):$/;"	c
Usage	steer_moe/tokenizer/glm4/README.md	/^## Usage$/;"	s	chapter:GLM-4-Voice
Usage	steer_moe/tokenizer/glm4/README_en.md	/^## Usage$/;"	s	chapter:GLM-4-Voice
Usage Examples	README.md	/^## Usage Examples$/;"	s	chapter:SteerMoE
Usage Examples	steer_moe/implementation_summary.md	/^## Usage Examples$/;"	s	chapter:SteerMoE Current Implementation Summary
VOCODER_LOC	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/app.py	/^def VOCODER_LOC(x):$/;"	f
VOCODER_URLS	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/cli.py	/^VOCODER_URLS = {$/;"	v
Validation Metrics	steer_moe/implementation_summary.md	/^### Validation Metrics$/;"	S	section:SteerMoE Current Implementation Summary""Monitoring and Analysis
WHISPER_ATTENTION_CLASSES	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^WHISPER_ATTENTION_CLASSES = {$/;"	v
WHISPER_ENCODER_INPUTS_DOCSTRING	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^WHISPER_ENCODER_INPUTS_DOCSTRING = r"""$/;"	v
WHISPER_ENCODER_INPUTS_DOCSTRING	steer_moe/tokenizer/whisper_Lv3/modeling_whisper.py	/^WHISPER_ENCODER_INPUTS_DOCSTRING = r"""$/;"	v
WHISPER_INPUTS_DOCSTRING	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^WHISPER_INPUTS_DOCSTRING = r"""$/;"	v
WHISPER_INPUTS_DOCSTRING	steer_moe/tokenizer/whisper_Lv3/modeling_whisper.py	/^WHISPER_INPUTS_DOCSTRING = r"""$/;"	v
WHISPER_PRETRAINED_MODEL_ARCHIVE_LIST	steer_moe/tokenizer/whisper_Lv3/modeling_whisper.py	/^WHISPER_PRETRAINED_MODEL_ARCHIVE_LIST = [$/;"	v
WHISPER_START_DOCSTRING	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^WHISPER_START_DOCSTRING = r"""$/;"	v
WHISPER_START_DOCSTRING	steer_moe/tokenizer/whisper_Lv3/modeling_whisper.py	/^WHISPER_START_DOCSTRING = r"""$/;"	v
WarmupAnnealHoldPolicy	steer_moe/tokenizer/glm4/cosyvoice/utils/scheduler.py	/^class WarmupAnnealHoldPolicy(_LRScheduler):$/;"	c
WarmupHoldPolicy	steer_moe/tokenizer/glm4/cosyvoice/utils/scheduler.py	/^class WarmupHoldPolicy(WarmupPolicy):$/;"	c
WarmupLR	steer_moe/tokenizer/glm4/cosyvoice/utils/scheduler.py	/^class WarmupLR(_LRScheduler):$/;"	c
WarmupPolicy	steer_moe/tokenizer/glm4/cosyvoice/utils/scheduler.py	/^class WarmupPolicy(_LRScheduler):$/;"	c
What does this PR do?	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/.github/PULL_REQUEST_TEMPLATE.md	/^## What does this PR do?$/;"	s
WhisperAttention	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^class WhisperAttention(nn.Module):$/;"	c
WhisperAttention	steer_moe/tokenizer/whisper_Lv3/modeling_whisper.py	/^class WhisperAttention(nn.Module):$/;"	c
WhisperDecoder	steer_moe/tokenizer/whisper_Lv3/modeling_whisper.py	/^class WhisperDecoder(WhisperPreTrainedModel):$/;"	c
WhisperDecoderLayer	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^class WhisperDecoderLayer(nn.Module):$/;"	c
WhisperDecoderLayer	steer_moe/tokenizer/whisper_Lv3/modeling_whisper.py	/^class WhisperDecoderLayer(nn.Module):$/;"	c
WhisperDecoderWrapper	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^class WhisperDecoderWrapper(WhisperPreTrainedModel):$/;"	c
WhisperEncoder	steer_moe/tokenizer/whisper_Lv3/modeling_whisper.py	/^class WhisperEncoder(WhisperPreTrainedModel):$/;"	c
WhisperEncoder	steer_moe/tokenizer/whisper_Lv3/whisper.py	/^class WhisperEncoder(nn.Module):$/;"	c
WhisperEncoderLayer	steer_moe/tokenizer/whisper_Lv3/modeling_whisper.py	/^class WhisperEncoderLayer(nn.Module):$/;"	c
WhisperEncoderWithSteering	steer_moe/layer_wise_aligner.py	/^class WhisperEncoderWithSteering(nn.Module):$/;"	c
WhisperFlashAttention2	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^class WhisperFlashAttention2(WhisperAttention):$/;"	c
WhisperForAudioClassification	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^class WhisperForAudioClassification(WhisperPreTrainedModel):$/;"	c
WhisperForCausalLM	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^class WhisperForCausalLM(WhisperPreTrainedModel):$/;"	c
WhisperGenerationMixin	steer_moe/tokenizer/glm4/speech_tokenizer/generation_whisper.py	/^class WhisperGenerationMixin:$/;"	c
WhisperModel	steer_moe/tokenizer/whisper_Lv3/modeling_whisper.py	/^class WhisperModel(WhisperPreTrainedModel):$/;"	c
WhisperPositionalEmbedding	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^class WhisperPositionalEmbedding(nn.Embedding):$/;"	c
WhisperPositionalEmbedding	steer_moe/tokenizer/whisper_Lv3/modeling_whisper.py	/^class WhisperPositionalEmbedding(nn.Embedding):$/;"	c
WhisperPositionalEncoding	steer_moe/tokenizer/glm4/cosyvoice/transformer/embedding.py	/^class WhisperPositionalEncoding(PositionalEncoding):$/;"	c
WhisperPreTrainedModel	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^class WhisperPreTrainedModel(PreTrainedModel):$/;"	c
WhisperPreTrainedModel	steer_moe/tokenizer/whisper_Lv3/modeling_whisper.py	/^class WhisperPreTrainedModel(PreTrainedModel):$/;"	c
WhisperSdpaAttention	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^class WhisperSdpaAttention(WhisperAttention):$/;"	c
WhisperVQConfig	steer_moe/tokenizer/glm4/speech_tokenizer/configuration_whisper.py	/^class WhisperVQConfig(WhisperConfig):$/;"	c
WhisperVQDecoder	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^class WhisperVQDecoder(WhisperPreTrainedModel):$/;"	c
WhisperVQEncoder	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^class WhisperVQEncoder(WhisperPreTrainedModel):$/;"	c
WhisperVQEncoderLayer	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^class WhisperVQEncoderLayer(nn.Module):$/;"	c
WhisperVQForConditionalGeneration	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^class WhisperVQForConditionalGeneration(WhisperGenerationMixin, WhisperPreTrainedModel):$/;"	c
WhisperVQModel	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^class WhisperVQModel(WhisperPreTrainedModel):$/;"	c
Workflow Summary	steer_moe/current_implementation_analysis.md	/^## Workflow Summary$/;"	s	chapter:Current SteerMoE Implementation Analysis
XUNet1d	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^def XUNet1d(type: str = "base", **kwargs) -> UNet1d:$/;"	f	typeref:typename:UNet1d
Your Concern: Feature Space Gap	cross_modal_steer/router_analysis_and_cross_modal_steering.md	/^### Your Concern: Feature Space Gap$/;"	S	section:Router Implementation Analysis and Cross-Modal Steering Analysis""2. Cross-Modal Attention Steering Analysis
ZhNormalizer	steer_moe/tokenizer/glm4/cosyvoice/cli/frontend.py	/^    from tn.chinese.normalizer import Normalizer as ZhNormalizer$/;"	x	nameref:unknown:Normalizer
[Shivam Mehta](https://www.kth.se/profile/smehta), [Ruibo Tu](https://www.kth.se/profile/ruibo), [Jonas Beskow](https://www.kth.se/profile/beskow), [√âva Sz√©kely](https://www.kth.se/profile/szekely), and [Gustav Eje Henter](https://people.kth.se/~ghe/)	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/README.md	/^### [Shivam Mehta](https:\/\/www.kth.se\/profile\/smehta), [Ruibo Tu](https:\/\/www.kth.se\/prof/;"	S	chapter:üçµ Matcha-TTS: A fast TTS architecture with conditional flow matching
_CHECKPOINT_FOR_DOC	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^_CHECKPOINT_FOR_DOC = "openai\/whisper-tiny"$/;"	v
_CHECKPOINT_FOR_DOC	steer_moe/tokenizer/whisper_Lv3/modeling_whisper.py	/^_CHECKPOINT_FOR_DOC = "openai\/whisper-tiny"$/;"	v
_CONFIG_FOR_DOC	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^_CONFIG_FOR_DOC = "WhisperConfig"$/;"	v
_CONFIG_FOR_DOC	steer_moe/tokenizer/whisper_Lv3/modeling_whisper.py	/^_CONFIG_FOR_DOC = "WhisperConfig"$/;"	v
_HIDDEN_STATES_START_POSITION	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^_HIDDEN_STATES_START_POSITION = 1$/;"	v
__call__	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/data/text_mel_datamodule.py	/^    def __call__(self, batch):$/;"	m	class:TextMelBatchCollate
__del__	steer_moe/tokenizer/glm4/cosyvoice/dataset/processor.py	/^    def __del__(self):$/;"	m	class:MMTar
__getitem__	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/cli.py	/^    def __getitem__(self, idx):$/;"	m	class:BatchedSynthesisDataset
__getitem__	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/data/text_mel_datamodule.py	/^    def __getitem__(self, index):$/;"	m	class:TextMelDataset
__getitem__	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/hifigan/meldataset.py	/^    def __getitem__(self, index):$/;"	m	class:MelDataset
__init__	cross_modal_steer/cross_modal_steering.py	/^    def __init__(self, audio_dim: int, text_dim: int, adapter_dim: int = 512,$/;"	m	class:CrossModalAdapter
__init__	cross_modal_steer/cross_modal_steering.py	/^    def __init__(self, audio_dim: int, text_dim: int, hidden_dim: int = 1024, $/;"	m	class:CrossModalFeatureAligner
__init__	cross_modal_steer/cross_modal_steering.py	/^    def __init__(self, audio_dim: int, text_dim: int, num_experts: int = 8,$/;"	m	class:ModalitySpecificSteering
__init__	cross_modal_steer/cross_modal_steering.py	/^    def __init__(self, audio_dim: int, text_dim: int, num_stages: int = 3,$/;"	m	class:ProgressiveCrossModalSteering
__init__	cross_modal_steer/router_comparison.py	/^    def __init__(self, feature_dim: int, num_experts: int = 8):$/;"	m	class:CurrentRouter
__init__	cross_modal_steer/router_comparison.py	/^    def __init__(self, feature_dim: int, num_experts: int = 8, num_global_experts: int = 4):$/;"	m	class:HierarchicalRouter
__init__	cross_modal_steer/router_comparison.py	/^    def __init__(self, feature_dim: int, num_experts: int = 8, num_heads: int = 8):$/;"	m	class:AttentionBasedRouter
__init__	cross_modal_steer/router_comparison.py	/^    def __init__(self, feature_dim: int, num_experts: int = 8, num_stages: int = 3):$/;"	m	class:ProgressiveRouter
__init__	scripts/train_layer_wise.py	/^    def __init__(self, max_norm: float = 1.0):$/;"	m	class:GradientClippingCallback
__init__	scripts/train_layer_wise.py	/^    def __init__(self, model, log_interval: int = 100):$/;"	m	class:SteeringAnalysisCallback
__init__	steer_moe/al_models.py	/^    def __init__(self, encoder, decoder, encoder_dim, decoder_dim, use_adapter=True):$/;"	m	class:AudioToText
__init__	steer_moe/aligner.py	/^    def __init__(self, feature_dim, num_experts):$/;"	m	class:SteerMoEAligner
__init__	steer_moe/efficient_layer_wise_whisper.py	/^    def __init__(self, original_whisper_encoder, num_experts: int = 8, steering_scale: float = 0/;"	m	class:EfficientLayerWiseSteeringWhisperEncoder
__init__	steer_moe/efficient_layer_wise_whisper.py	/^    def __init__(self, original_whisper_encoder, num_experts: int = 8, steering_scale: float = 0/;"	m	class:SharedRouterLayerWiseSteeringWhisperEncoder
__init__	steer_moe/layer_wise_aligner.py	/^    def __init__(self, feature_dim: int, num_experts: int, num_layers: int = 32):$/;"	m	class:LayerWiseSteerMoEAligner
__init__	steer_moe/layer_wise_aligner.py	/^    def __init__(self, whisper_encoder, aligner: LayerWiseSteerMoEAligner):$/;"	m	class:WhisperEncoderWithSteering
__init__	steer_moe/layer_wise_whisper.py	/^    def __init__(self, original_whisper_encoder, num_experts: int = 8, steering_scale: float = 0/;"	m	class:LayerWiseSteeringWhisperEncoder
__init__	steer_moe/models.py	/^    def __init__(self, whisper_encoder, aligner, llm_decoder):$/;"	m	class:SteerMoEModel
__init__	steer_moe/models.py	/^    def __init__(self, whisper_encoder, aligner, llm_decoder, prompt_proj=None, $/;"	m	class:SteerMoEHybridModel
__init__	steer_moe/models.py	/^    def __init__(self, whisper_encoder_path, llm_decoder, num_experts=8, $/;"	m	class:SteerMoEEfficientLayerWiseModel
__init__	steer_moe/models.py	/^    def __init__(self, whisper_encoder_path, llm_decoder, num_experts=8, $/;"	m	class:SteerMoELayerWiseModel
__init__	steer_moe/shared_router_implementation.py	/^    def __init__(self, original_whisper_encoder, num_experts: int = 8, steering_scale: float = 0/;"	m	class:MultipleRoutersLayerWiseSteeringWhisperEncoder
__init__	steer_moe/shared_router_implementation.py	/^    def __init__(self, original_whisper_encoder, num_experts: int = 8, steering_scale: float = 0/;"	m	class:SharedRouterLayerWiseSteeringWhisperEncoder
__init__	steer_moe/tokenizer/glm4/audio_process.py	/^    def __init__(self, sr=22050, min_silence_duration=0.1, threshold_db=-40):$/;"	m	class:AudioStreamProcessor
__init__	steer_moe/tokenizer/glm4/cosyvoice/cli/cosyvoice.py	/^    def __init__(self, model_dir):$/;"	m	class:CosyVoice
__init__	steer_moe/tokenizer/glm4/cosyvoice/cli/frontend.py	/^    def __init__(self,$/;"	m	class:CosyVoiceFrontEnd
__init__	steer_moe/tokenizer/glm4/cosyvoice/cli/model.py	/^    def __init__(self,$/;"	m	class:CosyVoiceModel
__init__	steer_moe/tokenizer/glm4/cosyvoice/dataset/dataset.py	/^    def __init__(self, lists, shuffle=True, partition=True):$/;"	m	class:DataList
__init__	steer_moe/tokenizer/glm4/cosyvoice/dataset/dataset.py	/^    def __init__(self, shuffle=True, partition=True):$/;"	m	class:DistributedSampler
__init__	steer_moe/tokenizer/glm4/cosyvoice/dataset/dataset.py	/^    def __init__(self, source, f, *args, **kw):$/;"	m	class:Processor
__init__	steer_moe/tokenizer/glm4/cosyvoice/dataset/processor.py	/^    def __init__(self, file_path: Path | str):$/;"	m	class:MMTar
__init__	steer_moe/tokenizer/glm4/cosyvoice/dataset/processor.py	/^    def __init__(self, path: Path):$/;"	m	class:Tar
__init__	steer_moe/tokenizer/glm4/cosyvoice/flow/decoder.py	/^    def __init__($/;"	m	class:ConditionalDecoder
__init__	steer_moe/tokenizer/glm4/cosyvoice/flow/flow.py	/^    def __init__(self,$/;"	m	class:MaskedDiffWithXvec
__init__	steer_moe/tokenizer/glm4/cosyvoice/flow/flow_gradtts.py	/^    def __init__(self,$/;"	m	class:MaskedDiffWithXvec
__init__	steer_moe/tokenizer/glm4/cosyvoice/flow/flow_matching.py	/^    def __init__(self, in_channels, cfm_params, n_spks=1, spk_emb_dim=64, estimator: torch.nn.Mo/;"	m	class:ConditionalCFM
__init__	steer_moe/tokenizer/glm4/cosyvoice/flow/flow_matching_dit.py	/^    def __init__(self, in_channels, cfm_params, n_spks=1, spk_emb_dim=64, estimator: torch.nn.Mo/;"	m	class:ConditionalCFM
__init__	steer_moe/tokenizer/glm4/cosyvoice/flow/length_regulator.py	/^    def __init__($/;"	m	class:InterpolateRegulator
__init__	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^    def __init__($/;"	m	class:Attention
__init__	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^    def __init__($/;"	m	class:AttentionBase
__init__	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^    def __init__($/;"	m	class:BottleneckBlock1d
__init__	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^    def __init__($/;"	m	class:ConvBlock1d	typeref:typename:None
__init__	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^    def __init__($/;"	m	class:DownsampleBlock1d
__init__	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^    def __init__($/;"	m	class:MappingToScaleShift
__init__	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^    def __init__($/;"	m	class:NumberEmbedder
__init__	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^    def __init__($/;"	m	class:Patcher
__init__	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^    def __init__($/;"	m	class:ResnetBlock1d	typeref:typename:None
__init__	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^    def __init__($/;"	m	class:STFT
__init__	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^    def __init__($/;"	m	class:Transformer1d
__init__	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^    def __init__($/;"	m	class:TransformerBlock
__init__	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^    def __init__($/;"	m	class:UNet1d
__init__	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^    def __init__($/;"	m	class:UNetCFG1d
__init__	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^    def __init__($/;"	m	class:Unpatcher
__init__	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^    def __init__($/;"	m	class:UpsampleBlock1d
__init__	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^    def __init__(self, *args, **kwargs):$/;"	m	class:Conv1d
__init__	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^    def __init__(self, *args, **kwargs):$/;"	m	class:ConvTranspose1d
__init__	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^    def __init__(self, *args, **kwargs):$/;"	m	class:UNetAll1d
__init__	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^    def __init__(self, *modules):$/;"	m	class:ConditionedSequential
__init__	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^    def __init__(self, context_features: int, **kwargs):$/;"	m	class:UNetNCCA1d
__init__	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^    def __init__(self, dim: int):$/;"	m	class:LearnedPositionalEmbedding
__init__	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^    def __init__(self, dim: int):$/;"	m	class:SinusoidalEmbedding
__init__	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^    def __init__(self, max_length: int, features: int):$/;"	m	class:FixedEmbedding
__init__	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/blocks.py	/^    def __init__(self, *main):$/;"	m	class:SkipBlock
__init__	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/blocks.py	/^    def __init__(self, c_in, c_mid, c_out, is_last=False, kernel_size=5, conv_bias=True, use_sna/;"	m	class:ResConvBlock
__init__	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/blocks.py	/^    def __init__(self, c_in, n_head=1, dropout_rate=0.):$/;"	m	class:SelfAttention1d
__init__	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/blocks.py	/^    def __init__(self, features, cond_features, eps=1e-6):$/;"	m	class:AdaRMSNorm
__init__	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/blocks.py	/^    def __init__(self, in_channels, out_channels, kernel_size=1):$/;"	m	class:ForcedWNConv1d
__init__	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/blocks.py	/^    def __init__(self, in_features, alpha=1.0, alpha_trainable=True, alpha_logscale=True):$/;"	m	class:SnakeBeta
__init__	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/blocks.py	/^    def __init__(self, in_features, out_features, bias=True):$/;"	m	class:LinearGEGLU
__init__	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/blocks.py	/^    def __init__(self, in_features, out_features, std=1.):$/;"	m	class:FourierFeatures
__init__	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/blocks.py	/^    def __init__(self, kernel='linear', pad_mode='reflect', channels_last=False):$/;"	m	class:Downsample1d
__init__	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/blocks.py	/^    def __init__(self, kernel='linear', pad_mode='reflect', channels_last=False):$/;"	m	class:Upsample1d
__init__	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/blocks.py	/^    def __init__(self, main, skip=None):$/;"	m	class:ResidualBlock
__init__	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/blocks.py	/^    def __init__(self, shape, fix_scale = False, eps=1e-6):$/;"	m	class:RMSNorm
__init__	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/dit.py	/^    def __init__(self,$/;"	m	class:DiffusionTransformer
__init__	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/dit_v2.py	/^    def __init__(self,$/;"	m	class:DiffusionTransformerV2
__init__	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/stable_diffusion.py	/^    def __init__(self, io_channels, input_concat_dim=None, embed_dim=768, depth=24, num_heads=24/;"	m	class:Stable_Diffusion
__init__	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/stable_diffusion_test.py	/^    def __init__(self):$/;"	m	class:Stable_Diffusion
__init__	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer.py	/^    def __init__($/;"	m	class:Attention
__init__	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer.py	/^    def __init__($/;"	m	class:ConformerModule
__init__	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer.py	/^    def __init__($/;"	m	class:ContinuousTransformer
__init__	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer.py	/^    def __init__($/;"	m	class:FeedForward
__init__	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer.py	/^    def __init__($/;"	m	class:GLU
__init__	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer.py	/^    def __init__($/;"	m	class:RotaryEmbedding
__init__	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer.py	/^    def __init__($/;"	m	class:TransformerBlock
__init__	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer.py	/^    def __init__(self, dim, bias=False, fix_scale=False):$/;"	m	class:LayerNorm
__init__	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer.py	/^    def __init__(self, dim, max_seq_len):$/;"	m	class:AbsolutePositionalEmbedding
__init__	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer.py	/^    def __init__(self, dim, theta = 10000):$/;"	m	class:ScaledSinusoidalEmbedding
__init__	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer_use_mask.py	/^    def __init__($/;"	m	class:Attention
__init__	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer_use_mask.py	/^    def __init__($/;"	m	class:ConformerModule
__init__	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer_use_mask.py	/^    def __init__($/;"	m	class:ContinuousTransformer
__init__	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer_use_mask.py	/^    def __init__($/;"	m	class:FeedForward
__init__	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer_use_mask.py	/^    def __init__($/;"	m	class:GLU
__init__	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer_use_mask.py	/^    def __init__($/;"	m	class:RotaryEmbedding
__init__	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer_use_mask.py	/^    def __init__($/;"	m	class:TransformerBlock
__init__	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer_use_mask.py	/^    def __init__(self, dim, bias=False, fix_scale=False):$/;"	m	class:LayerNorm
__init__	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer_use_mask.py	/^    def __init__(self, dim, max_seq_len):$/;"	m	class:AbsolutePositionalEmbedding
__init__	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer_use_mask.py	/^    def __init__(self, dim, theta=10000):$/;"	m	class:ScaledSinusoidalEmbedding
__init__	steer_moe/tokenizer/glm4/cosyvoice/hifigan/f0_predictor.py	/^    def __init__(self,$/;"	m	class:ConvRNNF0Predictor
__init__	steer_moe/tokenizer/glm4/cosyvoice/hifigan/generator.py	/^    def __init__($/;"	m	class:HiFTGenerator
__init__	steer_moe/tokenizer/glm4/cosyvoice/hifigan/generator.py	/^    def __init__($/;"	m	class:ResBlock
__init__	steer_moe/tokenizer/glm4/cosyvoice/hifigan/generator.py	/^    def __init__(self, samp_rate, harmonic_num=0,$/;"	m	class:SineGen
__init__	steer_moe/tokenizer/glm4/cosyvoice/hifigan/generator.py	/^    def __init__(self, sampling_rate, upsample_scale, harmonic_num=0, sine_amp=0.1,$/;"	m	class:SourceModuleHnNSF
__init__	steer_moe/tokenizer/glm4/cosyvoice/llm/llm.py	/^    def __init__($/;"	m	class:TransformerLM
__init__	steer_moe/tokenizer/glm4/cosyvoice/transformer/activation.py	/^    def __init__(self, in_features, alpha=1.0, alpha_trainable=True, alpha_logscale=False):$/;"	m	class:Snake
__init__	steer_moe/tokenizer/glm4/cosyvoice/transformer/attention.py	/^    def __init__(self,$/;"	m	class:BlockRelPositionMultiHeadedAttention
__init__	steer_moe/tokenizer/glm4/cosyvoice/transformer/attention.py	/^    def __init__(self,$/;"	m	class:MultiHeadedAttention
__init__	steer_moe/tokenizer/glm4/cosyvoice/transformer/attention.py	/^    def __init__(self,$/;"	m	class:RelPositionMultiHeadedAttention
__init__	steer_moe/tokenizer/glm4/cosyvoice/transformer/convolution.py	/^    def __init__(self,$/;"	m	class:ConvolutionModule
__init__	steer_moe/tokenizer/glm4/cosyvoice/transformer/decoder.py	/^    def __init__($/;"	m	class:BiTransformerDecoder
__init__	steer_moe/tokenizer/glm4/cosyvoice/transformer/decoder.py	/^    def __init__($/;"	m	class:TransformerDecoder
__init__	steer_moe/tokenizer/glm4/cosyvoice/transformer/decoder_layer.py	/^    def __init__($/;"	m	class:DecoderLayer
__init__	steer_moe/tokenizer/glm4/cosyvoice/transformer/embedding.py	/^    def __init__(self, d_model, dropout_rate, max_len=5000):$/;"	m	class:EspnetRelPositionalEncoding
__init__	steer_moe/tokenizer/glm4/cosyvoice/transformer/embedding.py	/^    def __init__(self, d_model: int, dropout_rate: float):$/;"	m	class:NoPositionalEncoding
__init__	steer_moe/tokenizer/glm4/cosyvoice/transformer/embedding.py	/^    def __init__(self, d_model: int, dropout_rate: float, max_len: int = 1500):$/;"	m	class:WhisperPositionalEncoding
__init__	steer_moe/tokenizer/glm4/cosyvoice/transformer/embedding.py	/^    def __init__(self, d_model: int, dropout_rate: float, max_len: int = 448):$/;"	m	class:LearnablePositionalEncoding
__init__	steer_moe/tokenizer/glm4/cosyvoice/transformer/embedding.py	/^    def __init__(self, d_model: int, dropout_rate: float, max_len: int = 5000):$/;"	m	class:RelPositionalEncoding
__init__	steer_moe/tokenizer/glm4/cosyvoice/transformer/embedding.py	/^    def __init__(self,$/;"	m	class:PositionalEncoding
__init__	steer_moe/tokenizer/glm4/cosyvoice/transformer/encoder.py	/^    def __init__($/;"	m	class:BaseEncoder
__init__	steer_moe/tokenizer/glm4/cosyvoice/transformer/encoder.py	/^    def __init__($/;"	m	class:BlockConformerEncoder
__init__	steer_moe/tokenizer/glm4/cosyvoice/transformer/encoder.py	/^    def __init__($/;"	m	class:ConformerEncoder
__init__	steer_moe/tokenizer/glm4/cosyvoice/transformer/encoder.py	/^    def __init__($/;"	m	class:TransformerEncoder
__init__	steer_moe/tokenizer/glm4/cosyvoice/transformer/encoder_layer.py	/^    def __init__($/;"	m	class:ConformerEncoderLayer
__init__	steer_moe/tokenizer/glm4/cosyvoice/transformer/encoder_layer.py	/^    def __init__($/;"	m	class:TransformerEncoderLayer
__init__	steer_moe/tokenizer/glm4/cosyvoice/transformer/label_smoothing_loss.py	/^    def __init__(self,$/;"	m	class:LabelSmoothingLoss
__init__	steer_moe/tokenizer/glm4/cosyvoice/transformer/positionwise_feed_forward.py	/^    def __init__($/;"	m	class:MoEFFNLayer
__init__	steer_moe/tokenizer/glm4/cosyvoice/transformer/positionwise_feed_forward.py	/^    def __init__($/;"	m	class:PositionwiseFeedForward
__init__	steer_moe/tokenizer/glm4/cosyvoice/transformer/subsampling.py	/^    def __init__(self):$/;"	m	class:BaseSubsampling
__init__	steer_moe/tokenizer/glm4/cosyvoice/transformer/subsampling.py	/^    def __init__(self, idim: int, odim: int, dropout_rate: float,$/;"	m	class:Conv1dSubsampling2
__init__	steer_moe/tokenizer/glm4/cosyvoice/transformer/subsampling.py	/^    def __init__(self, idim: int, odim: int, dropout_rate: float,$/;"	m	class:Conv2dSubsampling4
__init__	steer_moe/tokenizer/glm4/cosyvoice/transformer/subsampling.py	/^    def __init__(self, idim: int, odim: int, dropout_rate: float,$/;"	m	class:Conv2dSubsampling6
__init__	steer_moe/tokenizer/glm4/cosyvoice/transformer/subsampling.py	/^    def __init__(self, idim: int, odim: int, dropout_rate: float,$/;"	m	class:Conv2dSubsampling8
__init__	steer_moe/tokenizer/glm4/cosyvoice/transformer/subsampling.py	/^    def __init__(self, idim: int, odim: int, dropout_rate: float,$/;"	m	class:EmbedinigNoSubsampling
__init__	steer_moe/tokenizer/glm4/cosyvoice/transformer/subsampling.py	/^    def __init__(self, idim: int, odim: int, dropout_rate: float,$/;"	m	class:LegacyLinearNoSubsampling
__init__	steer_moe/tokenizer/glm4/cosyvoice/transformer/subsampling.py	/^    def __init__(self, idim: int, odim: int, dropout_rate: float,$/;"	m	class:LinearNoSubsampling
__init__	steer_moe/tokenizer/glm4/cosyvoice/utils/executor.py	/^    def __init__(self):$/;"	m	class:Executor
__init__	steer_moe/tokenizer/glm4/cosyvoice/utils/scheduler.py	/^    def __init__($/;"	m	class:ConstantLR
__init__	steer_moe/tokenizer/glm4/cosyvoice/utils/scheduler.py	/^    def __init__($/;"	m	class:WarmupAnnealHoldPolicy
__init__	steer_moe/tokenizer/glm4/cosyvoice/utils/scheduler.py	/^    def __init__($/;"	m	class:WarmupHoldPolicy
__init__	steer_moe/tokenizer/glm4/cosyvoice/utils/scheduler.py	/^    def __init__($/;"	m	class:WarmupLR
__init__	steer_moe/tokenizer/glm4/cosyvoice/utils/scheduler.py	/^    def __init__(self,$/;"	m	class:CosineAnnealing
__init__	steer_moe/tokenizer/glm4/cosyvoice/utils/scheduler.py	/^    def __init__(self,$/;"	m	class:NoamAnnealing
__init__	steer_moe/tokenizer/glm4/cosyvoice/utils/scheduler.py	/^    def __init__(self,$/;"	m	class:NoamHoldAnnealing
__init__	steer_moe/tokenizer/glm4/cosyvoice/utils/scheduler.py	/^    def __init__(self,$/;"	m	class:SquareAnnealing
__init__	steer_moe/tokenizer/glm4/cosyvoice/utils/scheduler.py	/^    def __init__(self,$/;"	m	class:SquareRootAnnealing
__init__	steer_moe/tokenizer/glm4/cosyvoice/utils/scheduler.py	/^    def __init__(self,$/;"	m	class:SquareRootConstantPolicy
__init__	steer_moe/tokenizer/glm4/cosyvoice/utils/scheduler.py	/^    def __init__(self,$/;"	m	class:WarmupPolicy
__init__	steer_moe/tokenizer/glm4/flow_inference.py	/^    def __init__(self, config_path, flow_ckpt_path, hift_ckpt_path, device="cuda"):$/;"	m	class:AudioDecoder
__init__	steer_moe/tokenizer/glm4/model_server.py	/^    def __init__(self, model_path, dtype="bfloat16", device='cuda'):$/;"	m	class:ModelWorker
__init__	steer_moe/tokenizer/glm4/model_server.py	/^    def __init__(self, skip_prompt: bool = False, timeout=None):$/;"	m	class:TokenStreamer
__init__	steer_moe/tokenizer/glm4/speech_tokenizer/configuration_whisper.py	/^    def __init__(self,$/;"	m	class:WhisperVQConfig
__init__	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^    def __init__($/;"	m	class:CausalConv1d
__init__	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^    def __init__($/;"	m	class:WhisperAttention
__init__	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^    def __init__(self, *args, **kwargs):$/;"	m	class:WhisperFlashAttention2
__init__	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^    def __init__(self, config):$/;"	m	class:WhisperDecoderWrapper
__init__	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^    def __init__(self, config):$/;"	m	class:WhisperForAudioClassification
__init__	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^    def __init__(self, config):$/;"	m	class:WhisperForCausalLM
__init__	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^    def __init__(self, config: WhisperVQConfig):$/;"	m	class:WhisperVQDecoder
__init__	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^    def __init__(self, config: WhisperVQConfig):$/;"	m	class:WhisperVQEncoder
__init__	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^    def __init__(self, config: WhisperVQConfig):$/;"	m	class:WhisperVQForConditionalGeneration
__init__	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^    def __init__(self, config: WhisperVQConfig):$/;"	m	class:WhisperVQModel
__init__	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^    def __init__(self, config: WhisperVQConfig, is_causal=False):$/;"	m	class:WhisperVQEncoderLayer
__init__	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^    def __init__(self, config: WhisperVQConfig, layer_idx: int = None):$/;"	m	class:WhisperDecoderLayer
__init__	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^    def __init__(self, num_positions: int, embedding_dim: int, padding_idx: Optional[int] = None/;"	m	class:WhisperPositionalEmbedding
__init__	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/cli.py	/^    def __init__(self, processed_texts):$/;"	m	class:BatchedSynthesisDataset
__init__	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/data/text_mel_datamodule.py	/^    def __init__(  # pylint: disable=unused-argument$/;"	m	class:TextMelDataModule
__init__	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/data/text_mel_datamodule.py	/^    def __init__($/;"	m	class:TextMelDataset
__init__	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/data/text_mel_datamodule.py	/^    def __init__(self, n_spks):$/;"	m	class:TextMelBatchCollate
__init__	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/hifigan/denoiser.py	/^    def __init__(self, vocoder, filter_length=1024, n_overlap=4, win_length=1024, mode="zeros"):$/;"	m	class:Denoiser
__init__	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/hifigan/env.py	/^    def __init__(self, *args, **kwargs):$/;"	m	class:AttrDict
__init__	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/hifigan/meldataset.py	/^    def __init__($/;"	m	class:MelDataset
__init__	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/hifigan/models.py	/^    def __init__(self):$/;"	m	class:MultiPeriodDiscriminator
__init__	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/hifigan/models.py	/^    def __init__(self):$/;"	m	class:MultiScaleDiscriminator
__init__	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/hifigan/models.py	/^    def __init__(self, h):$/;"	m	class:Generator
__init__	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/hifigan/models.py	/^    def __init__(self, h, channels, kernel_size=3, dilation=(1, 3)):$/;"	m	class:ResBlock2
__init__	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/hifigan/models.py	/^    def __init__(self, h, channels, kernel_size=3, dilation=(1, 3, 5)):$/;"	m	class:ResBlock1
__init__	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/hifigan/models.py	/^    def __init__(self, period, kernel_size=5, stride=3, use_spectral_norm=False):$/;"	m	class:DiscriminatorP
__init__	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/hifigan/models.py	/^    def __init__(self, use_spectral_norm=False):$/;"	m	class:DiscriminatorS
__init__	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/components/decoder.py	/^    def __init__(  # pylint: disable=useless-super-delegation$/;"	m	class:ConformerWrapper
__init__	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/components/decoder.py	/^    def __init__($/;"	m	class:Decoder
__init__	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/components/decoder.py	/^    def __init__($/;"	m	class:TimestepEmbedding
__init__	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/components/decoder.py	/^    def __init__(self, channels, use_conv=False, use_conv_transpose=True, out_channels=None, nam/;"	m	class:Upsample1D
__init__	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/components/decoder.py	/^    def __init__(self, dim):$/;"	m	class:Downsample1D
__init__	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/components/decoder.py	/^    def __init__(self, dim):$/;"	m	class:SinusoidalPosEmb
__init__	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/components/decoder.py	/^    def __init__(self, dim, dim_out, groups=8):$/;"	m	class:Block1D
__init__	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/components/decoder.py	/^    def __init__(self, dim, dim_out, time_emb_dim, groups=8):$/;"	m	class:ResnetBlock1D
__init__	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/components/flow_matching.py	/^    def __init__($/;"	m	class:BASECFM
__init__	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/components/flow_matching.py	/^    def __init__(self, in_channels, out_channel, cfm_params, decoder_params, n_spks=1, spk_emb_d/;"	m	class:CFM
__init__	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/components/text_encoder.py	/^    def __init__($/;"	m	class:Encoder
__init__	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/components/text_encoder.py	/^    def __init__($/;"	m	class:MultiHeadAttention
__init__	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/components/text_encoder.py	/^    def __init__($/;"	m	class:TextEncoder
__init__	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/components/text_encoder.py	/^    def __init__(self, channels, eps=1e-4):$/;"	m	class:LayerNorm
__init__	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/components/text_encoder.py	/^    def __init__(self, d: int, base: int = 10_000):$/;"	m	class:RotaryPositionalEmbeddings
__init__	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/components/text_encoder.py	/^    def __init__(self, in_channels, filter_channels, kernel_size, p_dropout):$/;"	m	class:DurationPredictor
__init__	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/components/text_encoder.py	/^    def __init__(self, in_channels, hidden_channels, out_channels, kernel_size, n_layers, p_drop/;"	m	class:ConvReluNorm
__init__	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/components/text_encoder.py	/^    def __init__(self, in_channels, out_channels, filter_channels, kernel_size, p_dropout=0.0):$/;"	m	class:FFN
__init__	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/components/transformer.py	/^    def __init__($/;"	m	class:BasicTransformerBlock
__init__	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/components/transformer.py	/^    def __init__($/;"	m	class:FeedForward
__init__	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/components/transformer.py	/^    def __init__(self, in_features, out_features, alpha=1.0, alpha_trainable=True, alpha_logscal/;"	m	class:SnakeBeta
__init__	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/matcha_tts.py	/^    def __init__($/;"	m	class:MatchaTTS
__init__	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/onnx/export.py	/^    def __init__(self, matcha, vocoder):$/;"	m	class:MatchaWithVocoder
__init__	steer_moe/tokenizer/glm4_tokenizer.py	/^    def __init__(self, tokenizer_path):$/;"	m	class:Glm4Tokenizer
__init__	steer_moe/tokenizer/whisper_Lv3/modeling_whisper.py	/^    def __init__($/;"	m	class:WhisperAttention
__init__	steer_moe/tokenizer/whisper_Lv3/modeling_whisper.py	/^    def __init__($/;"	m	class:WhisperPositionalEmbedding
__init__	steer_moe/tokenizer/whisper_Lv3/modeling_whisper.py	/^    def __init__(self, config: WhisperConfig):$/;"	m	class:WhisperDecoder
__init__	steer_moe/tokenizer/whisper_Lv3/modeling_whisper.py	/^    def __init__(self, config: WhisperConfig):$/;"	m	class:WhisperDecoderLayer
__init__	steer_moe/tokenizer/whisper_Lv3/modeling_whisper.py	/^    def __init__(self, config: WhisperConfig):$/;"	m	class:WhisperEncoder
__init__	steer_moe/tokenizer/whisper_Lv3/modeling_whisper.py	/^    def __init__(self, config: WhisperConfig):$/;"	m	class:WhisperEncoderLayer
__init__	steer_moe/tokenizer/whisper_Lv3/modeling_whisper.py	/^    def __init__(self, config: WhisperConfig):$/;"	m	class:WhisperModel
__init__	steer_moe/tokenizer/whisper_Lv3/whisper.py	/^    def __init__($/;"	m	class:WhisperEncoder
__init__	whisper_train/main_word_correct_clips.py	/^    def __init__($/;"	m	class:Logged_Seq2SeqTrainer
__init__	whisper_train/main_word_correct_clips.py	/^    def __init__(self, dataset_paths, batch_size, total_size):$/;"	m	class:CustomDatasetIterator
__iter__	steer_moe/tokenizer/glm4/cosyvoice/dataset/dataset.py	/^    def __iter__(self):$/;"	m	class:DataList
__iter__	steer_moe/tokenizer/glm4/cosyvoice/dataset/dataset.py	/^    def __iter__(self):$/;"	m	class:Processor
__iter__	steer_moe/tokenizer/glm4/model_server.py	/^    def __iter__(self):$/;"	m	class:TokenStreamer
__iter__	whisper_train/main_word_correct_clips.py	/^    def __iter__(self):$/;"	m	class:CustomDatasetIterator
__len__	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/cli.py	/^    def __len__(self):$/;"	m	class:BatchedSynthesisDataset
__len__	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/data/text_mel_datamodule.py	/^    def __len__(self):$/;"	m	class:TextMelDataset
__len__	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/hifigan/meldataset.py	/^    def __len__(self):$/;"	m	class:MelDataset
__len__	whisper_train/main_word_correct_clips.py	/^    def __len__(self):$/;"	m	class:CustomDatasetIterator
__next__	steer_moe/tokenizer/glm4/model_server.py	/^    def __next__(self):$/;"	m	class:TokenStreamer
__next__	whisper_train/main_word_correct_clips.py	/^    def __next__(self):$/;"	m	class:CustomDatasetIterator
__repr__	steer_moe/tokenizer/glm4/cosyvoice/utils/scheduler.py	/^    def __repr__(self):$/;"	m	class:WarmupLR
_abbreviations	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/text/cleaners.py	/^_abbreviations = [$/;"	v
_attention_bias_proximal	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/components/text_encoder.py	/^    def _attention_bias_proximal(length):$/;"	m	class:MultiHeadAttention
_build_cache	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/components/text_encoder.py	/^    def _build_cache(self, x: torch.Tensor):$/;"	m	class:RotaryPositionalEmbeddings
_check_decoder_input_ids	steer_moe/tokenizer/glm4/speech_tokenizer/generation_whisper.py	/^    def _check_decoder_input_ids(kwargs):$/;"	m	class:WhisperGenerationMixin
_clean_text	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/text/__init__.py	/^def _clean_text(text, cleaner_names):$/;"	f
_comma_number_re	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/text/numbers.py	/^_comma_number_re = re.compile(r"([0-9][0-9\\,]+[0-9])")$/;"	v
_compute_mask_indices	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^def _compute_mask_indices($/;"	f	typeref:typename:np.ndarray
_compute_mask_indices	steer_moe/tokenizer/whisper_Lv3/modeling_whisper.py	/^def _compute_mask_indices($/;"	f	typeref:typename:np.ndarray
_cosine_annealing	steer_moe/tokenizer/glm4/cosyvoice/utils/scheduler.py	/^def _cosine_annealing(initial_lr, step, max_steps, min_lr):$/;"	f
_decimal_number_re	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/text/numbers.py	/^_decimal_number_re = re.compile(r"([0-9]+\\.[0-9]+)")$/;"	v
_dollars_re	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/text/numbers.py	/^_dollars_re = re.compile(r"\\$([0-9\\.\\,]*[0-9]+)")$/;"	v
_dynamic_time_warping	steer_moe/tokenizer/glm4/speech_tokenizer/generation_whisper.py	/^def _dynamic_time_warping(matrix: np.ndarray):$/;"	f
_expand_decimal_point	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/text/numbers.py	/^def _expand_decimal_point(m):$/;"	f
_expand_dollars	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/text/numbers.py	/^def _expand_dollars(m):$/;"	f
_expand_mask	steer_moe/tokenizer/whisper_Lv3/modeling_whisper.py	/^def _expand_mask(mask: torch.Tensor, dtype: torch.dtype, tgt_len: Optional[int] = None):$/;"	f
_expand_number	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/text/numbers.py	/^def _expand_number(m):$/;"	f
_expand_ordinal	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/text/numbers.py	/^def _expand_ordinal(m):$/;"	f
_expand_variables_for_generation	steer_moe/tokenizer/glm4/speech_tokenizer/generation_whisper.py	/^    def _expand_variables_for_generation($/;"	m	class:WhisperGenerationMixin
_extract_speech_feat	steer_moe/tokenizer/glm4/cosyvoice/cli/frontend.py	/^    def _extract_speech_feat(self, speech):$/;"	m	class:CosyVoiceFrontEnd
_extract_speech_token	steer_moe/tokenizer/glm4/cosyvoice/cli/frontend.py	/^    def _extract_speech_token(self, speech):$/;"	m	class:CosyVoiceFrontEnd
_extract_spk_embedding	steer_moe/tokenizer/glm4/cosyvoice/cli/frontend.py	/^    def _extract_spk_embedding(self, speech):$/;"	m	class:CosyVoiceFrontEnd
_extract_text_token	steer_moe/tokenizer/glm4/cosyvoice/cli/frontend.py	/^    def _extract_text_token(self, text):$/;"	m	class:CosyVoiceFrontEnd
_extract_token_timestamps	steer_moe/tokenizer/glm4/speech_tokenizer/generation_whisper.py	/^    def _extract_token_timestamps(self, generate_outputs, alignment_heads, time_precision=0.02, /;"	m	class:WhisperGenerationMixin
_f02source	steer_moe/tokenizer/glm4/cosyvoice/hifigan/generator.py	/^    def _f02source(self, f0: torch.Tensor) -> torch.Tensor:$/;"	m	class:HiFTGenerator	typeref:typename:torch.Tensor
_f02uv	steer_moe/tokenizer/glm4/cosyvoice/hifigan/generator.py	/^    def _f02uv(self, f0):$/;"	m	class:SineGen
_find_silence_boundary	steer_moe/tokenizer/glm4/audio_process.py	/^    def _find_silence_boundary(self, audio):$/;"	m	class:AudioStreamProcessor
_find_silence_end	steer_moe/tokenizer/glm4/audio_process.py	/^    def _find_silence_end(self, start_point):$/;"	m	class:AudioStreamProcessor
_forward	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/dit.py	/^    def _forward($/;"	m	class:DiffusionTransformer
_forward	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/dit_v2.py	/^    def _forward($/;"	m	class:DiffusionTransformerV2
_freeze_parameters	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^    def _freeze_parameters(self):$/;"	m	class:WhisperVQEncoder
_freeze_parameters	steer_moe/tokenizer/whisper_Lv3/modeling_whisper.py	/^    def _freeze_parameters(self):$/;"	m	class:WhisperEncoder
_generated_methods	tmpx07ntkc2/_remote_module_non_scriptable.py	/^_generated_methods = [$/;"	v
_get_attr_from_logit_processors	steer_moe/tokenizer/glm4/speech_tokenizer/generation_whisper.py	/^def _get_attr_from_logit_processors(logits_processor, logit_processor_class, attribute_name):$/;"	f
_get_constant_lr	steer_moe/tokenizer/glm4/cosyvoice/utils/scheduler.py	/^    def _get_constant_lr(self, step):$/;"	m	class:CosineAnnealing
_get_constant_lr	steer_moe/tokenizer/glm4/cosyvoice/utils/scheduler.py	/^    def _get_constant_lr(self, step):$/;"	m	class:WarmupAnnealHoldPolicy
_get_feat_extract_output_lengths	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^    def _get_feat_extract_output_lengths(self, input_lengths: torch.LongTensor):$/;"	m	class:WhisperPreTrainedModel
_get_feat_extract_output_lengths	steer_moe/tokenizer/whisper_Lv3/modeling_whisper.py	/^    def _get_feat_extract_output_lengths(self, input_lengths: torch.LongTensor):$/;"	m	class:WhisperPreTrainedModel
_get_input_segment	steer_moe/tokenizer/glm4/speech_tokenizer/generation_whisper.py	/^    def _get_input_segment(input_features, seek, seek_num_frames, num_segment_frames, cur_bsz, b/;"	m	class:WhisperGenerationMixin
_get_layers	steer_moe/efficient_layer_wise_whisper.py	/^def _get_layers(encoder):$/;"	f
_get_linear_warmup_with_cosine_annealing_lr	steer_moe/tokenizer/glm4/cosyvoice/utils/scheduler.py	/^    def _get_linear_warmup_with_cosine_annealing_lr(self, step):$/;"	m	class:CosineAnnealing
_get_lr	steer_moe/tokenizer/glm4/cosyvoice/utils/scheduler.py	/^    def _get_lr(self, step):$/;"	m	class:CosineAnnealing
_get_lr	steer_moe/tokenizer/glm4/cosyvoice/utils/scheduler.py	/^    def _get_lr(self, step):$/;"	m	class:NoamHoldAnnealing
_get_lr	steer_moe/tokenizer/glm4/cosyvoice/utils/scheduler.py	/^    def _get_lr(self, step):$/;"	m	class:SquareAnnealing
_get_lr	steer_moe/tokenizer/glm4/cosyvoice/utils/scheduler.py	/^    def _get_lr(self, step):$/;"	m	class:SquareRootAnnealing
_get_lr	steer_moe/tokenizer/glm4/cosyvoice/utils/scheduler.py	/^    def _get_lr(self, step):$/;"	m	class:SquareRootConstantPolicy
_get_lr	steer_moe/tokenizer/glm4/cosyvoice/utils/scheduler.py	/^    def _get_lr(self, step):$/;"	m	class:WarmupAnnealHoldPolicy
_get_lr	steer_moe/tokenizer/glm4/cosyvoice/utils/scheduler.py	/^    def _get_lr(self, step):$/;"	m	class:WarmupPolicy
_get_num_layers	steer_moe/efficient_layer_wise_whisper.py	/^def _get_num_layers(encoder):$/;"	f
_get_warmup_lr	steer_moe/tokenizer/glm4/cosyvoice/utils/scheduler.py	/^    def _get_warmup_lr(self, step):$/;"	m	class:CosineAnnealing
_get_warmup_lr	steer_moe/tokenizer/glm4/cosyvoice/utils/scheduler.py	/^    def _get_warmup_lr(self, step):$/;"	m	class:WarmupAnnealHoldPolicy
_get_warmup_lr	steer_moe/tokenizer/glm4/cosyvoice/utils/scheduler.py	/^    def _get_warmup_lr(self, step):$/;"	m	class:WarmupPolicy
_id_to_symbol	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/text/__init__.py	/^_id_to_symbol = {i: s for i, s in enumerate(symbols)}  # pylint: disable=unnecessary-comprehensi/;"	v
_inflect	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/text/numbers.py	/^_inflect = inflect.engine()$/;"	v
_init_weights	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^    def _init_weights(self, module):$/;"	m	class:WhisperPreTrainedModel
_init_weights	steer_moe/tokenizer/whisper_Lv3/modeling_whisper.py	/^    def _init_weights(self, module):$/;"	m	class:WhisperPreTrainedModel
_istft	steer_moe/tokenizer/glm4/cosyvoice/hifigan/generator.py	/^    def _istft(self, magnitude, phase):$/;"	m	class:HiFTGenerator
_kernels	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/blocks.py	/^_kernels = {$/;"	v
_keys_to_ignore_on_load_missing	steer_moe/tokenizer/whisper_Lv3/modeling_whisper.py	/^    _keys_to_ignore_on_load_missing = [r"proj_out.weight"]$/;"	v	class:WhisperModel
_letters	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/text/symbols.py	/^_letters = "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz"$/;"	v
_letters_ipa	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/text/symbols.py	/^_letters_ipa = ($/;"	v
_linear_warmup_with_cosine_annealing	steer_moe/tokenizer/glm4/cosyvoice/utils/scheduler.py	/^def _linear_warmup_with_cosine_annealing(max_lr, warmup_steps, step,$/;"	f
_log_steering_analysis	scripts/train_layer_wise.py	/^    def _log_steering_analysis(self):$/;"	m	class:SteeringAnalysisCallback
_make_causal_mask	steer_moe/tokenizer/whisper_Lv3/modeling_whisper.py	/^def _make_causal_mask($/;"	f
_mask_input_features	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^    def _mask_input_features($/;"	m	class:WhisperVQModel
_mask_input_features	steer_moe/tokenizer/whisper_Lv3/modeling_whisper.py	/^    def _mask_input_features($/;"	m	class:WhisperModel
_maybe_reduce_batch	steer_moe/tokenizer/glm4/speech_tokenizer/generation_whisper.py	/^    def _maybe_reduce_batch(input_features, seek, max_frames, cur_bsz, batch_idx_map):$/;"	m	class:WhisperGenerationMixin
_maybe_warn_unused_inputs	steer_moe/tokenizer/glm4/speech_tokenizer/generation_whisper.py	/^    def _maybe_warn_unused_inputs($/;"	m	class:WhisperGenerationMixin
_median_filter	steer_moe/tokenizer/glm4/speech_tokenizer/generation_whisper.py	/^def _median_filter(inputs: torch.Tensor, filter_width: int) -> torch.Tensor:$/;"	f	typeref:typename:torch.Tensor
_need_fallback	steer_moe/tokenizer/glm4/speech_tokenizer/generation_whisper.py	/^    def _need_fallback($/;"	m	class:WhisperGenerationMixin
_neg_half	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/components/text_encoder.py	/^    def _neg_half(self, x: torch.Tensor):$/;"	m	class:RotaryPositionalEmbeddings
_no_split_modules	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^    _no_split_modules = ["WhisperEncoderLayer", "WhisperDecoderLayer"]$/;"	v	class:WhisperPreTrainedModel
_no_split_modules	steer_moe/tokenizer/whisper_Lv3/modeling_whisper.py	/^    _no_split_modules = ["WhisperEncoderLayer", "WhisperDecoderLayer"]$/;"	v	class:WhisperPreTrainedModel
_noam_annealing	steer_moe/tokenizer/glm4/cosyvoice/utils/scheduler.py	/^    def _noam_annealing(self, initial_lr, step):$/;"	m	class:NoamAnnealing
_noam_hold_annealing	steer_moe/tokenizer/glm4/cosyvoice/utils/scheduler.py	/^def _noam_hold_annealing(initial_lr, step, warmup_steps, hold_steps,$/;"	f
_number_re	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/text/numbers.py	/^_number_re = re.compile(r"[0-9]+")$/;"	v
_ordinal_re	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/text/numbers.py	/^_ordinal_re = re.compile(r"[0-9]+(st|nd|rd|th)")$/;"	v
_pad	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/text/symbols.py	/^_pad = "_"$/;"	v
_pad_tensors_to_max_len	whisper_train/main_word_correct_clips.py	/^    def _pad_tensors_to_max_len(self, tensor, max_length):$/;"	m	class:Logged_Seq2SeqTrainer
_pad_to_max_length	steer_moe/tokenizer/glm4/speech_tokenizer/generation_whisper.py	/^def _pad_to_max_length($/;"	f
_poly_decay	steer_moe/tokenizer/glm4/cosyvoice/utils/scheduler.py	/^def _poly_decay(initial_lr, step, decay_steps, power, min_lr, cycle):$/;"	f
_postprocess_outputs	steer_moe/tokenizer/glm4/speech_tokenizer/generation_whisper.py	/^    def _postprocess_outputs($/;"	m	class:WhisperGenerationMixin
_pounds_re	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/text/numbers.py	/^_pounds_re = re.compile(r"¬£([0-9\\,]*[0-9]+)")$/;"	v
_prepare	scripts/train.py	/^    def _prepare(batch):$/;"	f	function:prepare_asr_dataset	file:
_prepare	scripts/train.py	/^    def _prepare(batch):$/;"	f	function:train_with_deepspeed	file:
_prepare	scripts/train_layer_wise.py	/^    def _prepare(batch):$/;"	f	function:prepare_asr_dataset	file:
_prepare_4d_causal_attention_mask_with_cache_position	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^def _prepare_4d_causal_attention_mask_with_cache_position($/;"	f
_prepare_decoder_attention_mask	steer_moe/tokenizer/whisper_Lv3/modeling_whisper.py	/^    def _prepare_decoder_attention_mask($/;"	m	class:WhisperDecoder
_prepare_decoder_input_ids	steer_moe/tokenizer/glm4/speech_tokenizer/generation_whisper.py	/^    def _prepare_decoder_input_ids($/;"	m	class:WhisperGenerationMixin
_prepare_segments	steer_moe/tokenizer/glm4/speech_tokenizer/generation_whisper.py	/^    def _prepare_segments(prompt_ids, batch_size, generation_config):$/;"	m	class:WhisperGenerationMixin
_punctuation	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/text/symbols.py	/^_punctuation = ';:,.!?¬°¬ø‚Äî‚Ä¶"¬´¬ª‚Äú‚Äù '$/;"	v
_remote_forward	tmpx07ntkc2/_remote_module_non_scriptable.py	/^def _remote_forward($/;"	f
_remove_commas	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/text/numbers.py	/^def _remove_commas(m):$/;"	f
_reorder_cache	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^    def _reorder_cache(past_key_values, beam_idx):$/;"	m	class:WhisperForCausalLM
_resample_buffer	steer_moe/tokenizer/glm4/speech_tokenizer/utils.py	/^_resample_buffer: dict[int, torchaudio.transforms.Resample] = {}$/;"	v	typeref:typename:dict[int, torchaudio.transforms.Resample]
_retrieve_avg_logprobs	steer_moe/tokenizer/glm4/speech_tokenizer/generation_whisper.py	/^    def _retrieve_avg_logprobs(scores, tokens, eos_token_id, temperature):$/;"	m	class:WhisperGenerationMixin
_retrieve_compression_ratio	steer_moe/tokenizer/glm4/speech_tokenizer/generation_whisper.py	/^    def _retrieve_compression_ratio(tokens, vocab_size):$/;"	m	class:WhisperGenerationMixin
_retrieve_init_tokens	steer_moe/tokenizer/glm4/speech_tokenizer/generation_whisper.py	/^    def _retrieve_init_tokens(self, input_features, batch_size, generation_config, config, num_s/;"	m	class:WhisperGenerationMixin
_retrieve_init_tokens	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^    def _retrieve_init_tokens(self, input_features, batch_size, generation_config, config, num_s/;"	m	class:WhisperVQForConditionalGeneration
_retrieve_logit_processors	steer_moe/tokenizer/glm4/speech_tokenizer/generation_whisper.py	/^    def _retrieve_logit_processors(self, generation_config, logits_processor, begin_index, num_b/;"	m	class:WhisperGenerationMixin
_retrieve_max_frames_and_seek	steer_moe/tokenizer/glm4/speech_tokenizer/generation_whisper.py	/^    def _retrieve_max_frames_and_seek(batch_size, attention_mask, total_input_frames, is_shortfo/;"	m	class:WhisperGenerationMixin
_retrieve_segment	steer_moe/tokenizer/glm4/speech_tokenizer/generation_whisper.py	/^    def _retrieve_segment($/;"	m	class:WhisperGenerationMixin
_retrieve_total_input_frames	steer_moe/tokenizer/glm4/speech_tokenizer/generation_whisper.py	/^    def _retrieve_total_input_frames(input_features, input_stride, kwargs):$/;"	m	class:WhisperGenerationMixin
_set_condition_on_prev_tokens	steer_moe/tokenizer/glm4/speech_tokenizer/generation_whisper.py	/^    def _set_condition_on_prev_tokens(condition_on_prev_tokens, generation_config):$/;"	m	class:WhisperGenerationMixin
_set_gradient_checkpointing	steer_moe/tokenizer/whisper_Lv3/modeling_whisper.py	/^    def _set_gradient_checkpointing(self, module, value=False):$/;"	m	class:WhisperPreTrainedModel
_set_language_and_task	steer_moe/tokenizer/glm4/speech_tokenizer/generation_whisper.py	/^    def _set_language_and_task(language, task, is_multilingual, generation_config):$/;"	m	class:WhisperGenerationMixin
_set_max_new_tokens_and_length	steer_moe/tokenizer/glm4/speech_tokenizer/generation_whisper.py	/^    def _set_max_new_tokens_and_length(self, config, decoder_input_ids, generation_config):$/;"	m	class:WhisperGenerationMixin
_set_num_frames	steer_moe/tokenizer/glm4/speech_tokenizer/generation_whisper.py	/^    def _set_num_frames(return_token_timestamps, generation_config, kwargs):$/;"	m	class:WhisperGenerationMixin
_set_prompt_condition_type	steer_moe/tokenizer/glm4/speech_tokenizer/generation_whisper.py	/^    def _set_prompt_condition_type(generation_config, prompt_condition_type):$/;"	m	class:WhisperGenerationMixin
_set_return_outputs	steer_moe/tokenizer/glm4/speech_tokenizer/generation_whisper.py	/^    def _set_return_outputs(return_dict_in_generate, return_token_timestamps, logprob_threshold,/;"	m	class:WhisperGenerationMixin
_set_return_timestamps	steer_moe/tokenizer/glm4/speech_tokenizer/generation_whisper.py	/^    def _set_return_timestamps(self, return_timestamps, is_shortform, generation_config):$/;"	m	class:WhisperGenerationMixin
_set_thresholds_and_condition	steer_moe/tokenizer/glm4/speech_tokenizer/generation_whisper.py	/^    def _set_thresholds_and_condition($/;"	m	class:WhisperGenerationMixin
_setup_no_speech_detection	steer_moe/tokenizer/glm4/speech_tokenizer/generation_whisper.py	/^    def _setup_no_speech_detection(logits_processor, segment_input, decoder_input_ids, kwargs):$/;"	m	class:WhisperGenerationMixin
_shape	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^    def _shape(self, tensor: torch.Tensor, seq_len: int, bsz: int):$/;"	m	class:WhisperAttention
_shape	steer_moe/tokenizer/whisper_Lv3/modeling_whisper.py	/^    def _shape(self, tensor: torch.Tensor, seq_len: int, bsz: int):$/;"	m	class:WhisperAttention
_square_annealing	steer_moe/tokenizer/glm4/cosyvoice/utils/scheduler.py	/^def _square_annealing(initial_lr, step, max_steps, min_lr):$/;"	f
_squareroot_annealing	steer_moe/tokenizer/glm4/cosyvoice/utils/scheduler.py	/^def _squareroot_annealing(initial_lr, step, max_steps, min_lr):$/;"	f
_stack_split_outputs	steer_moe/tokenizer/glm4/speech_tokenizer/generation_whisper.py	/^    def _stack_split_outputs(self, seek_outputs, model_output_type, device, kwargs):$/;"	m	class:WhisperGenerationMixin
_stft	steer_moe/tokenizer/glm4/cosyvoice/hifigan/generator.py	/^    def _stft(self, x):$/;"	m	class:HiFTGenerator
_supports_cache_class	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^    _supports_cache_class = True$/;"	v	class:WhisperPreTrainedModel
_supports_flash_attn_2	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^    _supports_flash_attn_2 = True$/;"	v	class:WhisperPreTrainedModel
_supports_sdpa	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^    _supports_sdpa = True$/;"	v	class:WhisperPreTrainedModel
_supports_static_cache	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^    _supports_static_cache = True$/;"	v	class:WhisperPreTrainedModel
_symbol_to_id	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/text/__init__.py	/^_symbol_to_id = {s: i for i, s in enumerate(symbols)}$/;"	v
_tied_weights_keys	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^    _tied_weights_keys = ["proj_out.weight"]$/;"	v	class:WhisperForCausalLM
_tied_weights_keys	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^    _tied_weights_keys = ["proj_out.weight"]$/;"	v	class:WhisperVQForConditionalGeneration
_to_wav_bytes	steer_moe/tokenizer/glm4/audio_process.py	/^    def _to_wav_bytes(self, audio_data):$/;"	m	class:AudioStreamProcessor
_update_causal_mask	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^    def _update_causal_mask($/;"	m	class:WhisperVQDecoder
_whitespace_re	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/text/cleaners.py	/^_whitespace_re = re.compile(r"\\s+")$/;"	v
abs_audio_filename	whisper_train/generate_raw_parquet_multi_processing_word.py	/^            abs_audio_filename = os.path.join(tmp_file_path,$/;"	v
abs_json_filename	whisper_train/generate_raw_parquet_multi_processing_word.py	/^            abs_json_filename = os.path.join(tmp_file_path,$/;"	v
accelerate_version	whisper_train/main_word_correct_clips.py	/^    from accelerate import __version__ as accelerate_version$/;"	x	nameref:unknown:__version__
add_mask	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^def add_mask(sim: Tensor, mask: Tensor) -> Tensor:$/;"	f	typeref:typename:Tensor
add_optional_chunk_mask	steer_moe/tokenizer/glm4/cosyvoice/utils/mask.py	/^def add_optional_chunk_mask(xs: torch.Tensor,$/;"	f
add_skip	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^    def add_skip(self, x: Tensor, skip: Tensor) -> Tensor:$/;"	m	class:UpsampleBlock1d	typeref:typename:Tensor
allgather_bucket_size	configs/stage2.json	/^    "allgather_bucket_size": 2e8,$/;"	n	object:zero_optimization
allgather_partitions	configs/stage2.json	/^    "allgather_partitions": true,$/;"	b	object:zero_optimization
alpha_sigma_to_t	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/sampling.py	/^def alpha_sigma_to_t(alpha, sigma):$/;"	f
analyze_layer_wise_vs_post_encoder	steer_moe/layer_wise_whisper.py	/^def analyze_layer_wise_vs_post_encoder():$/;"	f
analyze_routing_patterns	cross_modal_steer/router_comparison.py	/^def analyze_routing_patterns():$/;"	f
analyze_steering_patterns	scripts/train_layer_wise.py	/^def analyze_steering_patterns(model_path: str):$/;"	f
app	steer_moe/tokenizer/glm4/model_server.py	/^app = FastAPI()$/;"	v
apply	steer_moe/tokenizer/glm4/cosyvoice/dataset/dataset.py	/^    def apply(self, f):$/;"	m	class:Processor
apply_rotary_pos_emb	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer.py	/^def apply_rotary_pos_emb(t, freqs, scale = 1):$/;"	f
apply_rotary_pos_emb	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer_use_mask.py	/^def apply_rotary_pos_emb(t, freqs, scale=1):$/;"	f
apply_weight_norm	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/hifigan/xutils.py	/^def apply_weight_norm(m):$/;"	f
args	scripts/batch_infer.py	/^    args = parser.parse_args()$/;"	v
args	scripts/train_layer_wise.py	/^    args = parser.parse_args()$/;"	v
args	steer_moe/tokenizer/glm4/model_server.py	/^    args = parser.parse_args()$/;"	v
args	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/app.py	/^args = Namespace($/;"	v
args	steer_moe/tokenizer/glm4/web_demo.py	/^    args = parser.parse_args()$/;"	v
args	whisper_train/generate_raw_parquet_multi_processing_word.py	/^    args = parser.parse_args()$/;"	v
args	whisper_train/main_word_correct_clips.py	/^    args = parser.parse_args()$/;"	v
args	whisper_train/pre_process_word_correct_data.py	/^    args = parser.parse_args()$/;"	v
assert_model_downloaded	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/utils/utils.py	/^def assert_model_downloaded(checkpoint_path, url, use_wget=True):$/;"	f
assert_required_models_available	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/cli.py	/^def assert_required_models_available(args):$/;"	f
attention	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/components/text_encoder.py	/^    def attention(self, query, key, value, mask=None):$/;"	m	class:MultiHeadAttention
audio	steer_moe/tokenizer/glm4/web_demo.py	/^                audio = gr.Audio(label="Input audio", type='filepath', show_download_button=True/;"	v
audio_decoder	steer_moe/tokenizer/glm4/web_demo.py	/^    audio_decoder: AudioDecoder = None$/;"	v	typeref:typename:AudioDecoder
audio_files	whisper_train/generate_raw_parquet_multi_processing_word.py	/^    audio_files = []$/;"	v
audio_token_pattern	steer_moe/tokenizer/glm4/web_demo.py	/^audio_token_pattern = re.compile(r"<\\|audio_(\\d+)\\|>")$/;"	v
base_model_prefix	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^    base_model_prefix = "model"$/;"	v	class:WhisperPreTrainedModel
base_model_prefix	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^    base_model_prefix = "model"$/;"	v	class:WhisperVQForConditionalGeneration
base_model_prefix	steer_moe/tokenizer/whisper_Lv3/modeling_whisper.py	/^    base_model_prefix = "model"$/;"	v	class:WhisperPreTrainedModel
basic_cleaners	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/text/cleaners.py	/^def basic_cleaners(text):$/;"	f
batch	steer_moe/tokenizer/glm4/cosyvoice/dataset/processor.py	/^def batch(data, batch_type='static', batch_size=16, max_frames_in_batch=12000, mode='train'):$/;"	f
batch	whisper_train/pre_process_word_correct_data.py	/^        batch = [os.path.join(ori_parquet_dir,file) for file in batch]$/;"	v
batch	whisper_train/pre_process_word_correct_data.py	/^        batch = train_files[i:i+batch_size]$/;"	v
batch_backward	steer_moe/tokenizer/glm4/cosyvoice/utils/train_utils.py	/^def batch_backward(model, info_dict):$/;"	f
batch_dict	whisper_train/generate_raw_parquet_multi_processing_word.py	/^    batch_dict = defaultdict(list)$/;"	v
batch_forward	steer_moe/tokenizer/glm4/cosyvoice/utils/train_utils.py	/^def batch_forward(model, batch, info_dict):$/;"	f
batch_infer	scripts/batch_infer.py	/^def batch_infer($/;"	f
batch_size	whisper_train/pre_process_word_correct_data.py	/^    batch_size=10$/;"	v
batch_tag	whisper_train/generate_raw_parquet_multi_processing_word.py	/^        batch_tag = args.batch_tag$/;"	v
batch_tag	whisper_train/main_word_correct_clips.py	/^        batch_tag=args.batch_tag$/;"	v
batch_tag	whisper_train/pre_process_word_correct_data.py	/^        batch_tag=args.batch_tag$/;"	v
batch_tags	whisper_train/main_word_correct_clips.py	/^    batch_tags=[batch_tag]$/;"	v
batched_collate_fn	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/cli.py	/^def batched_collate_fn(batch):$/;"	f
batched_synthesis	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/cli.py	/^def batched_synthesis(args, device, model, vocoder, denoiser, texts, spk):$/;"	f
betas	configs/stage3.json	/^      "betas": "auto",$/;"	s	object:optimizer.params
betas	configs/stage3_wo_offload.json	/^      "betas": "auto",$/;"	s	object:optimizer.params
bf16	configs/stage3.json	/^  "bf16": {$/;"	o
build_env	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/hifigan/env.py	/^def build_env(config, config_name, path):$/;"	f
calc_utt_length	steer_moe/tokenizer/glm4/cosyvoice/utils/frontend_utils.py	/^    def calc_utt_length(_text: str):$/;"	f	function:split_paragraph	file:
causal_mask	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^def causal_mask(q: Tensor, k: Tensor) -> Tensor:$/;"	f	typeref:typename:Tensor
chatbot	steer_moe/tokenizer/glm4/web_demo.py	/^        chatbot = gr.Chatbot($/;"	v
check_modify_and_save_config	steer_moe/tokenizer/glm4/cosyvoice/utils/train_utils.py	/^def check_modify_and_save_config(args, configs):$/;"	f
checkpoint	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer.py	/^def checkpoint(function, *args, **kwargs):$/;"	f
checkpoint	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer_use_mask.py	/^def checkpoint(function, *args, **kwargs):$/;"	f
chinese_char_pattern	steer_moe/tokenizer/glm4/cosyvoice/utils/frontend_utils.py	/^chinese_char_pattern = re.compile(r'[\\u4e00-\\u9fff]+')$/;"	v
ckpt	steer_moe/tokenizer/glm4/cosyvoice/transformer/decoder.py	/^import torch.utils.checkpoint as ckpt$/;"	I	nameref:module:torch.utils.checkpoint
ckpt	steer_moe/tokenizer/glm4/cosyvoice/transformer/encoder.py	/^import torch.utils.checkpoint as ckpt$/;"	I	nameref:module:torch.utils.checkpoint
clean	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/Makefile	/^clean: ## Clean autogenerated files$/;"	t
clean-logs	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/Makefile	/^clean-logs: ## Clean logs$/;"	t
cleaned_text_to_sequence	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/text/__init__.py	/^def cleaned_text_to_sequence(cleaned_text):$/;"	f
clear_fn	steer_moe/tokenizer/glm4/web_demo.py	/^    def clear_fn():$/;"	f
cli	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/cli.py	/^def cli():$/;"	f
closest_power_2	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^def closest_power_2(x: float) -> int:$/;"	f	typeref:typename:int
collapse_whitespace	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/text/cleaners.py	/^def collapse_whitespace(text):$/;"	f
compare_cross_modal_approaches	cross_modal_steer/cross_modal_steering.py	/^def compare_cross_modal_approaches():$/;"	f
compare_implementations	steer_moe/layer_wise_aligner.py	/^def compare_implementations():$/;"	f
compare_router_approaches	steer_moe/efficient_layer_wise_whisper.py	/^def compare_router_approaches():$/;"	f
compare_router_approaches_detailed	steer_moe/shared_router_implementation.py	/^def compare_router_approaches_detailed():$/;"	f
compare_router_implementations	cross_modal_steer/router_comparison.py	/^def compare_router_implementations():$/;"	f
compile	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/blocks.py	/^def compile(function, *args, **kwargs):$/;"	f
complete_audio	steer_moe/tokenizer/glm4/web_demo.py	/^                complete_audio = gr.Audio(label="Last Output Audio (If Any)", show_download_butt/;"	v
completion_tokens	steer_moe/tokenizer/glm4/web_demo.py	/^            completion_tokens = gr.Textbox($/;"	v
compute_data_statistics	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/utils/generate_data_statistics.py	/^def compute_data_statistics(data_loader: torch.utils.data.DataLoader, out_channels: int):$/;"	f
compute_fbank	steer_moe/tokenizer/glm4/cosyvoice/dataset/processor.py	/^def compute_fbank(data,$/;"	f
compute_loss	steer_moe/tokenizer/glm4/cosyvoice/flow/flow_matching.py	/^    def compute_loss(self, x1, mask, mu, spks=None, cond=None):$/;"	m	class:ConditionalCFM
compute_loss	steer_moe/tokenizer/glm4/cosyvoice/flow/flow_matching_dit.py	/^    def compute_loss(self, x1, mask, mu, spks=None, cond=None):$/;"	m	class:ConditionalCFM
compute_loss	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/stable_diffusion.py	/^    def compute_loss(self, x0, mask, mu):$/;"	m	class:Stable_Diffusion
compute_loss	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/stable_diffusion_test.py	/^    def compute_loss(self, x0, mask, mu):$/;"	m	class:Stable_Diffusion
compute_loss	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/components/flow_matching.py	/^    def compute_loss(self, x1, mask, mu, spks=None, cond=None):$/;"	m	class:BASECFM
compute_metrics	scripts/train.py	/^def compute_metrics(pred):$/;"	f
compute_metrics	scripts/train_layer_wise.py	/^def compute_metrics(pred):$/;"	f
compute_metrics_trainer	scripts/train.py	/^    def compute_metrics_trainer(eval_pred):$/;"	f	function:train_with_deepspeed	file:
compute_metrics_trainer	scripts/train_layer_wise.py	/^    def compute_metrics_trainer(eval_pred):$/;"	f	function:train_layer_wise_steermoe	file:
compute_num_masked_span	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^    def compute_num_masked_span(input_length):$/;"	f	function:_compute_mask_indices	file:
compute_num_masked_span	steer_moe/tokenizer/whisper_Lv3/modeling_whisper.py	/^    def compute_num_masked_span(input_length):$/;"	f	function:_compute_mask_indices	file:
cond_model_fn	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/sampling.py	/^    def cond_model_fn(x, sigma, **kwargs):$/;"	f	function:make_cond_model_fn	file:
config_class	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^    config_class = WhisperVQConfig$/;"	v	class:WhisperPreTrainedModel
config_class	steer_moe/tokenizer/whisper_Lv3/modeling_whisper.py	/^    config_class = WhisperConfig$/;"	v	class:WhisperPreTrainedModel
configure_optimizers	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/baselightningmodule.py	/^    def configure_optimizers(self) -> Any:$/;"	m	class:BaseLightningClass	typeref:typename:Any
contains_chinese	steer_moe/tokenizer/glm4/cosyvoice/utils/frontend_utils.py	/^def contains_chinese(text):$/;"	f
contiguous_gradients	configs/stage2.json	/^    "contiguous_gradients": true$/;"	b	object:zero_optimization
contiguous_gradients	configs/stage3.json	/^    "contiguous_gradients": true,$/;"	b	object:zero_optimization
contiguous_gradients	configs/stage3_wo_offload.json	/^    "contiguous_gradients": true,$/;"	b	object:zero_optimization
convert_pad_shape	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/utils/model.py	/^def convert_pad_shape(pad_shape):$/;"	f
convert_to_ascii	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/text/cleaners.py	/^def convert_to_ascii(text):$/;"	f
cos	whisper_train/generate_raw_parquet_multi_processing_word.py	/^cos = CosFileServer(setting.COS_BUCKET, setting.COS_SECRET_ID,$/;"	v
cosy_jsonl_opener	steer_moe/tokenizer/glm4/cosyvoice/dataset/processor.py	/^def cosy_jsonl_opener(data, mode='train', tts_data={}):$/;"	f
cosy_jsonl_opener_vq0918_nopool	steer_moe/tokenizer/glm4/cosyvoice/dataset/processor.py	/^def cosy_jsonl_opener_vq0918_nopool(data, mode='train', tts_data={}):$/;"	f
cosy_jsonl_opener_vq0918_pool2	steer_moe/tokenizer/glm4/cosyvoice/dataset/processor.py	/^def cosy_jsonl_opener_vq0918_pool2(data, mode='train', tts_data={}):$/;"	f
cosy_jsonl_opener_vq0918_pool4	steer_moe/tokenizer/glm4/cosyvoice/dataset/processor.py	/^def cosy_jsonl_opener_vq0918_pool4(data, mode='train', tts_data={}):$/;"	f
cosy_jsonl_opener_vq0918_pool8	steer_moe/tokenizer/glm4/cosyvoice/dataset/processor.py	/^def cosy_jsonl_opener_vq0918_pool8(data, mode='train', tts_data={}):$/;"	f
cosyvoice_join	steer_moe/tokenizer/glm4/cosyvoice/utils/train_utils.py	/^def cosyvoice_join(group_join, info_dict):$/;"	f
create-package	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/Makefile	/^create-package: ## Create wheel and tar gz$/;"	t
create_causal_mask	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer.py	/^def create_causal_mask(i, j, device):$/;"	f
create_causal_mask	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer_use_mask.py	/^def create_causal_mask(i, j, device):$/;"	f
create_custom_forward	steer_moe/tokenizer/whisper_Lv3/modeling_whisper.py	/^                    def create_custom_forward(module):$/;"	f	member:WhisperEncoder.forward	file:
create_custom_forward	steer_moe/tokenizer/whisper_Lv3/modeling_whisper.py	/^                def create_custom_forward(module):$/;"	f	member:WhisperDecoder.forward	file:
create_grid_mask	steer_moe/tokenizer/glm4/cosyvoice/utils/block_mask_util.py	/^def create_grid_mask(seq_length, trunck_length, fill_triangle):$/;"	f
create_layer_wise_optimizer	scripts/train_layer_wise.py	/^def create_layer_wise_optimizer(model, learning_rate: float = 1e-4,$/;"	f
create_layer_wise_steering_model	steer_moe/layer_wise_whisper.py	/^def create_layer_wise_steering_model(whisper_encoder_path: str, num_experts: int = 8):$/;"	f
critical_logger	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/text/cleaners.py	/^critical_logger = logging.getLogger("phonemizer")$/;"	v
custom_forward	steer_moe/tokenizer/whisper_Lv3/modeling_whisper.py	/^                        def custom_forward(*inputs):$/;"	f	function:WhisperEncoder.forward.create_custom_forward	file:
custom_forward	steer_moe/tokenizer/whisper_Lv3/modeling_whisper.py	/^                    def custom_forward(*inputs):$/;"	f	function:WhisperDecoder.forward.create_custom_forward	file:
cv	steer_moe/tokenizer/glm4/cosyvoice/utils/executor.py	/^    def cv(self, model, cv_data_loader, writer, info_dict, on_batch_end=True):$/;"	m	class:Executor
cwd	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/setup.py	/^cwd = os.path.dirname(os.path.abspath(__file__))$/;"	v
data	whisper_train/generate_raw_parquet_multi_processing_word.py	/^                data = json.load(f)$/;"	v
data_pipe	whisper_train/pre_process_word_correct_data.py	/^data_pipe = HFDataProcessorPipeline(feature_extractor=feature_extractor, tokenizer=tokenizer)$/;"	v
decode	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^    def decode(self, stft_a: Tensor, stft_b: Tensor) -> Tensor:$/;"	m	class:STFT	typeref:typename:Tensor
decode1d	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^    def decode1d(self, stft_pair: Tensor) -> Tensor:$/;"	m	class:STFT	typeref:typename:Tensor
default	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^def default(val: Optional[T], d: Union[Callable[..., T], T]) -> T:$/;"	f	typeref:typename:T
denoiser	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/app.py	/^vocoder, denoiser = load_vocoder(args.vocoder, VOCODER_LOC(args.vocoder), device)$/;"	v
denormalize	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/utils/model.py	/^def denormalize(data, mu, std):$/;"	f
detailed	configs/stage2.json	/^    "detailed": true,$/;"	b	object:flops_profiler
detailed	configs/stage3.json	/^    "detailed": true,$/;"	b	object:flops_profiler
detailed_error	steer_moe/tokenizer/glm4/web_demo.py	/^        detailed_error = gr.Textbox($/;"	v
detect_language	steer_moe/tokenizer/glm4/speech_tokenizer/generation_whisper.py	/^    def detect_language($/;"	m	class:WhisperGenerationMixin	typeref:typename:torch.Tensor
device	configs/stage3.json	/^      "device": "cpu",$/;"	s	object:zero_optimization.offload_optimizer
device	configs/stage3.json	/^      "device": "cpu",$/;"	s	object:zero_optimization.offload_param
device	steer_moe/al_models.py	/^    def device(self):$/;"	m	class:AudioToText
device	steer_moe/models.py	/^    def device(self):$/;"	m	class:SteerMoEEfficientLayerWiseModel
device	steer_moe/models.py	/^    def device(self):$/;"	m	class:SteerMoEHybridModel
device	steer_moe/models.py	/^    def device(self):$/;"	m	class:SteerMoELayerWiseModel
device	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/app.py	/^device = get_device(args)$/;"	v
device	steer_moe/tokenizer/glm4/web_demo.py	/^    device = "cuda"$/;"	v
df	whisper_train/pre_process_word_correct_data.py	/^            df = pd.read_csv(f'{processed_status_dir}{f}')$/;"	v
df_clip	whisper_train/generate_raw_parquet_multi_processing_word.py	/^            df_clip = pd.DataFrame(list(data['result']))$/;"	v
df_clip	whisper_train/generate_raw_parquet_multi_processing_word.py	/^            df_clip = pd.DataFrame(list(df_json.result))$/;"	v
df_clip	whisper_train/generate_raw_parquet_multi_processing_word.py	/^        df_clip = df_clip[[$/;"	v
df_clip_dict	whisper_train/generate_raw_parquet_multi_processing_word.py	/^        df_clip_dict = df_clip.to_dict('records')$/;"	v
discriminator_loss	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/hifigan/models.py	/^def discriminator_loss(disc_real_outputs, disc_generated_outputs):$/;"	f
dist	steer_moe/tokenizer/glm4/cosyvoice/bin/train.py	/^import torch.distributed as dist$/;"	I	nameref:module:torch.distributed
dist	steer_moe/tokenizer/glm4/cosyvoice/dataset/dataset.py	/^import torch.distributed as dist$/;"	I	nameref:module:torch.distributed
dist	steer_moe/tokenizer/glm4/cosyvoice/utils/executor.py	/^import torch.distributed as dist$/;"	I	nameref:module:torch.distributed
dist	steer_moe/tokenizer/glm4/cosyvoice/utils/train_utils.py	/^import torch.distributed as dist$/;"	I	nameref:module:torch.distributed
dist	whisper_train/main_word_correct_clips.py	/^import torch.distributed as dist$/;"	I	nameref:module:torch.distributed
distance_fn	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^    distance_fn = lambda z: abs(x - 2 ** z)  # noqa$/;"	f	function:closest_power_2	file:
download_from_cos	whisper_train/pre_process_word_correct_data.py	/^def download_from_cos(path,tag='train'):$/;"	f
dt	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/cli.py	/^import datetime as dt$/;"	I	nameref:module:datetime
dt	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/matcha_tts.py	/^import datetime as dt$/;"	I	nameref:module:datetime
duration_loss	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/utils/model.py	/^def duration_loss(logw, logw_, lengths):$/;"	f
dynamic_batch	steer_moe/tokenizer/glm4/cosyvoice/dataset/processor.py	/^def dynamic_batch(data, max_frames_in_batch=12000, mode='train'):$/;"	f
dynamic_range_compression	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/hifigan/meldataset.py	/^def dynamic_range_compression(x, C=1, clip_val=1e-5):$/;"	f
dynamic_range_compression	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/utils/audio.py	/^def dynamic_range_compression(x, C=1, clip_val=1e-5):$/;"	f
dynamic_range_compression_torch	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/hifigan/meldataset.py	/^def dynamic_range_compression_torch(x, C=1, clip_val=1e-5):$/;"	f
dynamic_range_compression_torch	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/utils/audio.py	/^def dynamic_range_compression_torch(x, C=1, clip_val=1e-5):$/;"	f
dynamic_range_decompression	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/hifigan/meldataset.py	/^def dynamic_range_decompression(x, C=1):$/;"	f
dynamic_range_decompression	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/utils/audio.py	/^def dynamic_range_decompression(x, C=1):$/;"	f
dynamic_range_decompression_torch	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/hifigan/meldataset.py	/^def dynamic_range_decompression_torch(x, C=1):$/;"	f
dynamic_range_decompression_torch	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/utils/audio.py	/^def dynamic_range_decompression_torch(x, C=1):$/;"	f
enabled	configs/stage0.json	/^    "enabled": "auto",$/;"	s	object:fp16
enabled	configs/stage2.json	/^    "enabled": "auto",$/;"	s	object:fp16
enabled	configs/stage2.json	/^    "enabled": true,$/;"	b	object:flops_profiler
enabled	configs/stage2.json	/^    "enabled": true,$/;"	b	object:tensorboard
enabled	configs/stage3.json	/^    "enabled": "auto"$/;"	s	object:bf16
enabled	configs/stage3.json	/^    "enabled": "auto",$/;"	s	object:fp16
enabled	configs/stage3.json	/^    "enabled": true,$/;"	b	object:flops_profiler
enabled	configs/stage3_wo_offload.json	/^    "enabled": "auto",$/;"	s	object:fp16
encode	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^    def encode(self, wave: Tensor) -> Tuple[Tensor, Tensor]:$/;"	m	class:STFT	typeref:typename:Tuple[Tensor,Tensor]
encode	steer_moe/tokenizer/glm4/cosyvoice/llm/llm.py	/^    def encode($/;"	m	class:TransformerLM
encode1d	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^    def encode1d($/;"	m	class:STFT	typeref:typename:Union[Tensor,Tuple[Tensor,Tensor]]
end	steer_moe/tokenizer/glm4/model_server.py	/^    def end(self):$/;"	m	class:TokenStreamer
enforce_tags	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/utils/rich_utils.py	/^def enforce_tags(cfg: DictConfig, save_to_file: bool = False) -> None:$/;"	f	typeref:typename:None
english_cleaners2	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/text/cleaners.py	/^def english_cleaners2(text):$/;"	f
english_cleaners_piper	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/text/cleaners.py	/^def english_cleaners_piper(text):$/;"	f
eps	configs/stage3.json	/^      "eps": "auto",$/;"	s	object:optimizer.params
eps	configs/stage3_wo_offload.json	/^      "eps": "auto",$/;"	s	object:optimizer.params
error_batchs	whisper_train/pre_process_word_correct_data.py	/^    error_batchs = []$/;"	v
error_list	whisper_train/generate_raw_parquet_multi_processing_word.py	/^    error_list = []$/;"	v
evaluate	whisper_train/main_word_correct_clips.py	/^    def evaluate($/;"	m	class:Logged_Seq2SeqTrainer	typeref:typename:Dict[str,float]
evaluate_layer_wise_model	scripts/train_layer_wise.py	/^def evaluate_layer_wise_model(model_path: str, eval_dataset_name: str, config_path: str):$/;"	f
evaluation_loop	whisper_train/main_word_correct_clips.py	/^    def evaluation_loop($/;"	m	class:Logged_Traniner	typeref:typename:EvalLoopOutput
example_dataset_loading	scripts/example_training.py	/^def example_dataset_loading():$/;"	f
example_hybrid_training	scripts/example_training.py	/^def example_hybrid_training():$/;"	f
example_inference	scripts/train.py	/^def example_inference(model_dir, audio_path, whisper_encoder_path, tokenizer_class=AutoTokenizer/;"	f
example_steermoe_training	scripts/example_training.py	/^def example_steermoe_training():$/;"	f
example_with_custom_config	scripts/example_training.py	/^def example_with_custom_config():$/;"	f
exists	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^def exists(val: Optional[T]) -> T:$/;"	f	typeref:typename:T
expand	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^    def expand(self, x: Any, shape: Tuple[int, ...]) -> Tensor:$/;"	m	class:UNetNCCA1d	typeref:typename:Tensor
expand_abbreviations	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/text/cleaners.py	/^def expand_abbreviations(text):$/;"	f
expand_to_planes	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/blocks.py	/^def expand_to_planes(input, shape):$/;"	f
extend_pe	steer_moe/tokenizer/glm4/cosyvoice/transformer/embedding.py	/^    def extend_pe(self, x):$/;"	m	class:EspnetRelPositionalEncoding
extra_repr	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/blocks.py	/^    def extra_repr(self):$/;"	m	class:AdaRMSNorm
extra_repr	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/blocks.py	/^    def extra_repr(self):$/;"	m	class:RMSNorm
extract_speech_token	steer_moe/tokenizer/glm4/speech_tokenizer/utils.py	/^def extract_speech_token(model: WhisperVQEncoder, feature_extractor: WhisperFeatureExtractor, ut/;"	f
extras	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/utils/utils.py	/^def extras(cfg: DictConfig) -> None:$/;"	f	typeref:typename:None
exts	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/setup.py	/^exts = [$/;"	v
fa3_func	steer_moe/tokenizer/whisper_Lv3/modeling_whisper.py	/^        flash_attn_func as fa3_func,$/;"	x	nameref:unknown:flash_attn_func
fa3_varlen_func	steer_moe/tokenizer/whisper_Lv3/modeling_whisper.py	/^        flash_attn_varlen_func as fa3_varlen_func,$/;"	x	nameref:unknown:flash_attn_varlen_func
fade_in_out	steer_moe/tokenizer/glm4/flow_inference.py	/^def fade_in_out(fade_in_mel, fade_out_mel, window):$/;"	f
feature_extractor	steer_moe/tokenizer/glm4/web_demo.py	/^    whisper_model, feature_extractor = None, None$/;"	v
feature_extractor	whisper_train/pre_process_word_correct_data.py	/^feature_extractor = WhisperFeatureExtractor.from_pretrained(model_path["whisper_large-v2"])$/;"	v
feature_loss	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/hifigan/models.py	/^def feature_loss(fmap_r, fmap_g):$/;"	f
file_id	whisper_train/generate_raw_parquet_multi_processing_word.py	/^        file_id = Path(audio_file).stem$/;"	v
filter	steer_moe/tokenizer/glm4/cosyvoice/dataset/processor.py	/^def filter(data,$/;"	f
filter_dataset_by_length	scripts/train.py	/^def filter_dataset_by_length(dataset, max_audio_length=30.0, max_text_length=448):$/;"	f
filter_dataset_by_length	scripts/train_layer_wise.py	/^def filter_dataset_by_length(dataset: DatasetDict, max_audio_length: float = 30.0,$/;"	f	typeref:typename:DatasetDict
filter_inputs	scripts/train.py	/^    def filter_inputs(input_length):$/;"	f	function:filter_dataset_by_length	file:
filter_inputs	scripts/train_layer_wise.py	/^    def filter_inputs(input_length):$/;"	f	function:filter_dataset_by_length	file:
filter_inputs	whisper_train/main_word_correct_clips.py	/^    def filter_inputs(input_length):$/;"	f	function:train	file:
filter_labels	scripts/train.py	/^    def filter_labels(labels):$/;"	f	function:filter_dataset_by_length	file:
filter_labels	scripts/train_layer_wise.py	/^    def filter_labels(labels):$/;"	f	function:filter_dataset_by_length	file:
filter_labels	whisper_train/main_word_correct_clips.py	/^    def filter_labels(labels):$/;"	f	function:train	file:
filter_speech_token	steer_moe/tokenizer/glm4/cosyvoice/dataset/processor.py	/^def filter_speech_token(data,$/;"	f
fix_len_compatibility	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/utils/model.py	/^def fix_len_compatibility(length, num_downsamplings_in_unet=2):$/;"	f
flash_attn	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer.py	/^    def flash_attn($/;"	m	class:Attention
flash_attn	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer_use_mask.py	/^    def flash_attn($/;"	m	class:Attention
flash_attn_func	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer.py	/^    flash_attn_func = None$/;"	v
flash_attn_func	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer_use_mask.py	/^    flash_attn_func = None$/;"	v
flash_attn_kvpacked_func	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer.py	/^    flash_attn_kvpacked_func = None$/;"	v
flash_attn_kvpacked_func	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer_use_mask.py	/^    flash_attn_kvpacked_func = None$/;"	v
flops_profiler	configs/stage2.json	/^  "flops_profiler": {$/;"	o
flops_profiler	configs/stage3.json	/^  "flops_profiler": {$/;"	o
flow_checkpoint	steer_moe/tokenizer/glm4/web_demo.py	/^    flow_checkpoint = os.path.join(args.flow_path, 'flow.pt')$/;"	v
flow_config	steer_moe/tokenizer/glm4/web_demo.py	/^    flow_config = os.path.join(args.flow_path, "config.yaml")$/;"	v
folder_path	whisper_train/pre_process_word_correct_data.py	/^        folder_path = f"{processed_parquet_prefix}\/{batch_tag}_processed_in_batch\/batch_{i}_{i/;"	v
format	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/Makefile	/^format: ## Run pre-commit hooks$/;"	t
forward	cross_modal_steer/cross_modal_steering.py	/^    def forward(self, audio_features: torch.Tensor, text_features: torch.Tensor) -> torch.Tensor/;"	m	class:CrossModalAdapter	typeref:typename:torch.Tensor
forward	cross_modal_steer/cross_modal_steering.py	/^    def forward(self, audio_features: torch.Tensor, text_features: torch.Tensor) -> torch.Tensor/;"	m	class:CrossModalFeatureAligner	typeref:typename:torch.Tensor
forward	cross_modal_steer/cross_modal_steering.py	/^    def forward(self, audio_features: torch.Tensor, text_features: torch.Tensor) -> torch.Tensor/;"	m	class:ModalitySpecificSteering	typeref:typename:torch.Tensor
forward	cross_modal_steer/cross_modal_steering.py	/^    def forward(self, audio_features: torch.Tensor, text_features: torch.Tensor) -> torch.Tensor/;"	m	class:ProgressiveCrossModalSteering	typeref:typename:torch.Tensor
forward	cross_modal_steer/router_comparison.py	/^    def forward(self, x: torch.Tensor, return_gating: bool = False):$/;"	m	class:AttentionBasedRouter
forward	cross_modal_steer/router_comparison.py	/^    def forward(self, x: torch.Tensor, return_gating: bool = False):$/;"	m	class:CurrentRouter
forward	cross_modal_steer/router_comparison.py	/^    def forward(self, x: torch.Tensor, return_gating: bool = False):$/;"	m	class:HierarchicalRouter
forward	cross_modal_steer/router_comparison.py	/^    def forward(self, x: torch.Tensor, return_gating: bool = False):$/;"	m	class:ProgressiveRouter
forward	steer_moe/al_models.py	/^    def forward(self, input_features, decoder_input_ids, labels=None):$/;"	m	class:AudioToText
forward	steer_moe/aligner.py	/^    def forward(self, h_audio, return_gating=False):$/;"	m	class:SteerMoEAligner
forward	steer_moe/efficient_layer_wise_whisper.py	/^    def forward(self, mel_spec, return_gating=False):$/;"	m	class:EfficientLayerWiseSteeringWhisperEncoder
forward	steer_moe/efficient_layer_wise_whisper.py	/^    def forward(self, mel_spec, return_gating=False):$/;"	m	class:SharedRouterLayerWiseSteeringWhisperEncoder
forward	steer_moe/layer_wise_aligner.py	/^    def forward(self, audio_input, return_gating=False):$/;"	m	class:WhisperEncoderWithSteering
forward	steer_moe/layer_wise_aligner.py	/^    def forward(self, whisper_encoder, audio_input, return_gating=False):$/;"	m	class:LayerWiseSteerMoEAligner
forward	steer_moe/layer_wise_whisper.py	/^    def forward(self, mel_spec, return_gating=False):$/;"	m	class:LayerWiseSteeringWhisperEncoder
forward	steer_moe/models.py	/^    def forward(self, audio_waveform, *args, **kwargs):$/;"	m	class:SteerMoEModel
forward	steer_moe/models.py	/^    def forward(self, audio_waveform, decoder_input_ids=None, labels=None, $/;"	m	class:SteerMoEEfficientLayerWiseModel
forward	steer_moe/models.py	/^    def forward(self, audio_waveform, decoder_input_ids=None, labels=None, $/;"	m	class:SteerMoEHybridModel
forward	steer_moe/models.py	/^    def forward(self, audio_waveform, decoder_input_ids=None, labels=None, $/;"	m	class:SteerMoELayerWiseModel
forward	steer_moe/shared_router_implementation.py	/^    def forward(self, mel_spec, return_gating=False):$/;"	m	class:MultipleRoutersLayerWiseSteeringWhisperEncoder
forward	steer_moe/shared_router_implementation.py	/^    def forward(self, mel_spec, return_gating=False):$/;"	m	class:SharedRouterLayerWiseSteeringWhisperEncoder
forward	steer_moe/tokenizer/glm4/cosyvoice/flow/decoder.py	/^    def forward(self, x, mask, mu, t, spks=None, cond=None):$/;"	m	class:ConditionalDecoder
forward	steer_moe/tokenizer/glm4/cosyvoice/flow/flow.py	/^    def forward($/;"	m	class:MaskedDiffWithXvec	typeref:typename:Dict[str,Optional[torch.Tensor]]
forward	steer_moe/tokenizer/glm4/cosyvoice/flow/flow_gradtts.py	/^    def forward($/;"	m	class:MaskedDiffWithXvec	typeref:typename:Dict[str,Optional[torch.Tensor]]
forward	steer_moe/tokenizer/glm4/cosyvoice/flow/flow_matching.py	/^    def forward(self, mu, mask, n_timesteps, temperature=1.0, spks=None, cond=None):$/;"	m	class:ConditionalCFM
forward	steer_moe/tokenizer/glm4/cosyvoice/flow/flow_matching_dit.py	/^    def forward(self, mu, mask, n_timesteps, temperature=1.0, spks=None, cond=None):$/;"	m	class:ConditionalCFM
forward	steer_moe/tokenizer/glm4/cosyvoice/flow/length_regulator.py	/^    def forward(self, x, ylens=None):$/;"	m	class:InterpolateRegulator
forward	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^    def forward(  # type: ignore$/;"	m	class:UNetCFG1d	typeref:typename:Tensor
forward	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^    def forward(  # type: ignore$/;"	m	class:UNetNCCA1d	typeref:typename:Tensor
forward	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^    def forward($/;"	m	class:Attention	typeref:typename:Tensor
forward	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^    def forward($/;"	m	class:AttentionBase	typeref:typename:Tensor
forward	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^    def forward($/;"	m	class:BottleneckBlock1d	typeref:typename:Tensor
forward	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^    def forward($/;"	m	class:ConvBlock1d	typeref:typename:Tensor
forward	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^    def forward($/;"	m	class:DownsampleBlock1d	typeref:typename:Union[Tuple[Tensor,List[Tensor]],Tensor]
forward	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^    def forward($/;"	m	class:UNet1d	typeref:typename:Tensor
forward	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^    def forward($/;"	m	class:UpsampleBlock1d	typeref:typename:Union[Tuple[Tensor,Tensor],Tensor]
forward	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^    def forward(self, *args, **kwargs):  # type: ignore$/;"	m	class:UNetAll1d
forward	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^    def forward(self, mapping: Tensor) -> Tuple[Tensor, Tensor]:$/;"	m	class:MappingToScaleShift	typeref:typename:Tuple[Tensor,Tensor]
forward	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^    def forward(self, x: Tensor) -> Tensor:$/;"	m	class:FixedEmbedding	typeref:typename:Tensor
forward	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^    def forward(self, x: Tensor) -> Tensor:$/;"	m	class:LearnedPositionalEmbedding	typeref:typename:Tensor
forward	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^    def forward(self, x: Tensor) -> Tensor:$/;"	m	class:SinusoidalEmbedding	typeref:typename:Tensor
forward	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^    def forward(self, x: Tensor, *, context: Optional[Tensor] = None, context_mask: Optional[Ten/;"	m	class:Transformer1d	typeref:typename:Tensor
forward	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^    def forward(self, x: Tensor, *, context: Optional[Tensor] = None, context_mask: Optional[Ten/;"	m	class:TransformerBlock	typeref:typename:Tensor
forward	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^    def forward(self, x: Tensor, causal=False) -> Tensor:$/;"	m	class:Conv1d	typeref:typename:Tensor
forward	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^    def forward(self, x: Tensor, causal=False) -> Tensor:$/;"	m	class:ConvTranspose1d	typeref:typename:Tensor
forward	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^    def forward(self, x: Tensor, mapping: Optional[Tensor] = None):$/;"	m	class:ConditionedSequential
forward	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^    def forward(self, x: Tensor, mapping: Optional[Tensor] = None, causal=False) -> Tensor:$/;"	m	class:Patcher	typeref:typename:Tensor
forward	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^    def forward(self, x: Tensor, mapping: Optional[Tensor] = None, causal=False) -> Tensor:$/;"	m	class:ResnetBlock1d	typeref:typename:Tensor
forward	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^    def forward(self, x: Tensor, mapping: Optional[Tensor] = None, causal=False) -> Tensor:$/;"	m	class:Unpatcher	typeref:typename:Tensor
forward	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^    def forward(self, x: Union[List[float], Tensor]) -> Tensor:$/;"	m	class:NumberEmbedder	typeref:typename:Tensor
forward	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/blocks.py	/^    def forward(self, input):$/;"	m	class:FourierFeatures
forward	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/blocks.py	/^    def forward(self, input):$/;"	m	class:ResidualBlock
forward	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/blocks.py	/^    def forward(self, input):$/;"	m	class:SelfAttention1d
forward	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/blocks.py	/^    def forward(self, input):$/;"	m	class:SkipBlock
forward	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/blocks.py	/^    def forward(self, x):$/;"	m	class:Downsample1d
forward	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/blocks.py	/^    def forward(self, x):$/;"	m	class:ForcedWNConv1d
forward	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/blocks.py	/^    def forward(self, x):$/;"	m	class:LinearGEGLU
forward	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/blocks.py	/^    def forward(self, x):$/;"	m	class:RMSNorm
forward	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/blocks.py	/^    def forward(self, x):$/;"	m	class:SnakeBeta
forward	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/blocks.py	/^    def forward(self, x):$/;"	m	class:Upsample1d
forward	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/blocks.py	/^    def forward(self, x, cond):$/;"	m	class:AdaRMSNorm
forward	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/dit.py	/^    def forward($/;"	m	class:DiffusionTransformer
forward	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/dit_v2.py	/^    def forward($/;"	m	class:DiffusionTransformerV2
forward	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/stable_diffusion.py	/^    def forward(self, mu, mask, n_timesteps):$/;"	m	class:Stable_Diffusion
forward	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/stable_diffusion_test.py	/^    def forward(self, mu, mask, n_timesteps):$/;"	m	class:Stable_Diffusion
forward	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer.py	/^    def forward($/;"	m	class:Attention
forward	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer.py	/^    def forward($/;"	m	class:ContinuousTransformer
forward	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer.py	/^    def forward($/;"	m	class:TransformerBlock
forward	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer.py	/^    def forward(self, t):$/;"	m	class:RotaryEmbedding
forward	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer.py	/^    def forward(self, x):$/;"	m	class:ConformerModule
forward	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer.py	/^    def forward(self, x):$/;"	m	class:FeedForward
forward	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer.py	/^    def forward(self, x):$/;"	m	class:GLU
forward	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer.py	/^    def forward(self, x):$/;"	m	class:LayerNorm
forward	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer.py	/^    def forward(self, x, pos = None, seq_start_pos = None):$/;"	m	class:AbsolutePositionalEmbedding
forward	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer.py	/^    def forward(self, x, pos = None, seq_start_pos = None):$/;"	m	class:ScaledSinusoidalEmbedding
forward	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer_use_mask.py	/^    def forward($/;"	m	class:Attention
forward	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer_use_mask.py	/^    def forward($/;"	m	class:ContinuousTransformer
forward	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer_use_mask.py	/^    def forward($/;"	m	class:TransformerBlock
forward	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer_use_mask.py	/^    def forward(self, t):$/;"	m	class:RotaryEmbedding
forward	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer_use_mask.py	/^    def forward(self, x):$/;"	m	class:ConformerModule
forward	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer_use_mask.py	/^    def forward(self, x):$/;"	m	class:FeedForward
forward	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer_use_mask.py	/^    def forward(self, x):$/;"	m	class:GLU
forward	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer_use_mask.py	/^    def forward(self, x):$/;"	m	class:LayerNorm
forward	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer_use_mask.py	/^    def forward(self, x, pos=None, seq_start_pos=None):$/;"	m	class:AbsolutePositionalEmbedding
forward	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer_use_mask.py	/^    def forward(self, x, pos=None, seq_start_pos=None):$/;"	m	class:ScaledSinusoidalEmbedding
forward	steer_moe/tokenizer/glm4/cosyvoice/hifigan/f0_predictor.py	/^    def forward(self, x: torch.Tensor) -> torch.Tensor:$/;"	m	class:ConvRNNF0Predictor	typeref:typename:torch.Tensor
forward	steer_moe/tokenizer/glm4/cosyvoice/hifigan/generator.py	/^    def forward(self, f0):$/;"	m	class:SineGen
forward	steer_moe/tokenizer/glm4/cosyvoice/hifigan/generator.py	/^    def forward(self, x):$/;"	m	class:SourceModuleHnNSF
forward	steer_moe/tokenizer/glm4/cosyvoice/hifigan/generator.py	/^    def forward(self, x: torch.Tensor) -> torch.Tensor:$/;"	m	class:ResBlock	typeref:typename:torch.Tensor
forward	steer_moe/tokenizer/glm4/cosyvoice/hifigan/generator.py	/^    def forward(self, x: torch.Tensor, cache_source: torch.Tensor = torch.zeros(1, 1, 0)) -> tor/;"	m	class:HiFTGenerator	typeref:typename:torch.Tensor
forward	steer_moe/tokenizer/glm4/cosyvoice/llm/llm.py	/^    def forward($/;"	m	class:TransformerLM	typeref:typename:Dict[str,Optional[torch.Tensor]]
forward	steer_moe/tokenizer/glm4/cosyvoice/transformer/activation.py	/^    def forward(self, x):$/;"	m	class:Snake
forward	steer_moe/tokenizer/glm4/cosyvoice/transformer/activation.py	/^    def forward(self, x: torch.Tensor) -> torch.Tensor:$/;"	m	class:Swish	typeref:typename:torch.Tensor
forward	steer_moe/tokenizer/glm4/cosyvoice/transformer/attention.py	/^    def forward($/;"	m	class:BlockRelPositionMultiHeadedAttention	typeref:typename:Tuple[torch.Tensor,torch.Tensor]
forward	steer_moe/tokenizer/glm4/cosyvoice/transformer/attention.py	/^    def forward($/;"	m	class:MultiHeadedAttention	typeref:typename:Tuple[torch.Tensor,torch.Tensor]
forward	steer_moe/tokenizer/glm4/cosyvoice/transformer/attention.py	/^    def forward($/;"	m	class:RelPositionMultiHeadedAttention	typeref:typename:Tuple[torch.Tensor,torch.Tensor]
forward	steer_moe/tokenizer/glm4/cosyvoice/transformer/convolution.py	/^    def forward($/;"	m	class:ConvolutionModule	typeref:typename:Tuple[torch.Tensor,torch.Tensor]
forward	steer_moe/tokenizer/glm4/cosyvoice/transformer/decoder.py	/^    def forward($/;"	m	class:BiTransformerDecoder	typeref:typename:Tuple[torch.Tensor,torch.Tensor,torch.Tensor]
forward	steer_moe/tokenizer/glm4/cosyvoice/transformer/decoder.py	/^    def forward($/;"	m	class:TransformerDecoder	typeref:typename:Tuple[torch.Tensor,torch.Tensor,torch.Tensor]
forward	steer_moe/tokenizer/glm4/cosyvoice/transformer/decoder_layer.py	/^    def forward($/;"	m	class:DecoderLayer	typeref:typename:Tuple[torch.Tensor,torch.Tensor,torch.Tensor,torch.Tensor]
forward	steer_moe/tokenizer/glm4/cosyvoice/transformer/embedding.py	/^    def forward(self, x: torch.Tensor, offset: Union[int, torch.Tensor] = 0):$/;"	m	class:EspnetRelPositionalEncoding
forward	steer_moe/tokenizer/glm4/cosyvoice/transformer/embedding.py	/^    def forward(self,$/;"	m	class:NoPositionalEncoding	typeref:typename:Tuple[torch.Tensor,torch.Tensor]
forward	steer_moe/tokenizer/glm4/cosyvoice/transformer/embedding.py	/^    def forward(self,$/;"	m	class:PositionalEncoding	typeref:typename:Tuple[torch.Tensor,torch.Tensor]
forward	steer_moe/tokenizer/glm4/cosyvoice/transformer/embedding.py	/^    def forward(self,$/;"	m	class:RelPositionalEncoding	typeref:typename:Tuple[torch.Tensor,torch.Tensor]
forward	steer_moe/tokenizer/glm4/cosyvoice/transformer/encoder.py	/^    def forward($/;"	m	class:BaseEncoder	typeref:typename:Tuple[torch.Tensor,torch.Tensor]
forward	steer_moe/tokenizer/glm4/cosyvoice/transformer/encoder_layer.py	/^    def forward($/;"	m	class:ConformerEncoderLayer	typeref:typename:Tuple[torch.Tensor,torch.Tensor,torch.Tensor,torch.Tensor]
forward	steer_moe/tokenizer/glm4/cosyvoice/transformer/encoder_layer.py	/^    def forward($/;"	m	class:TransformerEncoderLayer	typeref:typename:Tuple[torch.Tensor,torch.Tensor,torch.Tensor,torch.Tensor]
forward	steer_moe/tokenizer/glm4/cosyvoice/transformer/label_smoothing_loss.py	/^    def forward(self, x: torch.Tensor, target: torch.Tensor) -> torch.Tensor:$/;"	m	class:LabelSmoothingLoss	typeref:typename:torch.Tensor
forward	steer_moe/tokenizer/glm4/cosyvoice/transformer/positionwise_feed_forward.py	/^    def forward(self, xs: torch.Tensor) -> torch.Tensor:$/;"	m	class:MoEFFNLayer	typeref:typename:torch.Tensor
forward	steer_moe/tokenizer/glm4/cosyvoice/transformer/positionwise_feed_forward.py	/^    def forward(self, xs: torch.Tensor) -> torch.Tensor:$/;"	m	class:PositionwiseFeedForward	typeref:typename:torch.Tensor
forward	steer_moe/tokenizer/glm4/cosyvoice/transformer/subsampling.py	/^    def forward($/;"	m	class:Conv1dSubsampling2	typeref:typename:Tuple[torch.Tensor,torch.Tensor,torch.Tensor]
forward	steer_moe/tokenizer/glm4/cosyvoice/transformer/subsampling.py	/^    def forward($/;"	m	class:Conv2dSubsampling4	typeref:typename:Tuple[torch.Tensor,torch.Tensor,torch.Tensor]
forward	steer_moe/tokenizer/glm4/cosyvoice/transformer/subsampling.py	/^    def forward($/;"	m	class:Conv2dSubsampling6	typeref:typename:Tuple[torch.Tensor,torch.Tensor,torch.Tensor]
forward	steer_moe/tokenizer/glm4/cosyvoice/transformer/subsampling.py	/^    def forward($/;"	m	class:Conv2dSubsampling8	typeref:typename:Tuple[torch.Tensor,torch.Tensor,torch.Tensor]
forward	steer_moe/tokenizer/glm4/cosyvoice/transformer/subsampling.py	/^    def forward($/;"	m	class:EmbedinigNoSubsampling	typeref:typename:Tuple[torch.Tensor,torch.Tensor,torch.Tensor]
forward	steer_moe/tokenizer/glm4/cosyvoice/transformer/subsampling.py	/^    def forward($/;"	m	class:LegacyLinearNoSubsampling	typeref:typename:Tuple[torch.Tensor,torch.Tensor,torch.Tensor]
forward	steer_moe/tokenizer/glm4/cosyvoice/transformer/subsampling.py	/^    def forward($/;"	m	class:LinearNoSubsampling	typeref:typename:Tuple[torch.Tensor,torch.Tensor,torch.Tensor]
forward	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^    def forward($/;"	m	class:WhisperAttention	typeref:typename:Tuple[torch.Tensor,Optional[torch.Tensor],Optional[Tuple[torch.Tensor]]]
forward	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^    def forward($/;"	m	class:WhisperDecoderLayer	typeref:typename:torch.Tensor
forward	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^    def forward($/;"	m	class:WhisperFlashAttention2	typeref:typename:Tuple[torch.Tensor,Optional[torch.Tensor],Optional[Tuple[torch.Tensor]]]
forward	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^    def forward($/;"	m	class:WhisperForAudioClassification	typeref:typename:Union[Tuple[torch.Tensor],SequenceClassifierOutput]
forward	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^    def forward($/;"	m	class:WhisperForCausalLM	typeref:typename:Union[Tuple,CausalLMOutputWithCrossAttentions]
forward	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^    def forward($/;"	m	class:WhisperSdpaAttention	typeref:typename:Tuple[torch.Tensor,Optional[torch.Tensor],Optional[Tuple[torch.Tensor]]]
forward	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^    def forward($/;"	m	class:WhisperVQDecoder
forward	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^    def forward($/;"	m	class:WhisperVQEncoder
forward	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^    def forward($/;"	m	class:WhisperVQEncoderLayer	typeref:typename:torch.Tensor
forward	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^    def forward($/;"	m	class:WhisperVQForConditionalGeneration	typeref:typename:Union[Tuple[torch.Tensor],Seq2SeqLMOutput]
forward	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^    def forward($/;"	m	class:WhisperVQModel	typeref:typename:Union[Tuple[torch.Tensor],Seq2SeqModelOutput]
forward	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^    def forward(self, *args, **kwargs):$/;"	m	class:WhisperDecoderWrapper
forward	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^    def forward(self, inp):$/;"	m	class:CausalConv1d
forward	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^    def forward(self, input_ids, past_key_values_length=0, position_ids=None):$/;"	m	class:WhisperPositionalEmbedding
forward	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/hifigan/denoiser.py	/^    def forward(self, audio, strength=0.0005):$/;"	m	class:Denoiser
forward	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/hifigan/models.py	/^    def forward(self, x):$/;"	m	class:DiscriminatorP
forward	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/hifigan/models.py	/^    def forward(self, x):$/;"	m	class:DiscriminatorS
forward	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/hifigan/models.py	/^    def forward(self, x):$/;"	m	class:Generator
forward	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/hifigan/models.py	/^    def forward(self, x):$/;"	m	class:ResBlock1
forward	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/hifigan/models.py	/^    def forward(self, x):$/;"	m	class:ResBlock2
forward	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/hifigan/models.py	/^    def forward(self, y, y_hat):$/;"	m	class:MultiPeriodDiscriminator
forward	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/hifigan/models.py	/^    def forward(self, y, y_hat):$/;"	m	class:MultiScaleDiscriminator
forward	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/components/decoder.py	/^    def forward($/;"	m	class:ConformerWrapper
forward	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/components/decoder.py	/^    def forward(self, inputs):$/;"	m	class:Upsample1D
forward	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/components/decoder.py	/^    def forward(self, sample, condition=None):$/;"	m	class:TimestepEmbedding
forward	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/components/decoder.py	/^    def forward(self, x):$/;"	m	class:Downsample1D
forward	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/components/decoder.py	/^    def forward(self, x, mask):$/;"	m	class:Block1D
forward	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/components/decoder.py	/^    def forward(self, x, mask, mu, t, spks=None, cond=None):$/;"	m	class:Decoder
forward	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/components/decoder.py	/^    def forward(self, x, mask, time_emb):$/;"	m	class:ResnetBlock1D
forward	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/components/decoder.py	/^    def forward(self, x, scale=1000):$/;"	m	class:SinusoidalPosEmb
forward	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/components/flow_matching.py	/^    def forward(self, mu, mask, n_timesteps, temperature=1.0, spks=None, cond=None):$/;"	m	class:BASECFM
forward	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/components/text_encoder.py	/^    def forward(self, x):$/;"	m	class:LayerNorm
forward	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/components/text_encoder.py	/^    def forward(self, x, c, attn_mask=None):$/;"	m	class:MultiHeadAttention
forward	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/components/text_encoder.py	/^    def forward(self, x, x_lengths, spks=None):$/;"	m	class:TextEncoder
forward	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/components/text_encoder.py	/^    def forward(self, x, x_mask):$/;"	m	class:ConvReluNorm
forward	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/components/text_encoder.py	/^    def forward(self, x, x_mask):$/;"	m	class:DurationPredictor
forward	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/components/text_encoder.py	/^    def forward(self, x, x_mask):$/;"	m	class:Encoder
forward	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/components/text_encoder.py	/^    def forward(self, x, x_mask):$/;"	m	class:FFN
forward	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/components/text_encoder.py	/^    def forward(self, x: torch.Tensor):$/;"	m	class:RotaryPositionalEmbeddings
forward	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/components/transformer.py	/^    def forward($/;"	m	class:BasicTransformerBlock
forward	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/components/transformer.py	/^    def forward(self, hidden_states):$/;"	m	class:FeedForward
forward	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/components/transformer.py	/^    def forward(self, x):$/;"	m	class:SnakeBeta
forward	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/matcha_tts.py	/^    def forward(self, x, x_lengths, y, y_lengths, spks=None, out_size=None, cond=None):$/;"	m	class:MatchaTTS
forward	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/onnx/export.py	/^    def forward(self, x, x_lengths, scales, spks=None):$/;"	m	class:MatchaWithVocoder
forward	steer_moe/tokenizer/whisper_Lv3/modeling_whisper.py	/^    def forward($/;"	m	class:WhisperAttention	typeref:typename:Tuple[torch.Tensor,Optional[torch.Tensor],Optional[Tuple[torch.Tensor]]]
forward	steer_moe/tokenizer/whisper_Lv3/modeling_whisper.py	/^    def forward($/;"	m	class:WhisperDecoder
forward	steer_moe/tokenizer/whisper_Lv3/modeling_whisper.py	/^    def forward($/;"	m	class:WhisperDecoderLayer	typeref:typename:torch.Tensor
forward	steer_moe/tokenizer/whisper_Lv3/modeling_whisper.py	/^    def forward($/;"	m	class:WhisperEncoder
forward	steer_moe/tokenizer/whisper_Lv3/modeling_whisper.py	/^    def forward($/;"	m	class:WhisperEncoderLayer	typeref:typename:torch.Tensor
forward	steer_moe/tokenizer/whisper_Lv3/modeling_whisper.py	/^    def forward($/;"	m	class:WhisperModel	typeref:typename:Union[Tuple[torch.Tensor],Seq2SeqModelOutput]
forward	steer_moe/tokenizer/whisper_Lv3/modeling_whisper.py	/^    def forward(self, input_ids, past_key_values_length=0):$/;"	m	class:WhisperPositionalEmbedding
forward	tmpx07ntkc2/_remote_module_non_scriptable.py	/^def forward(self, *args, **kwargs):$/;"	f
forward_async	tmpx07ntkc2/_remote_module_non_scriptable.py	/^def forward_async(self, *args, **kwargs):$/;"	f
forward_attention	steer_moe/tokenizer/glm4/cosyvoice/transformer/attention.py	/^    def forward_attention($/;"	m	class:MultiHeadedAttention	typeref:typename:torch.Tensor
forward_chunk	steer_moe/tokenizer/glm4/cosyvoice/transformer/encoder.py	/^    def forward_chunk($/;"	m	class:BaseEncoder	typeref:typename:Tuple[torch.Tensor,torch.Tensor,torch.Tensor]
forward_chunk_by_chunk	steer_moe/tokenizer/glm4/cosyvoice/transformer/encoder.py	/^    def forward_chunk_by_chunk($/;"	m	class:BaseEncoder	typeref:typename:Tuple[torch.Tensor,torch.Tensor]
forward_flash_attn	steer_moe/tokenizer/whisper_Lv3/modeling_whisper.py	/^    def forward_flash_attn($/;"	m	class:WhisperAttention
forward_from_seq_len	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer.py	/^    def forward_from_seq_len(self, seq_len):$/;"	m	class:RotaryEmbedding
forward_from_seq_len	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer_use_mask.py	/^    def forward_from_seq_len(self, seq_len):$/;"	m	class:RotaryEmbedding
forward_layers	steer_moe/tokenizer/glm4/cosyvoice/transformer/decoder.py	/^    def forward_layers(self, x: torch.Tensor, tgt_mask: torch.Tensor,$/;"	m	class:TransformerDecoder	typeref:typename:torch.Tensor
forward_layers	steer_moe/tokenizer/glm4/cosyvoice/transformer/encoder.py	/^    def forward_layers(self, xs: torch.Tensor, chunk_masks: torch.Tensor,$/;"	m	class:BaseEncoder	typeref:typename:torch.Tensor
forward_layers_checkpointed	steer_moe/tokenizer/glm4/cosyvoice/transformer/decoder.py	/^    def forward_layers_checkpointed(self, x: torch.Tensor,$/;"	m	class:TransformerDecoder	typeref:typename:torch.Tensor
forward_layers_checkpointed	steer_moe/tokenizer/glm4/cosyvoice/transformer/encoder.py	/^    def forward_layers_checkpointed(self, xs: torch.Tensor,$/;"	m	class:BaseEncoder	typeref:typename:torch.Tensor
forward_one_step	steer_moe/tokenizer/glm4/cosyvoice/transformer/decoder.py	/^    def forward_one_step($/;"	m	class:BiTransformerDecoder	typeref:typename:Tuple[torch.Tensor,List[torch.Tensor]]
forward_one_step	steer_moe/tokenizer/glm4/cosyvoice/transformer/decoder.py	/^    def forward_one_step($/;"	m	class:TransformerDecoder	typeref:typename:Tuple[torch.Tensor,List[torch.Tensor]]
forward_qkv	steer_moe/tokenizer/glm4/cosyvoice/transformer/attention.py	/^    def forward_qkv($/;"	m	class:MultiHeadedAttention	typeref:typename:Tuple[torch.Tensor,torch.Tensor,torch.Tensor]
fp16	configs/stage0.json	/^  "fp16": {$/;"	o
fp16	configs/stage2.json	/^  "fp16": {$/;"	o
fp16	configs/stage3.json	/^  "fp16": {$/;"	o
fp16	configs/stage3_wo_offload.json	/^  "fp16": {$/;"	o
freeze_encoder	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^    def freeze_encoder(self):$/;"	m	class:WhisperForAudioClassification
freeze_encoder	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^    def freeze_encoder(self):$/;"	m	class:WhisperVQForConditionalGeneration
freeze_encoder	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^    def freeze_encoder(self):$/;"	m	class:WhisperVQModel
freeze_encoder	steer_moe/tokenizer/whisper_Lv3/modeling_whisper.py	/^    def freeze_encoder(self):$/;"	m	class:WhisperModel
frontend_cross_lingual	steer_moe/tokenizer/glm4/cosyvoice/cli/frontend.py	/^    def frontend_cross_lingual(self, tts_text, prompt_speech_16k):$/;"	m	class:CosyVoiceFrontEnd
frontend_instruct	steer_moe/tokenizer/glm4/cosyvoice/cli/frontend.py	/^    def frontend_instruct(self, tts_text, spk_id, instruct_text):$/;"	m	class:CosyVoiceFrontEnd
frontend_sft	steer_moe/tokenizer/glm4/cosyvoice/cli/frontend.py	/^    def frontend_sft(self, tts_text, spk_id):$/;"	m	class:CosyVoiceFrontEnd
frontend_zero_shot	steer_moe/tokenizer/glm4/cosyvoice/cli/frontend.py	/^    def frontend_zero_shot(self, tts_text, prompt_text, prompt_speech_16k):$/;"	m	class:CosyVoiceFrontEnd
generate	steer_moe/tokenizer/glm4/speech_tokenizer/generation_whisper.py	/^    def generate($/;"	m	class:WhisperGenerationMixin
generate_no_timestamps	whisper_train/generate_raw_parquet_multi_processing_word.py	/^def generate_no_timestamps(chunks, actual_start_time):$/;"	f
generate_path	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/utils/model.py	/^def generate_path(duration, mask):$/;"	f
generate_stream	steer_moe/tokenizer/glm4/model_server.py	/^    def generate_stream(self, params):$/;"	m	class:ModelWorker
generate_stream	steer_moe/tokenizer/glm4/model_server.py	/^async def generate_stream(request: Request):$/;"	f
generate_stream_gate	steer_moe/tokenizer/glm4/model_server.py	/^    def generate_stream_gate(self, params):$/;"	m	class:ModelWorker
generate_timestamps	whisper_train/generate_raw_parquet_multi_processing_word.py	/^def generate_timestamps(chunks, actual_start_time):$/;"	f
generate_with_fallback	steer_moe/tokenizer/glm4/speech_tokenizer/generation_whisper.py	/^    def generate_with_fallback($/;"	m	class:WhisperGenerationMixin
generated	steer_moe/models.py	/^    generated = llm_decoder.generate(inputs_embeds=prompts)$/;"	v
generator_loss	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/hifigan/models.py	/^def generator_loss(disc_outputs):$/;"	f
get_alphas_sigmas	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/sampling.py	/^def get_alphas_sigmas(t):$/;"	f
get_args	steer_moe/tokenizer/glm4/cosyvoice/bin/inference.py	/^def get_args():$/;"	f
get_args	steer_moe/tokenizer/glm4/cosyvoice/bin/train.py	/^def get_args():$/;"	f
get_asr_dataset_by_name	scripts/train.py	/^def get_asr_dataset_by_name(dataset_name, split='test', sample_rate=16000):$/;"	f
get_at_offset	steer_moe/tokenizer/glm4/cosyvoice/dataset/processor.py	/^    def get_at_offset(self, offset) -> tuple[str, bytes]:$/;"	m	class:MMTar	typeref:typename:tuple[str,bytes]
get_block	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/components/decoder.py	/^    def get_block(block_type, dim, attention_head_dim, num_heads, dropout, act_fn):$/;"	m	class:Decoder
get_block_causal_attention_mask	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^    def get_block_causal_attention_mask(self, attention_mask, block_size=50):$/;"	m	class:WhisperVQEncoder
get_bmask	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/sampling.py	/^def get_bmask(i, steps, mask):$/;"	f
get_channels	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^    def get_channels($/;"	m	class:UNet1d	typeref:typename:Optional[Tensor]
get_datapoint	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/data/text_mel_datamodule.py	/^    def get_datapoint(self, filepath_and_text):$/;"	m	class:TextMelDataset
get_dataset_filelist	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/hifigan/meldataset.py	/^def get_dataset_filelist(a):$/;"	f
get_decoder	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^    def get_decoder(self):$/;"	m	class:WhisperForCausalLM
get_decoder	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^    def get_decoder(self):$/;"	m	class:WhisperVQForConditionalGeneration
get_decoder	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^    def get_decoder(self):$/;"	m	class:WhisperVQModel
get_decoder	steer_moe/tokenizer/whisper_Lv3/modeling_whisper.py	/^    def get_decoder(self):$/;"	m	class:WhisperModel
get_device	steer_moe/al_models.py	/^    def get_device(self):$/;"	m	class:AudioToText
get_device	steer_moe/models.py	/^    def get_device(self):$/;"	m	class:SteerMoEEfficientLayerWiseModel
get_device	steer_moe/models.py	/^    def get_device(self):$/;"	m	class:SteerMoEHybridModel
get_device	steer_moe/models.py	/^    def get_device(self):$/;"	m	class:SteerMoELayerWiseModel
get_device	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/cli.py	/^def get_device(args):$/;"	f
get_empty_segmentation	whisper_train/generate_raw_parquet_multi_processing_word.py	/^def get_empty_segmentation(duration, music_li, noise_li, frame_rate, channels,$/;"	f
get_encoder	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^    def get_encoder(self):$/;"	m	class:WhisperVQForConditionalGeneration
get_encoder	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^    def get_encoder(self):$/;"	m	class:WhisperVQModel
get_encoder	steer_moe/tokenizer/whisper_Lv3/modeling_whisper.py	/^    def get_encoder(self):$/;"	m	class:WhisperModel
get_exportable_module	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/onnx/export.py	/^def get_exportable_module(matcha, vocoder, n_timesteps):$/;"	f
get_extra_padding_for_conv1d	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^def get_extra_padding_for_conv1d(x: torch.Tensor, kernel_size: int, stride: int,$/;"	f	typeref:typename:int
get_input_embeddings	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^    def get_input_embeddings(self) -> nn.Module:$/;"	m	class:WhisperForAudioClassification	typeref:typename:nn.Module
get_input_embeddings	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^    def get_input_embeddings(self) -> nn.Module:$/;"	m	class:WhisperForCausalLM	typeref:typename:nn.Module
get_input_embeddings	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^    def get_input_embeddings(self) -> nn.Module:$/;"	m	class:WhisperVQEncoder	typeref:typename:nn.Module
get_input_embeddings	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^    def get_input_embeddings(self) -> nn.Module:$/;"	m	class:WhisperVQForConditionalGeneration	typeref:typename:nn.Module
get_input_embeddings	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^    def get_input_embeddings(self):$/;"	m	class:WhisperDecoderWrapper
get_input_embeddings	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^    def get_input_embeddings(self):$/;"	m	class:WhisperVQDecoder
get_input_embeddings	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^    def get_input_embeddings(self):$/;"	m	class:WhisperVQModel
get_input_embeddings	steer_moe/tokenizer/whisper_Lv3/modeling_whisper.py	/^    def get_input_embeddings(self) -> nn.Module:$/;"	m	class:WhisperEncoder	typeref:typename:nn.Module
get_input_embeddings	steer_moe/tokenizer/whisper_Lv3/modeling_whisper.py	/^    def get_input_embeddings(self):$/;"	m	class:WhisperDecoder
get_input_embeddings	steer_moe/tokenizer/whisper_Lv3/modeling_whisper.py	/^    def get_input_embeddings(self):$/;"	m	class:WhisperModel
get_inputs	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/onnx/export.py	/^def get_inputs(is_multi_speaker):$/;"	f
get_losses	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/baselightningmodule.py	/^    def get_losses(self, batch):$/;"	m	class:BaseLightningClass
get_lr	steer_moe/tokenizer/glm4/cosyvoice/utils/scheduler.py	/^    def get_lr(self):$/;"	m	class:ConstantLR
get_lr	steer_moe/tokenizer/glm4/cosyvoice/utils/scheduler.py	/^    def get_lr(self):$/;"	m	class:NoamAnnealing
get_lr	steer_moe/tokenizer/glm4/cosyvoice/utils/scheduler.py	/^    def get_lr(self):$/;"	m	class:SquareRootConstantPolicy
get_lr	steer_moe/tokenizer/glm4/cosyvoice/utils/scheduler.py	/^    def get_lr(self):$/;"	m	class:WarmupAnnealHoldPolicy
get_lr	steer_moe/tokenizer/glm4/cosyvoice/utils/scheduler.py	/^    def get_lr(self):$/;"	m	class:WarmupHoldPolicy
get_lr	steer_moe/tokenizer/glm4/cosyvoice/utils/scheduler.py	/^    def get_lr(self):$/;"	m	class:WarmupLR
get_lr	steer_moe/tokenizer/glm4/cosyvoice/utils/scheduler.py	/^    def get_lr(self):$/;"	m	class:WarmupPolicy
get_mapping	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^    def get_mapping($/;"	m	class:UNet1d	typeref:typename:Optional[Tensor]
get_mel	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/data/text_mel_datamodule.py	/^    def get_mel(self, filepath):$/;"	m	class:TextMelDataset
get_metric_value	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/utils/utils.py	/^def get_metric_value(metric_dict: Dict[str, Any], metric_name: str) -> float:$/;"	f	typeref:typename:float
get_output_embeddings	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^    def get_output_embeddings(self):$/;"	m	class:WhisperForCausalLM
get_output_embeddings	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^    def get_output_embeddings(self):$/;"	m	class:WhisperVQForConditionalGeneration
get_padding	steer_moe/tokenizer/glm4/cosyvoice/utils/common.py	/^def get_padding(kernel_size, dilation=1):$/;"	f
get_padding	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/hifigan/xutils.py	/^def get_padding(kernel_size, dilation=1):$/;"	f
get_pylogger	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/utils/pylogger.py	/^def get_pylogger(name: str = __name__) -> logging.Logger:$/;"	f	typeref:typename:logging.Logger
get_steering_analysis	steer_moe/efficient_layer_wise_whisper.py	/^    def get_steering_analysis(self, gating_scores_list):$/;"	m	class:EfficientLayerWiseSteeringWhisperEncoder
get_steering_analysis	steer_moe/layer_wise_aligner.py	/^    def get_steering_analysis(self, gating_scores_list):$/;"	m	class:LayerWiseSteerMoEAligner
get_steering_analysis	steer_moe/layer_wise_whisper.py	/^    def get_steering_analysis(self, gating_scores_list):$/;"	m	class:LayerWiseSteeringWhisperEncoder
get_steering_analysis	steer_moe/models.py	/^    def get_steering_analysis(self, gating_scores):$/;"	m	class:SteerMoEEfficientLayerWiseModel
get_steering_analysis	steer_moe/models.py	/^    def get_steering_analysis(self, gating_scores):$/;"	m	class:SteerMoELayerWiseModel
get_text	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/data/text_mel_datamodule.py	/^    def get_text(self, text, add_blank=True):$/;"	m	class:TextMelDataset
get_texts	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/cli.py	/^def get_texts(args):$/;"	f
get_user_data_dir	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/utils/utils.py	/^def get_user_data_dir(appname="matcha_tts"):$/;"	f
glm_tokenizer	steer_moe/tokenizer/glm4/web_demo.py	/^    glm_tokenizer = None$/;"	v
global_phonemizer	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/text/cleaners.py	/^global_phonemizer = phonemizer.backend.EspeakBackend($/;"	v
gr	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/app.py	/^import gradio as gr$/;"	I	nameref:module:gradio
gr	steer_moe/tokenizer/glm4/web_demo.py	/^import gradio as gr$/;"	I	nameref:module:gradio
gradient_accumulation_steps	configs/stage0.json	/^  "gradient_accumulation_steps": "auto",$/;"	s
gradient_accumulation_steps	configs/stage2.json	/^  "gradient_accumulation_steps": "auto",$/;"	s
gradient_accumulation_steps	configs/stage3.json	/^  "gradient_accumulation_steps": "auto",$/;"	s
gradient_accumulation_steps	configs/stage3_wo_offload.json	/^  "gradient_accumulation_steps": "auto",$/;"	s
gradient_clipping	configs/stage0.json	/^  "gradient_clipping": "auto",$/;"	s
gradient_clipping	configs/stage2.json	/^  "gradient_clipping": "auto",$/;"	s
gradient_clipping	configs/stage3.json	/^  "gradient_clipping": "auto",$/;"	s
gradient_clipping	configs/stage3_wo_offload.json	/^  "gradient_clipping": "auto",$/;"	s
group_dict_by_prefix	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^def group_dict_by_prefix(prefix: str, d: Dict) -> Tuple[Dict, Dict]:$/;"	f	typeref:typename:Tuple[Dict,Dict]
groupby	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^def groupby(prefix: str, d: Dict, keep_prefix: bool = False) -> Tuple[Dict, Dict]:$/;"	f	typeref:typename:Tuple[Dict,Dict]
handle_one_file	whisper_train/generate_raw_parquet_multi_processing_word.py	/^    def handle_one_file(audio_file):$/;"	f
handle_voice	whisper_train/generate_raw_parquet_multi_processing_word.py	/^def handle_voice(audio, df, audio_file_id, meta_file_type, tag):$/;"	f
handle_voice_ori	whisper_train/generate_raw_parquet_multi_processing_word.py	/^def handle_voice_ori(audio,$/;"	f
hann_window	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/hifigan/meldataset.py	/^hann_window = {}$/;"	v
hann_window	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/utils/audio.py	/^hann_window = {}$/;"	v
help	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/Makefile	/^help:  ## Show help$/;"	t
hf_hub_utils	whisper_train/main_word_correct_clips.py	/^import huggingface_hub.utils as hf_hub_utils$/;"	I	nameref:module:huggingface_hub.utils
hift_checkpoint	steer_moe/tokenizer/glm4/web_demo.py	/^    hift_checkpoint = os.path.join(args.flow_path, 'hift.pt')$/;"	v
history_state	steer_moe/tokenizer/glm4/web_demo.py	/^        history_state = gr.State([])$/;"	v
hysteresis	configs/stage0.json	/^    "hysteresis": 2,$/;"	n	object:fp16
hysteresis	configs/stage2.json	/^    "hysteresis": 2,$/;"	n	object:fp16
hysteresis	configs/stage3.json	/^    "hysteresis": 2,$/;"	n	object:fp16
hysteresis	configs/stage3_wo_offload.json	/^    "hysteresis": 2,$/;"	n	object:fp16
inference	steer_moe/tokenizer/glm4/cosyvoice/cli/model.py	/^    def inference(self, text, text_len, flow_embedding, llm_embedding=torch.zeros(0, 192),$/;"	m	class:CosyVoiceModel
inference	steer_moe/tokenizer/glm4/cosyvoice/flow/flow.py	/^    def inference(self,$/;"	m	class:MaskedDiffWithXvec
inference	steer_moe/tokenizer/glm4/cosyvoice/flow/flow_gradtts.py	/^    def inference(self,$/;"	m	class:MaskedDiffWithXvec
inference	steer_moe/tokenizer/glm4/cosyvoice/hifigan/generator.py	/^    def inference(self, mel: torch.Tensor, cache_source: torch.Tensor = torch.zeros(1, 1, 0)) ->/;"	m	class:HiFTGenerator	typeref:typename:torch.Tensor
inference	steer_moe/tokenizer/glm4/cosyvoice/llm/llm.py	/^    def inference($/;"	m	class:TransformerLM	typeref:typename:torch.Tensor
inference_cross_lingual	steer_moe/tokenizer/glm4/cosyvoice/cli/cosyvoice.py	/^    def inference_cross_lingual(self, tts_text, prompt_speech_16k):$/;"	m	class:CosyVoice
inference_fn	steer_moe/tokenizer/glm4/web_demo.py	/^    def inference_fn($/;"	f
inference_instruct	steer_moe/tokenizer/glm4/cosyvoice/cli/cosyvoice.py	/^    def inference_instruct(self, tts_text, spk_id, instruct_text):$/;"	m	class:CosyVoice
inference_sft	steer_moe/tokenizer/glm4/cosyvoice/cli/cosyvoice.py	/^    def inference_sft(self, tts_text, spk_id):$/;"	m	class:CosyVoice
inference_zero_shot	steer_moe/tokenizer/glm4/cosyvoice/cli/cosyvoice.py	/^    def inference_zero_shot(self, tts_text, prompt_text, prompt_speech_16k):$/;"	m	class:CosyVoice
init_dataset_and_dataloader	steer_moe/tokenizer/glm4/cosyvoice/utils/train_utils.py	/^def init_dataset_and_dataloader(args, configs):$/;"	f
init_distributed	steer_moe/tokenizer/glm4/cosyvoice/utils/train_utils.py	/^def init_distributed(args):$/;"	f
init_optimizer_and_scheduler	steer_moe/tokenizer/glm4/cosyvoice/utils/train_utils.py	/^def init_optimizer_and_scheduler(args, configs, model):$/;"	f
init_pooling_layer	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^    def init_pooling_layer(self, config: WhisperVQConfig):$/;"	m	class:WhisperVQEncoder
init_quantize_layer	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^    def init_quantize_layer(self, config: WhisperVQConfig, quantize_load_codebook=None):$/;"	m	class:WhisperVQEncoder
init_summarywriter	steer_moe/tokenizer/glm4/cosyvoice/utils/train_utils.py	/^def init_summarywriter(args):$/;"	f
init_weights	steer_moe/tokenizer/glm4/cosyvoice/utils/common.py	/^def init_weights(m, mean=0.0, std=0.01):$/;"	f
init_weights	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/hifigan/xutils.py	/^def init_weights(m, mean=0.0, std=0.01):$/;"	f
initial_scale_power	configs/stage0.json	/^    "initial_scale_power": 16,$/;"	n	object:fp16
initial_scale_power	configs/stage2.json	/^    "initial_scale_power": 16,$/;"	n	object:fp16
initial_scale_power	configs/stage3.json	/^    "initial_scale_power": 16,$/;"	n	object:fp16
initial_scale_power	configs/stage3_wo_offload.json	/^    "initial_scale_power": 16,$/;"	n	object:fp16
initialize_fn	steer_moe/tokenizer/glm4/web_demo.py	/^    def initialize_fn():$/;"	f
initialize_weights	steer_moe/tokenizer/glm4/cosyvoice/flow/decoder.py	/^    def initialize_weights(self):$/;"	m	class:ConditionalDecoder
initialize_weights	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/components/decoder.py	/^    def initialize_weights(self):$/;"	m	class:Decoder
inpainting_callback	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/sampling.py	/^        def inpainting_callback(args):$/;"	f	function:sample_k	file:
input_mode	steer_moe/tokenizer/glm4/web_demo.py	/^                input_mode = gr.Radio(["audio", "text"], label="Input Mode", value="audio")$/;"	v
input_tokens	steer_moe/tokenizer/glm4/web_demo.py	/^            input_tokens = gr.Textbox($/;"	v
instantiate_callbacks	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/utils/instantiators.py	/^def instantiate_callbacks(callbacks_cfg: DictConfig) -> List[Callback]:$/;"	f	typeref:typename:List[Callback]
instantiate_loggers	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/utils/instantiators.py	/^def instantiate_loggers(logger_cfg: DictConfig) -> List[Logger]:$/;"	f	typeref:typename:List[Logger]
intersperse	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/utils/utils.py	/^def intersperse(lst, item):$/;"	f
job_name	configs/stage2.json	/^    "job_name": "train_whisper"$/;"	s	object:tensorboard
json_file	whisper_train/generate_raw_parquet_multi_processing_word.py	/^        json_file = json_files[audio_files.index(audio_file)]$/;"	v
json_files	whisper_train/generate_raw_parquet_multi_processing_word.py	/^    json_files = []$/;"	v
kaldi	steer_moe/tokenizer/glm4/cosyvoice/cli/frontend.py	/^import torchaudio.compliance.kaldi as kaldi$/;"	I	nameref:module:torchaudio.compliance.kaldi
language_to_id	steer_moe/tokenizer/glm4/speech_tokenizer/generation_whisper.py	/^        def language_to_id(language: str) -> int:$/;"	f	member:WhisperGenerationMixin._retrieve_init_tokens	typeref:typename:int	file:
last_saved	whisper_train/main_word_correct_clips.py	/^    last_saved=args.last_saved$/;"	v
librosa_mel_fn	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/hifigan/meldataset.py	/^from librosa.filters import mel as librosa_mel_fn$/;"	x	nameref:unknown:mel
librosa_mel_fn	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/utils/audio.py	/^from librosa.filters import mel as librosa_mel_fn$/;"	x	nameref:unknown:mel
linear_geglu	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/blocks.py	/^def linear_geglu(x, weight, bias=None):$/;"	f
list_avaliable_spks	steer_moe/tokenizer/glm4/cosyvoice/cli/cosyvoice.py	/^    def list_avaliable_spks(self):$/;"	m	class:CosyVoice
ljspeech_example_cacher	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/app.py	/^def ljspeech_example_cacher(text, n_timesteps, mel_temp, length_scale, spk=-1):$/;"	f
load	steer_moe/tokenizer/glm4/cosyvoice/cli/model.py	/^    def load(self, llm_model, flow_model, hift_model):$/;"	m	class:CosyVoiceModel
load_audio	steer_moe/tokenizer/whisper_Lv3/whisper.py	/^def load_audio(file: str, sr: int = SAMPLE_RATE):$/;"	f
load_balancing_loss	steer_moe/utils.py	/^def load_balancing_loss(gating_scores):$/;"	f
load_bytesio_audio	steer_moe/tokenizer/whisper_Lv3/whisper.py	/^def load_bytesio_audio(content, sr: int = SAMPLE_RATE):$/;"	f
load_checkpoint	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/hifigan/xutils.py	/^def load_checkpoint(filepath, device):$/;"	f
load_config	scripts/train.py	/^def load_config(path):$/;"	f
load_config	scripts/train_layer_wise.py	/^def load_config(path: str) -> Dict:$/;"	f	typeref:typename:Dict
load_from_hub	scripts/train.py	/^def load_from_hub(model_class, repo_name, subfolder=None, revision=None, tokenizer_class=None):$/;"	f
load_generation_config	whisper_train/main_word_correct_clips.py	/^    def load_generation_config(gen_config_arg: Union[str, GenerationConfig]) -> GenerationConfig/;"	m	class:Logged_Seq2SeqTrainer	typeref:typename:GenerationConfig
load_hifigan	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/cli.py	/^def load_hifigan(checkpoint_path, device):$/;"	f
load_matcha	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/cli.py	/^def load_matcha(model_name, checkpoint_path, device):$/;"	f
load_model	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/app.py	/^def load_model(model_name, vocoder_name):$/;"	f
load_model_ui	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/app.py	/^def load_model_ui(model_type, textbox):$/;"	f
load_optimizer_state	scripts/train.py	/^def load_optimizer_state(trainer, optimizer_path):$/;"	f
load_parquet_datasets	steer_moe/utils.py	/^def load_parquet_datasets(parquet_dirs):$/;"	f
load_parquet_datasets_for_steermoe	scripts/train.py	/^def load_parquet_datasets_for_steermoe(parquet_dirs):$/;"	f
load_parquet_datasets_for_steermoe	scripts/train_layer_wise.py	/^def load_parquet_datasets_for_steermoe(parquet_dirs: List[str]) -> DatasetDict:$/;"	f	typeref:typename:DatasetDict
load_quantize_encoder	steer_moe/tokenizer/glm4/speech_tokenizer/utils.py	/^def load_quantize_encoder(model_path):$/;"	f
load_slience_data	whisper_train/generate_raw_parquet_multi_processing_word.py	/^def load_slience_data(music_dir_li, noise_dir_li):$/;"	f
load_state_dict	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/data/text_mel_datamodule.py	/^    def load_state_dict(self, state_dict: Dict[str, Any]):$/;"	m	class:TextMelDataModule
load_trainer_model	scripts/train.py	/^def load_trainer_model(model_class, model_dir, tokenizer_class=None):$/;"	f
load_vocoder	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/cli.py	/^def load_vocoder(vocoder_name, checkpoint_path, device):$/;"	f
load_wav	steer_moe/tokenizer/glm4/cosyvoice/utils/file_utils.py	/^def load_wav(wav, target_sr):$/;"	f
load_wav	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/hifigan/meldataset.py	/^def load_wav(full_path):$/;"	f
load_wav	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/utils/audio.py	/^def load_wav(full_path):$/;"	f
log	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/baselightningmodule.py	/^log = utils.get_pylogger(__name__)$/;"	v
log	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/components/flow_matching.py	/^log = get_pylogger(__name__)$/;"	v
log	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/components/text_encoder.py	/^log = utils.get_pylogger(__name__)$/;"	v
log	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/matcha_tts.py	/^log = utils.get_pylogger(__name__)$/;"	v
log	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/train.py	/^log = utils.get_pylogger(__name__)$/;"	v
log	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/utils/generate_data_statistics.py	/^log = pylogger.get_pylogger(__name__)$/;"	v
log	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/utils/instantiators.py	/^log = pylogger.get_pylogger(__name__)$/;"	v
log	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/utils/logging_utils.py	/^log = pylogger.get_pylogger(__name__)$/;"	v
log	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/utils/rich_utils.py	/^log = pylogger.get_pylogger(__name__)$/;"	v
log	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/utils/utils.py	/^log = pylogger.get_pylogger(__name__)$/;"	v
log_hyperparameters	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/utils/logging_utils.py	/^def log_hyperparameters(object_dict: Dict[str, Any]) -> None:$/;"	f	typeref:typename:None
log_mel_spectrogram	steer_moe/tokenizer/whisper_Lv3/whisper.py	/^def log_mel_spectrogram($/;"	f
log_per_save	steer_moe/tokenizer/glm4/cosyvoice/utils/train_utils.py	/^def log_per_save(writer, info_dict):$/;"	f
log_per_step	steer_moe/tokenizer/glm4/cosyvoice/utils/train_utils.py	/^def log_per_step(writer, info_dict):$/;"	f
logger	steer_moe/tokenizer/glm4/speech_tokenizer/generation_whisper.py	/^logger = logging.get_logger(__name__)$/;"	v
logger	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^logger = logging.get_logger(__name__)$/;"	v
logger	steer_moe/tokenizer/whisper_Lv3/modeling_whisper.py	/^logger = logging.get_logger(__name__)$/;"	v
logger	whisper_train/main_word_correct_clips.py	/^logger = logging.get_logger(__name__)$/;"	v
loss_scale	configs/stage0.json	/^    "loss_scale": 0,$/;"	n	object:fp16
loss_scale	configs/stage2.json	/^    "loss_scale": 0,$/;"	n	object:fp16
loss_scale	configs/stage3.json	/^    "loss_scale": 0,$/;"	n	object:fp16
loss_scale	configs/stage3_wo_offload.json	/^    "loss_scale": 0,$/;"	n	object:fp16
loss_scale_window	configs/stage0.json	/^    "loss_scale_window": 1000,$/;"	n	object:fp16
loss_scale_window	configs/stage2.json	/^    "loss_scale_window": 1000,$/;"	n	object:fp16
loss_scale_window	configs/stage3.json	/^    "loss_scale_window": 1000,$/;"	n	object:fp16
loss_scale_window	configs/stage3_wo_offload.json	/^    "loss_scale_window": 1000,$/;"	n	object:fp16
lowercase	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/text/cleaners.py	/^def lowercase(text):$/;"	f
lr	configs/stage3.json	/^      "lr": "auto",$/;"	s	object:optimizer.params
lr	configs/stage3_wo_offload.json	/^      "lr": "auto",$/;"	s	object:optimizer.params
main	scripts/example_training.py	/^def main():$/;"	f
main	scripts/train.py	/^def main():$/;"	f
main	steer_moe/tokenizer/glm4/cosyvoice/bin/inference.py	/^def main():$/;"	f
main	steer_moe/tokenizer/glm4/cosyvoice/bin/train.py	/^def main():$/;"	f
main	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/app.py	/^def main():$/;"	f
main	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/onnx/export.py	/^def main():$/;"	f
main	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/onnx/infer.py	/^def main():$/;"	f
main	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/train.py	/^def main(cfg: DictConfig) -> Optional[float]:$/;"	f	typeref:typename:Optional[float]
main	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/utils/generate_data_statistics.py	/^def main():$/;"	f
main_asr_example	steer_moe/al_models.py	/^def main_asr_example():$/;"	f
main_input_name	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^    main_input_name = "input_features"$/;"	v	class:WhisperPreTrainedModel
main_input_name	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^    main_input_name = "input_ids"$/;"	v	class:WhisperForCausalLM
main_input_name	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^    main_input_name = "input_ids"$/;"	v	class:WhisperVQDecoder
main_input_name	steer_moe/tokenizer/whisper_Lv3/modeling_whisper.py	/^    main_input_name = "input_features"$/;"	v	class:WhisperPreTrainedModel
make_cond_model_fn	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/sampling.py	/^def make_cond_model_fn(model, cond_fn):$/;"	f
make_pad_mask	steer_moe/tokenizer/glm4/cosyvoice/utils/mask.py	/^def make_pad_mask(lengths: torch.Tensor, max_len: int = 0) -> torch.Tensor:$/;"	f	typeref:typename:torch.Tensor
mask	steer_moe/tokenizer/glm4/cosyvoice/utils/block_mask_util.py	/^    mask = create_grid_mask(seq_length=8, trunck_length=3, fill_triangle=True).int()$/;"	v
max_new_token	steer_moe/tokenizer/glm4/web_demo.py	/^            max_new_token = gr.Number($/;"	v
maximum_path	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/utils/monotonic_align/__init__.py	/^def maximum_path(value, mask):$/;"	f
maximum_path_c	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/utils/monotonic_align/core.pyx	/^cpdef void maximum_path_c(int[:,:,::1] paths, float[:,:,::1] values, int[::1] t_xs, int[::1] t_y/;"	f
maximum_path_each	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/utils/monotonic_align/core.pyx	/^cdef void maximum_path_each(int[:,::1] path, float[:,::1] value, int t_x, int t_y, float max_neg/;"	f
mel_basis	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/hifigan/meldataset.py	/^mel_basis = {}$/;"	v
mel_basis	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/utils/audio.py	/^mel_basis = {}$/;"	v
mel_filters	steer_moe/tokenizer/whisper_Lv3/whisper.py	/^def mel_filters(device, n_mels: int = 128) -> torch.Tensor:$/;"	f	typeref:typename:torch.Tensor
mel_spectrogram	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/hifigan/meldataset.py	/^def mel_spectrogram(y, n_fft, num_mels, sampling_rate, hop_size, win_size, fmin, fmax, center=Fa/;"	f
mel_spectrogram	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/utils/audio.py	/^def mel_spectrogram(y, n_fft, num_mels, sampling_rate, hop_size, win_size, fmin, fmax, center=Fa/;"	f
met	whisper_train/main_word_correct_clips.py	/^    import torch_xla.debug.metrics as met$/;"	I	nameref:module:torch_xla.debug.metrics
min_loss_scale	configs/stage0.json	/^    "min_loss_scale": 1$/;"	n	object:fp16
min_loss_scale	configs/stage2.json	/^    "min_loss_scale": 1$/;"	n	object:fp16
min_loss_scale	configs/stage3.json	/^    "min_loss_scale": 1$/;"	n	object:fp16
min_loss_scale	configs/stage3_wo_offload.json	/^    "min_loss_scale": 1$/;"	n	object:fp16
model	steer_moe/models.py	/^    model = SteerMoEHybridModel($/;"	v
model	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/app.py	/^model = load_matcha(args.model, MATCHA_TTS_LOC(args.model), device)$/;"	v
model_test	whisper_train/main_word_correct_clips.py	/^def model_test():$/;"	f
module_depth	configs/stage2.json	/^    "module_depth": -1,$/;"	n	object:flops_profiler
module_depth	configs/stage3.json	/^    "module_depth": -1,$/;"	n	object:flops_profiler
module_interface_cls	tmpx07ntkc2/_remote_module_non_scriptable.py	/^module_interface_cls = None$/;"	v
monotonic_align	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/matcha_tts.py	/^import matcha.utils.monotonic_align as monotonic_align$/;"	I	nameref:module:matcha.utils.monotonic_align
mp	steer_moe/tokenizer/glm4/cosyvoice/dataset/processor.py	/^import multiprocessing as mp$/;"	I	nameref:module:multiprocessing
mse_loss	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/stable_diffusion.py	/^    def mse_loss(self, output, targets, mask):$/;"	m	class:Stable_Diffusion
mse_loss	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/stable_diffusion_test.py	/^    def mse_loss(self, output, targets, mask):$/;"	m	class:Stable_Diffusion
mse_loss_with_mask	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^def mse_loss_with_mask(input, target, mask):$/;"	f
multispeaker_example_cacher	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/app.py	/^def multispeaker_example_cacher(text, n_timesteps, mel_temp, length_scale, spk):$/;"	f
music_dir_li	whisper_train/generate_raw_parquet_multi_processing_word.py	/^    music_dir_li = [$/;"	v
music_wav_li	whisper_train/generate_raw_parquet_multi_processing_word.py	/^    music_wav_li, noise_wav_li = load_slience_data(music_dir_li, noise_dir_li)$/;"	v
natten	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer.py	/^    natten = None$/;"	v
natten	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer_use_mask.py	/^    natten = None$/;"	v
nn	cross_modal_steer/cross_modal_steering.py	/^import torch.nn as nn$/;"	I	nameref:module:torch.nn
nn	cross_modal_steer/router_comparison.py	/^import torch.nn as nn$/;"	I	nameref:module:torch.nn
nn	scripts/train_layer_wise.py	/^import torch.nn as nn$/;"	I	nameref:module:torch.nn
nn	steer_moe/al_models.py	/^import torch.nn as nn$/;"	I	nameref:module:torch.nn
nn	steer_moe/aligner.py	/^import torch.nn as nn$/;"	I	nameref:module:torch.nn
nn	steer_moe/efficient_layer_wise_whisper.py	/^import torch.nn as nn$/;"	I	nameref:module:torch.nn
nn	steer_moe/layer_wise_aligner.py	/^import torch.nn as nn$/;"	I	nameref:module:torch.nn
nn	steer_moe/layer_wise_whisper.py	/^import torch.nn as nn$/;"	I	nameref:module:torch.nn
nn	steer_moe/models.py	/^import torch.nn as nn$/;"	I	nameref:module:torch.nn
nn	steer_moe/shared_router_implementation.py	/^import torch.nn as nn$/;"	I	nameref:module:torch.nn
nn	steer_moe/tokenizer/glm4/cosyvoice/flow/decoder.py	/^import torch.nn as nn$/;"	I	nameref:module:torch.nn
nn	steer_moe/tokenizer/glm4/cosyvoice/flow/flow.py	/^import torch.nn as nn$/;"	I	nameref:module:torch.nn
nn	steer_moe/tokenizer/glm4/cosyvoice/flow/flow_gradtts.py	/^import torch.nn as nn$/;"	I	nameref:module:torch.nn
nn	steer_moe/tokenizer/glm4/cosyvoice/flow/length_regulator.py	/^import torch.nn as nn$/;"	I	nameref:module:torch.nn
nn	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^import torch.nn as nn$/;"	I	nameref:module:torch.nn
nn	steer_moe/tokenizer/glm4/cosyvoice/hifigan/f0_predictor.py	/^import torch.nn as nn$/;"	I	nameref:module:torch.nn
nn	steer_moe/tokenizer/glm4/cosyvoice/hifigan/generator.py	/^import torch.nn as nn$/;"	I	nameref:module:torch.nn
nn	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/hifigan/models.py	/^import torch.nn as nn$/;"	I	nameref:module:torch.nn
nn	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/components/decoder.py	/^import torch.nn as nn$/;"	I	nameref:module:torch.nn
nn	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/components/text_encoder.py	/^import torch.nn as nn$/;"	I	nameref:module:torch.nn
nn	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/components/transformer.py	/^import torch.nn as nn$/;"	I	nameref:module:torch.nn
noise_dir_li	whisper_train/generate_raw_parquet_multi_processing_word.py	/^    noise_dir_li = ['\/root\/autodl-tmp\/ruitao\/whisper_test\/data\/musan\/noise\/']$/;"	v
noise_wav_li	whisper_train/generate_raw_parquet_multi_processing_word.py	/^    music_wav_li, noise_wav_li = load_slience_data(music_dir_li, noise_dir_li)$/;"	v
normalize	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/blocks.py	/^def normalize(x, eps=1e-4):$/;"	f
normalize	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/utils/model.py	/^def normalize(data, mu, std):$/;"	f
normalize_numbers	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/text/numbers.py	/^def normalize_numbers(text):$/;"	f
np	scripts/train_layer_wise.py	/^import numpy as np$/;"	I	nameref:module:numpy
np	steer_moe/al_models.py	/^    import numpy as np$/;"	I	nameref:module:numpy
np	steer_moe/tokenizer/glm4/audio_process.py	/^import numpy as np$/;"	I	nameref:module:numpy
np	steer_moe/tokenizer/glm4/cosyvoice/cli/frontend.py	/^import numpy as np$/;"	I	nameref:module:numpy
np	steer_moe/tokenizer/glm4/cosyvoice/dataset/processor.py	/^import numpy as np$/;"	I	nameref:module:numpy
np	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/blocks.py	/^import numpy as np$/;"	I	nameref:module:numpy
np	steer_moe/tokenizer/glm4/cosyvoice/hifigan/generator.py	/^import numpy as np$/;"	I	nameref:module:numpy
np	steer_moe/tokenizer/glm4/cosyvoice/transformer/embedding.py	/^import numpy as np$/;"	I	nameref:module:numpy
np	steer_moe/tokenizer/glm4/flow_inference.py	/^import numpy as np$/;"	I	nameref:module:numpy
np	steer_moe/tokenizer/glm4/speech_tokenizer/generation_whisper.py	/^import numpy as np$/;"	I	nameref:module:numpy
np	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^                import numpy as np$/;"	I	member:WhisperVQEncoder.forward	file:	nameref:module:numpy
np	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^import numpy as np$/;"	I	nameref:module:numpy
np	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/cli.py	/^import numpy as np$/;"	I	nameref:module:numpy
np	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/hifigan/meldataset.py	/^import numpy as np$/;"	I	nameref:module:numpy
np	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/onnx/export.py	/^import numpy as np$/;"	I	nameref:module:numpy
np	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/onnx/infer.py	/^import numpy as np$/;"	I	nameref:module:numpy
np	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/utils/audio.py	/^import numpy as np$/;"	I	nameref:module:numpy
np	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/utils/model.py	/^import numpy as np$/;"	I	nameref:module:numpy
np	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/utils/monotonic_align/__init__.py	/^import numpy as np$/;"	I	nameref:module:numpy
np	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/utils/monotonic_align/core.pyx	/^cimport numpy as np$/;"	I	nameref:module:numpy
np	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/utils/monotonic_align/core.pyx	/^import numpy as np$/;"	I	nameref:module:numpy
np	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/utils/utils.py	/^import numpy as np$/;"	I	nameref:module:numpy
np	steer_moe/tokenizer/whisper_Lv3/modeling_whisper.py	/^import numpy as np$/;"	I	nameref:module:numpy
np	steer_moe/tokenizer/whisper_Lv3/whisper.py	/^import numpy as np$/;"	I	nameref:module:numpy
np	whisper_train/main_word_correct_clips.py	/^import numpy as np$/;"	I	nameref:module:numpy
offline_inference	steer_moe/tokenizer/glm4/flow_inference.py	/^    def offline_inference(self, token):$/;"	m	class:AudioDecoder
offload_optimizer	configs/stage3.json	/^    "offload_optimizer": {$/;"	o	object:zero_optimization
offload_param	configs/stage3.json	/^    "offload_param": {$/;"	o	object:zero_optimization
offset	whisper_train/pre_process_word_correct_data.py	/^        offset=(len(processed_batchs)\/\/batch_size*batch_size)$/;"	v
on_before_optimizer_step	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/baselightningmodule.py	/^    def on_before_optimizer_step(self, optimizer):$/;"	m	class:BaseLightningClass
on_load_checkpoint	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/baselightningmodule.py	/^    def on_load_checkpoint(self, checkpoint: Dict[str, Any]) -> None:$/;"	m	class:BaseLightningClass	typeref:typename:None
on_save	whisper_train/main_word_correct_clips.py	/^        def on_save($/;"	m	class:train_lora.SavePeftModelCallback
on_save	whisper_train/main_word_correct_clips.py	/^        def on_save($/;"	m	class:train_lora_in_8bit.SavePeftModelCallback
on_step_end	scripts/train_layer_wise.py	/^    def on_step_end(self, args, state, control, **kwargs):$/;"	m	class:GradientClippingCallback
on_step_end	scripts/train_layer_wise.py	/^    def on_step_end(self, args, state, control, **kwargs):$/;"	m	class:SteeringAnalysisCallback
on_validation_end	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/baselightningmodule.py	/^    def on_validation_end(self) -> None:$/;"	m	class:BaseLightningClass	typeref:typename:None
onnx_forward_func	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/onnx/export.py	/^    def onnx_forward_func(x, x_lengths, scales, spks=None):$/;"	f	function:get_exportable_module	file:
optim	steer_moe/tokenizer/glm4/cosyvoice/utils/train_utils.py	/^import torch.optim as optim$/;"	I	nameref:module:torch.optim
optimizer	configs/stage3.json	/^  "optimizer": {$/;"	o
optimizer	configs/stage3_wo_offload.json	/^  "optimizer": {$/;"	o
or_reduce	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer.py	/^def or_reduce(masks):$/;"	f
or_reduce	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer_use_mask.py	/^def or_reduce(masks):$/;"	f
ori_parquet_dir	whisper_train/generate_raw_parquet_multi_processing_word.py	/^    ori_parquet_dir = f'\/root\/autodl-nas\/ruitao\/data\/train\/origin_parquet\/{batch_tag}'$/;"	v
ori_parquet_dir	whisper_train/pre_process_word_correct_data.py	/^    ori_parquet_dir = f'\/root\/autodl-nas\/ruitao\/data\/train\/origin_parquet\/{batch_tag}'$/;"	v
ort	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/onnx/infer.py	/^import onnxruntime as ort$/;"	I	nameref:module:onnxruntime
output	steer_moe/models.py	/^    output = model($/;"	v
output_audio	steer_moe/tokenizer/glm4/web_demo.py	/^                output_audio = gr.Audio(label="Play", streaming=True,$/;"	v
output_dir	whisper_train/main_word_correct_clips.py	/^        output_dir = f'\/root\/autodl-tmp\/ruitao\/whisper_test\/model\/whisper_large_v2_{batch_/;"	v
output_file	configs/stage2.json	/^    "output_file": null$/;"	z	object:flops_profiler
output_file	configs/stage3.json	/^    "output_file": null$/;"	z	object:flops_profiler
output_path	configs/stage2.json	/^    "output_path": "..\/log\/ds_logs\/",$/;"	s	object:tensorboard
output_size	steer_moe/tokenizer/glm4/cosyvoice/transformer/encoder.py	/^    def output_size(self) -> int:$/;"	m	class:BaseEncoder	typeref:typename:int
overlap_comm	configs/stage2.json	/^    "overlap_comm": false,$/;"	b	object:zero_optimization
overlap_comm	configs/stage3.json	/^    "overlap_comm": true,$/;"	b	object:zero_optimization
overlap_comm	configs/stage3_wo_offload.json	/^    "overlap_comm": true,$/;"	b	object:zero_optimization
pad1d	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^def pad1d(x: torch.Tensor, paddings: tp.Tuple[int, int], mode: str = 'constant', value: float = /;"	f
pad_and_create_mask	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/stable_diffusion.py	/^def pad_and_create_mask(matrix, target_length):$/;"	f
pad_and_create_mask	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/stable_diffusion_test.py	/^def pad_and_create_mask(matrix, target_length):$/;"	f
pad_for_conv1d	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^def pad_for_conv1d(x: torch.Tensor, kernel_size: int, stride: int, padding_total: int = 0):$/;"	f
pad_list	steer_moe/tokenizer/glm4/cosyvoice/utils/common.py	/^def pad_list(xs: List[torch.Tensor], pad_value: int):$/;"	f
pad_or_trim	steer_moe/tokenizer/whisper_Lv3/whisper.py	/^def pad_or_trim(array, length: int = N_SAMPLES, *, axis: int = -1):$/;"	f
pad_unpad_sequence	steer_moe/tokenizer/glm4/cosyvoice/llm/llm.py	/^    def pad_unpad_sequence(self, sos_eos_emb, embedding, text_token, text_token_len, task_id_emb/;"	m	class:TransformerLM
padding	steer_moe/tokenizer/glm4/cosyvoice/dataset/processor.py	/^def padding(data, use_spk_embedding, mode='train'):$/;"	f
padding_speech_token	steer_moe/tokenizer/glm4/cosyvoice/dataset/processor.py	/^def padding_speech_token(data, use_spk_embedding, mode='train'):$/;"	f
padding_speech_token_spk	steer_moe/tokenizer/glm4/cosyvoice/dataset/processor.py	/^def padding_speech_token_spk(data, use_spk_embedding, mode='train'):$/;"	f
params	configs/stage3.json	/^    "params": {$/;"	o	object:optimizer
params	configs/stage3.json	/^    "params": {$/;"	o	object:scheduler
params	configs/stage3_wo_offload.json	/^    "params": {$/;"	o	object:optimizer
params	configs/stage3_wo_offload.json	/^    "params": {$/;"	o	object:scheduler
parquet_folder	whisper_train/main_word_correct_clips.py	/^        parquet_folder=processed_parquet_dir$/;"	v
parquet_opener	steer_moe/tokenizer/glm4/cosyvoice/dataset/processor.py	/^def parquet_opener(data, mode='train', tts_data={}):$/;"	f
parse_embedding	steer_moe/tokenizer/glm4/cosyvoice/dataset/processor.py	/^def parse_embedding(data, normalize, mode='train'):$/;"	f
parse_filelist	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/data/text_mel_datamodule.py	/^def parse_filelist(filelist_path, split_char="|"):$/;"	f
parse_tar_header	steer_moe/tokenizer/glm4/cosyvoice/dataset/processor.py	/^def parse_tar_header(header_bytes):$/;"	f
parser	scripts/batch_infer.py	/^    parser = argparse.ArgumentParser(description='Batch inference\/evaluation for SteerMoE')$/;"	v
parser	scripts/train_layer_wise.py	/^    parser = argparse.ArgumentParser(description='Train SteerMoE with layer-wise steering')$/;"	v
parser	steer_moe/tokenizer/glm4/model_server.py	/^    parser = argparse.ArgumentParser()$/;"	v
parser	steer_moe/tokenizer/glm4/web_demo.py	/^    parser = ArgumentParser()$/;"	v
parser	whisper_train/generate_raw_parquet_multi_processing_word.py	/^    parser = argparse.ArgumentParser()$/;"	v
parser	whisper_train/main_word_correct_clips.py	/^    parser = argparse.ArgumentParser()$/;"	v
parser	whisper_train/pre_process_word_correct_data.py	/^    parser = argparse.ArgumentParser()$/;"	v
pd	whisper_train/generate_raw_parquet_multi_processing_word.py	/^import pandas as pd$/;"	I	nameref:module:pandas
pd	whisper_train/pre_process_word_correct_data.py	/^import pandas as pd$/;"	I	nameref:module:pandas
pin_memory	configs/stage3.json	/^      "pin_memory": true$/;"	b	object:zero_optimization.offload_optimizer
pin_memory	configs/stage3.json	/^      "pin_memory": true$/;"	b	object:zero_optimization.offload_param
plot_spectrogram	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/hifigan/xutils.py	/^def plot_spectrogram(spectrogram):$/;"	f
plot_spectrogram_to_numpy	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/cli.py	/^def plot_spectrogram_to_numpy(spectrogram, filename):$/;"	f
plot_tensor	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/utils/utils.py	/^def plot_tensor(tensor):$/;"	f
plt	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/cli.py	/^import matplotlib.pyplot as plt$/;"	I	nameref:module:matplotlib.pyplot
plt	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/hifigan/xutils.py	/^import matplotlib.pylab as plt$/;"	I	nameref:module:matplotlib.pylab
plt	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/utils/utils.py	/^import matplotlib.pyplot as plt$/;"	I	nameref:module:matplotlib.pyplot
position_encoding	steer_moe/tokenizer/glm4/cosyvoice/transformer/embedding.py	/^    def position_encoding(self, offset: Union[int, torch.Tensor],$/;"	m	class:NoPositionalEncoding	typeref:typename:torch.Tensor
position_encoding	steer_moe/tokenizer/glm4/cosyvoice/transformer/embedding.py	/^    def position_encoding(self,$/;"	m	class:EspnetRelPositionalEncoding	typeref:typename:torch.Tensor
position_encoding	steer_moe/tokenizer/glm4/cosyvoice/transformer/embedding.py	/^    def position_encoding(self,$/;"	m	class:PositionalEncoding	typeref:typename:torch.Tensor
position_encoding	steer_moe/tokenizer/glm4/cosyvoice/transformer/subsampling.py	/^    def position_encoding(self, offset: Union[int, torch.Tensor],$/;"	m	class:BaseSubsampling	typeref:typename:torch.Tensor
pq	steer_moe/tokenizer/glm4/cosyvoice/dataset/processor.py	/^import pyarrow.parquet as pq$/;"	I	nameref:module:pyarrow.parquet
predict	whisper_train/main_word_correct_clips.py	/^    def predict($/;"	m	class:Logged_Seq2SeqTrainer	typeref:typename:"PredictionOutput"
prediction_step	whisper_train/main_word_correct_clips.py	/^    def prediction_step($/;"	m	class:Logged_Seq2SeqTrainer	typeref:typename:Tuple[Optional[float],Optional[torch.Tensor],Optional[torch.Tensor]]
prepare_asr_dataset	scripts/train.py	/^def prepare_asr_dataset(dataset, audio_column, text_column, whisper_encoder, tokenizer, sample_r/;"	f
prepare_asr_dataset	scripts/train_layer_wise.py	/^def prepare_asr_dataset(dataset, audio_column: str, text_column: str,$/;"	f
prepare_dataset	steer_moe/utils.py	/^def prepare_dataset(batch, audio_column, text_column, whisper_processor, tokenizer, sample_rate=/;"	f
prepare_inputs_for_generation	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^    def prepare_inputs_for_generation($/;"	m	class:WhisperForCausalLM
prepare_inputs_for_generation	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^    def prepare_inputs_for_generation($/;"	m	class:WhisperVQForConditionalGeneration
print_config	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/cli.py	/^def print_config(args):$/;"	f
print_config_tree	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/utils/rich_utils.py	/^def print_config_tree($/;"	f	typeref:typename:None
process	steer_moe/tokenizer/glm4/audio_process.py	/^    def process(self, audio_data, last=False):$/;"	m	class:AudioStreamProcessor
process_list_in_parallel	whisper_train/generate_raw_parquet_multi_processing_word.py	/^    def process_list_in_parallel(ls):$/;"	f
process_sft_vq0918_pool2	steer_moe/tokenizer/glm4/cosyvoice/dataset/processor.py	/^def process_sft_vq0918_pool2(data, mode='train', tts_data={}):$/;"	f
process_sft_vq0918_pool2_split	steer_moe/tokenizer/glm4/cosyvoice/dataset/processor.py	/^def process_sft_vq0918_pool2_split(data, mode='train',split_token=50, tts_data={}):$/;"	f
process_sft_vq0918_pool4	steer_moe/tokenizer/glm4/cosyvoice/dataset/processor.py	/^def process_sft_vq0918_pool4(data, mode='train', tts_data={}):$/;"	f
process_sft_vq0918_pool4_gpt	steer_moe/tokenizer/glm4/cosyvoice/dataset/processor.py	/^def process_sft_vq0918_pool4_gpt(data, mode='train', tts_data={}):$/;"	f
process_sft_vq0918_pool4_gpt_1010	steer_moe/tokenizer/glm4/cosyvoice/dataset/processor.py	/^def process_sft_vq0918_pool4_gpt_1010(data, mode='train', tts_data={}):$/;"	f
process_sft_vq0918_pool4_split	steer_moe/tokenizer/glm4/cosyvoice/dataset/processor.py	/^def process_sft_vq0918_pool4_split(data, mode='train',split_token=25, tts_data={}):$/;"	f
process_text	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/cli.py	/^def process_text(i: int, text: str, device: torch.device):$/;"	f
process_text_gradio	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/app.py	/^def process_text_gradio(text):$/;"	f
processed_batch	whisper_train/pre_process_word_correct_data.py	/^        processed_batch = [{'file': file} for file in batch]$/;"	v
processed_batchs	whisper_train/pre_process_word_correct_data.py	/^    processed_batchs = []$/;"	v
processed_batchs	whisper_train/pre_process_word_correct_data.py	/^    processed_batchs = [file.split('\/')[-1] for file in processed_batchs]$/;"	v
processed_batchs_df	whisper_train/pre_process_word_correct_data.py	/^    processed_batchs_df = os.listdir(processed_status_dir)$/;"	v
processed_data	whisper_train/pre_process_word_correct_data.py	/^processed_data = []$/;"	v
processed_parquet_dir	whisper_train/generate_raw_parquet_multi_processing_word.py	/^    processed_parquet_dir = f'\/root\/autodl-nas\/ruitao\/data\/train\/processed_parquet\/{batch/;"	v
processed_parquet_dir	whisper_train/main_word_correct_clips.py	/^        processed_parquet_dir = f'\/root\/autodl-nas\/ruitao\/data\/train\/processed_parquet\/{b/;"	v
processed_parquet_dir	whisper_train/pre_process_word_correct_data.py	/^    processed_parquet_dir = f'\/root\/autodl-nas\/ruitao\/data\/train\/processed_parquet\/{batch/;"	v
processed_parquet_prefix	whisper_train/generate_raw_parquet_multi_processing_word.py	/^    processed_parquet_prefix = f'\/root\/autodl-nas\/ruitao\/data\/train\/processed_parquet\/'$/;"	v
processed_parquet_prefix	whisper_train/pre_process_word_correct_data.py	/^    processed_parquet_prefix = f'\/root\/autodl-nas\/ruitao\/data\/train\/processed_parquet\/'$/;"	v
processed_status_dir	whisper_train/pre_process_word_correct_data.py	/^    processed_status_dir = f'\/root\/autodl-nas\/ruitao\/data\/train\/'$/;"	v
profile_step	configs/stage2.json	/^    "profile_step": 1,$/;"	n	object:flops_profiler
profile_step	configs/stage3.json	/^    "profile_step": 1,$/;"	n	object:flops_profiler
prompts	steer_moe/models.py	/^    prompts = model($/;"	v
push_to_hub	scripts/train.py	/^def push_to_hub(output_dir, repo_name, token=None, private=True):$/;"	f
put	steer_moe/tokenizer/glm4/model_server.py	/^    def put(self, value):$/;"	m	class:TokenStreamer
put_cos	whisper_train/generate_raw_parquet_multi_processing_word.py	/^def put_cos(f_parquet, meta_file_name, meta_file_id, client):$/;"	f
quantized_token_ids	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^    quantized_token_ids: Optional[torch.LongTensor] = None$/;"	v	class:QuantizedBaseModelOutput	typeref:typename:Optional[torch.LongTensor]
rand_bool	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^def rand_bool(shape: Any, proba: float, device: Any = None) -> Tensor:$/;"	f	typeref:typename:Tensor
read	steer_moe/tokenizer/glm4/cosyvoice/dataset/processor.py	/^    def read(self, name: str) -> bytes:$/;"	m	class:Tar	typeref:typename:bytes
read_json_lists	steer_moe/tokenizer/glm4/cosyvoice/utils/file_utils.py	/^def read_json_lists(list_file):$/;"	f
read_lists	steer_moe/tokenizer/glm4/cosyvoice/utils/file_utils.py	/^def read_lists(list_file):$/;"	f
reduce_bucket_size	configs/stage2.json	/^    "reduce_bucket_size": 2e8,$/;"	n	object:zero_optimization
reduce_bucket_size	configs/stage3.json	/^    "reduce_bucket_size": "auto",$/;"	s	object:zero_optimization
reduce_bucket_size	configs/stage3_wo_offload.json	/^    "reduce_bucket_size": "auto",$/;"	s	object:zero_optimization
reduce_scatter	configs/stage2.json	/^    "reduce_scatter": true,$/;"	b	object:zero_optimization
refine_mask	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer_use_mask.py	/^    def refine_mask(self, mask):$/;"	m	class:ContinuousTransformer
rel_shift	steer_moe/tokenizer/glm4/cosyvoice/transformer/attention.py	/^    def rel_shift(self, x):$/;"	m	class:RelPositionMultiHeadedAttention
rel_shift	steer_moe/tokenizer/glm4/cosyvoice/transformer/attention.py	/^    def rel_shift(self, x: torch.Tensor) -> torch.Tensor:$/;"	m	class:BlockRelPositionMultiHeadedAttention	typeref:typename:torch.Tensor
remove_bracket	steer_moe/tokenizer/glm4/cosyvoice/utils/frontend_utils.py	/^def remove_bracket(text):$/;"	f
remove_weight_norm	steer_moe/tokenizer/glm4/cosyvoice/hifigan/generator.py	/^    def remove_weight_norm(self):$/;"	m	class:HiFTGenerator
remove_weight_norm	steer_moe/tokenizer/glm4/cosyvoice/hifigan/generator.py	/^    def remove_weight_norm(self):$/;"	m	class:ResBlock
remove_weight_norm	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/hifigan/models.py	/^    def remove_weight_norm(self):$/;"	m	class:Generator
remove_weight_norm	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/hifigan/models.py	/^    def remove_weight_norm(self):$/;"	m	class:ResBlock1
remove_weight_norm	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/hifigan/models.py	/^    def remove_weight_norm(self):$/;"	m	class:ResBlock2
replace_blank	steer_moe/tokenizer/glm4/cosyvoice/utils/frontend_utils.py	/^def replace_blank(text: str):$/;"	f
replace_corner_mark	steer_moe/tokenizer/glm4/cosyvoice/utils/frontend_utils.py	/^def replace_corner_mark(text):$/;"	f
replace_or_add	steer_moe/tokenizer/glm4/speech_tokenizer/generation_whisper.py	/^        def replace_or_add(lst: List[int], num: int, itr: Iterator[int]):$/;"	f	member:WhisperGenerationMixin._retrieve_init_tokens	file:
resample	steer_moe/tokenizer/glm4/cosyvoice/dataset/processor.py	/^def resample(data, resample_rate=22050, min_sample_rate=16000, mode='train'):$/;"	f
reset_btn	steer_moe/tokenizer/glm4/web_demo.py	/^                reset_btn = gr.Button("Clear")$/;"	v
respond	steer_moe/tokenizer/glm4/web_demo.py	/^        respond = submit_btn.click($/;"	v
resume_from_model	whisper_train/main_word_correct_clips.py	/^        resume_from_model = f'\/root\/autodl-tmp\/ruitao\/whisper_test\/model\/whisper_large_v2_/;"	v
rms_norm	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/blocks.py	/^def rms_norm(x, scale, eps):$/;"	f
rotate_half	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer.py	/^def rotate_half(x):$/;"	f
rotate_half	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/transformer_use_mask.py	/^def rotate_half(x):$/;"	f
rpc	tmpx07ntkc2/_remote_module_non_scriptable.py	/^import torch.distributed.rpc as rpc$/;"	I	nameref:module:torch.distributed.rpc
sample	steer_moe/tokenizer/glm4/cosyvoice/dataset/dataset.py	/^    def sample(self, data):$/;"	m	class:DistributedSampler
sample	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/sampling.py	/^def sample(model, x, steps, eta, **extra_args):$/;"	f
sample_discrete_euler	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/sampling.py	/^def sample_discrete_euler(model, x, steps, sigma_max=1, **extra_args):$/;"	f
sample_k	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/sampling.py	/^def sample_k($/;"	f
sample_rf	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/sampling.py	/^def sample_rf($/;"	f
sampling_ids	steer_moe/tokenizer/glm4/cosyvoice/llm/llm.py	/^    def sampling_ids($/;"	m	class:TransformerLM
save_checkpoint	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/hifigan/xutils.py	/^def save_checkpoint(filepath, obj):$/;"	f
save_dir	whisper_train/main_word_correct_clips.py	/^        save_dir = f'\/root\/autodl-tmp\/ruitao\/whisper_test\/model\/whisper_large_v2_{batch_ta/;"	v
save_figure_to_numpy	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/utils/utils.py	/^def save_figure_to_numpy(fig):$/;"	f
save_model	steer_moe/tokenizer/glm4/cosyvoice/utils/train_utils.py	/^def save_model(model, model_name, info_dict):$/;"	f
save_optimizer_state	scripts/train.py	/^def save_optimizer_state(trainer, output_dir):$/;"	f
save_plot	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/utils/utils.py	/^def save_plot(tensor, savepath):$/;"	f
save_to_folder	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/cli.py	/^def save_to_folder(filename: str, output: dict, folder: str):$/;"	f
save_trainer_model	scripts/train.py	/^def save_trainer_model(trainer, output_dir):$/;"	f
scan_checkpoint	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/hifigan/xutils.py	/^def scan_checkpoint(cp_dir, prefix):$/;"	f
scheduler	configs/stage3.json	/^  "scheduler": {$/;"	o
scheduler	configs/stage3_wo_offload.json	/^  "scheduler": {$/;"	o
scheduler	steer_moe/tokenizer/glm4/cosyvoice/utils/train_utils.py	/^        def scheduler(opt):$/;"	f	function:init_optimizer_and_scheduler	file:
sequence_mask	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/utils/model.py	/^def sequence_mask(length, max_length=None):$/;"	f
sequence_to_text	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/text/__init__.py	/^def sequence_to_text(sequence):$/;"	f
set_chunk_feed_forward	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/components/transformer.py	/^    def set_chunk_feed_forward(self, chunk_size: Optional[int], dim: int):$/;"	m	class:BasicTransformerBlock
set_decoder	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^    def set_decoder(self, decoder):$/;"	m	class:WhisperForCausalLM
set_epoch	steer_moe/tokenizer/glm4/cosyvoice/dataset/dataset.py	/^    def set_epoch(self, epoch):$/;"	m	class:DataList
set_epoch	steer_moe/tokenizer/glm4/cosyvoice/dataset/dataset.py	/^    def set_epoch(self, epoch):$/;"	m	class:DistributedSampler
set_epoch	steer_moe/tokenizer/glm4/cosyvoice/dataset/dataset.py	/^    def set_epoch(self, epoch):$/;"	m	class:Processor
set_input_embeddings	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^    def set_input_embeddings(self, value):$/;"	m	class:WhisperDecoderWrapper
set_input_embeddings	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^    def set_input_embeddings(self, value):$/;"	m	class:WhisperForCausalLM
set_input_embeddings	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^    def set_input_embeddings(self, value):$/;"	m	class:WhisperVQDecoder
set_input_embeddings	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^    def set_input_embeddings(self, value):$/;"	m	class:WhisperVQModel
set_input_embeddings	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^    def set_input_embeddings(self, value: nn.Module):$/;"	m	class:WhisperForAudioClassification
set_input_embeddings	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^    def set_input_embeddings(self, value: nn.Module):$/;"	m	class:WhisperVQEncoder
set_input_embeddings	steer_moe/tokenizer/whisper_Lv3/modeling_whisper.py	/^    def set_input_embeddings(self, value):$/;"	m	class:WhisperDecoder
set_input_embeddings	steer_moe/tokenizer/whisper_Lv3/modeling_whisper.py	/^    def set_input_embeddings(self, value):$/;"	m	class:WhisperModel
set_input_embeddings	steer_moe/tokenizer/whisper_Lv3/modeling_whisper.py	/^    def set_input_embeddings(self, value: nn.Module):$/;"	m	class:WhisperEncoder
set_output_embeddings	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^    def set_output_embeddings(self, new_embeddings):$/;"	m	class:WhisperForCausalLM
set_output_embeddings	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^    def set_output_embeddings(self, new_embeddings):$/;"	m	class:WhisperVQForConditionalGeneration
set_step	steer_moe/tokenizer/glm4/cosyvoice/utils/scheduler.py	/^    def set_step(self, step: int):$/;"	m	class:ConstantLR
set_step	steer_moe/tokenizer/glm4/cosyvoice/utils/scheduler.py	/^    def set_step(self, step: int):$/;"	m	class:NoamHoldAnnealing
set_step	steer_moe/tokenizer/glm4/cosyvoice/utils/scheduler.py	/^    def set_step(self, step: int):$/;"	m	class:WarmupLR
setup	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/data/text_mel_datamodule.py	/^    def setup(self, stage: Optional[str] = None):  # pylint: disable=unused-argument$/;"	m	class:TextMelDataModule
sf	scripts/batch_infer.py	/^        import soundfile as sf$/;"	I	function:batch_infer	file:	nameref:module:soundfile
sf	scripts/train.py	/^    import soundfile as sf$/;"	I	function:example_inference	file:	nameref:module:soundfile
sf	steer_moe/al_models.py	/^             import soundfile as sf$/;"	I	function:main_asr_example	file:	nameref:module:soundfile
sf	steer_moe/tokenizer/glm4/audio_process.py	/^import soundfile as sf$/;"	I	nameref:module:soundfile
sf	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/app.py	/^import soundfile as sf$/;"	I	nameref:module:soundfile
sf	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/cli.py	/^import soundfile as sf$/;"	I	nameref:module:soundfile
sf	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/onnx/infer.py	/^import soundfile as sf$/;"	I	nameref:module:soundfile
sf	steer_moe/utils.py	/^        import soundfile as sf$/;"	I	function:prepare_dataset	file:	nameref:module:soundfile
shift_tokens_right	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^def shift_tokens_right(input_ids: torch.Tensor, pad_token_id: int, decoder_start_token_id: int):$/;"	f
shift_tokens_right	steer_moe/tokenizer/whisper_Lv3/modeling_whisper.py	/^def shift_tokens_right($/;"	f
should_merge	steer_moe/tokenizer/glm4/cosyvoice/utils/frontend_utils.py	/^    def should_merge(_text: str):$/;"	f	function:split_paragraph	file:
shuffle	steer_moe/tokenizer/glm4/cosyvoice/dataset/processor.py	/^def shuffle(data, shuffle_size=10000, mode='train'):$/;"	f
sinusoids	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^def sinusoids(length: int, channels: int, max_timescale: float = 10000) -> torch.Tensor:$/;"	f	typeref:typename:torch.Tensor
smp	whisper_train/main_word_correct_clips.py	/^    import smdistributed.modelparallel.torch as smp$/;"	I	nameref:module:smdistributed.modelparallel.torch
snake_beta	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/blocks.py	/^def snake_beta(x, alpha, beta):$/;"	f
solve_euler	steer_moe/tokenizer/glm4/cosyvoice/flow/flow_matching.py	/^    def solve_euler(self, x, t_span, mu, mask, spks, cond):$/;"	m	class:ConditionalCFM
solve_euler	steer_moe/tokenizer/glm4/cosyvoice/flow/flow_matching_dit.py	/^    def solve_euler(self, x, t_span, mu, mask, spks, cond):$/;"	m	class:ConditionalCFM
solve_euler	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/components/flow_matching.py	/^    def solve_euler(self, x, t_span, mu, mask, spks, cond):$/;"	m	class:BASECFM
sort	steer_moe/tokenizer/glm4/cosyvoice/dataset/processor.py	/^def sort(data, sort_size=500, mode='train'):$/;"	f
spectral_de_normalize_torch	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/hifigan/meldataset.py	/^def spectral_de_normalize_torch(magnitudes):$/;"	f
spectral_de_normalize_torch	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/utils/audio.py	/^def spectral_de_normalize_torch(magnitudes):$/;"	f
spectral_normalize_torch	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/hifigan/meldataset.py	/^def spectral_normalize_torch(magnitudes):$/;"	f
spectral_normalize_torch	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/utils/audio.py	/^def spectral_normalize_torch(magnitudes):$/;"	f
speed_change	steer_moe/tokenizer/glm4/cosyvoice/utils/file_utils.py	/^def speed_change(waveform, sample_rate, speed_factor: str):$/;"	f
spell_out_number	steer_moe/tokenizer/glm4/cosyvoice/utils/frontend_utils.py	/^def spell_out_number(text: str, inflect_parser):$/;"	f
split_by_batch_index	steer_moe/tokenizer/glm4/speech_tokenizer/generation_whisper.py	/^        def split_by_batch_index(values, key, batch_idx, is_shortform):$/;"	f	member:WhisperGenerationMixin._postprocess_outputs	file:
split_paragraph	steer_moe/tokenizer/glm4/cosyvoice/utils/frontend_utils.py	/^def split_paragraph(text: str, tokenize, lang="zh", token_max_n=80, token_min_n=60, merge_len=20/;"	f
stage	configs/stage0.json	/^    "stage": 0$/;"	n	object:zero_optimization
stage	configs/stage2.json	/^    "stage": 2,$/;"	n	object:zero_optimization
stage	configs/stage3.json	/^    "stage": 3,$/;"	n	object:zero_optimization
stage	configs/stage3_wo_offload.json	/^    "stage": 3,$/;"	n	object:zero_optimization
stage3_gather_16bit_weights_on_model_save	configs/stage3.json	/^    "stage3_gather_16bit_weights_on_model_save": false$/;"	b	object:zero_optimization
stage3_gather_16bit_weights_on_model_save	configs/stage3_wo_offload.json	/^    "stage3_gather_16bit_weights_on_model_save": false$/;"	b	object:zero_optimization
stage3_max_live_parameters	configs/stage3.json	/^    "stage3_max_live_parameters": 1e9,$/;"	n	object:zero_optimization
stage3_max_live_parameters	configs/stage3_wo_offload.json	/^    "stage3_max_live_parameters": 1e9,$/;"	n	object:zero_optimization
stage3_max_reuse_distance	configs/stage3.json	/^    "stage3_max_reuse_distance": 1e9,$/;"	n	object:zero_optimization
stage3_max_reuse_distance	configs/stage3_wo_offload.json	/^    "stage3_max_reuse_distance": 1e9,$/;"	n	object:zero_optimization
stage3_param_persistence_threshold	configs/stage3.json	/^    "stage3_param_persistence_threshold": "auto",$/;"	s	object:zero_optimization
stage3_param_persistence_threshold	configs/stage3_wo_offload.json	/^    "stage3_param_persistence_threshold": "auto",$/;"	s	object:zero_optimization
stage3_prefetch_bucket_size	configs/stage3.json	/^    "stage3_prefetch_bucket_size": "auto",$/;"	s	object:zero_optimization
stage3_prefetch_bucket_size	configs/stage3_wo_offload.json	/^    "stage3_prefetch_bucket_size": "auto",$/;"	s	object:zero_optimization
start_app	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/Makefile	/^start_app: ## Start the app$/;"	t
state_dict	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/data/text_mel_datamodule.py	/^    def state_dict(self):  # pylint: disable=no-self-use$/;"	m	class:TextMelDataModule
static_batch	steer_moe/tokenizer/glm4/cosyvoice/dataset/processor.py	/^def static_batch(data, batch_size=16):$/;"	f
steps_per_print	configs/stage3.json	/^  "steps_per_print": 5,$/;"	n
steps_per_print	configs/stage3_wo_offload.json	/^  "steps_per_print": 5,$/;"	n
stft_fn	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/hifigan/denoiser.py	/^        def stft_fn(audio, n_fft, hop_length, win_length, window):$/;"	f	member:Denoiser.__init__	file:
stream_inference	steer_moe/tokenizer/glm4/flow_inference.py	/^    def stream_inference(self, token):$/;"	m	class:AudioDecoder
sub_group_size	configs/stage3.json	/^    "sub_group_size": 1e9,$/;"	n	object:zero_optimization
sub_group_size	configs/stage3_wo_offload.json	/^    "sub_group_size": 1e9,$/;"	n	object:zero_optimization
submit_btn	steer_moe/tokenizer/glm4/web_demo.py	/^                submit_btn = gr.Button("Submit")$/;"	v
subsequent_chunk_mask	steer_moe/tokenizer/glm4/cosyvoice/utils/mask.py	/^def subsequent_chunk_mask($/;"	f	typeref:typename:torch.Tensor
subsequent_mask	steer_moe/tokenizer/glm4/cosyvoice/utils/mask.py	/^def subsequent_mask($/;"	f	typeref:typename:torch.Tensor
supports_gradient_checkpointing	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^    supports_gradient_checkpointing = True$/;"	v	class:WhisperPreTrainedModel
supports_gradient_checkpointing	steer_moe/tokenizer/whisper_Lv3/modeling_whisper.py	/^    supports_gradient_checkpointing = True$/;"	v	class:WhisperPreTrainedModel
symbols	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/text/symbols.py	/^symbols = [_pad] + list(_punctuation) + list(_letters) + list(_letters_ipa)$/;"	v
sync	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/Makefile	/^sync: ## Merge changes from main branch to your current branch$/;"	t
synthesise	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/matcha_tts.py	/^    def synthesise(self, x, x_lengths, n_timesteps, temperature=1.0, spks=None, length_scale=1.0/;"	m	class:MatchaTTS
synthesise_mel	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/app.py	/^def synthesise_mel(text, text_length, n_timesteps, temperature, length_scale, spk):$/;"	f
t_to_alpha_sigma	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/sampling.py	/^def t_to_alpha_sigma(t):$/;"	f
ta	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/data/text_mel_datamodule.py	/^import torchaudio as ta$/;"	I	nameref:module:torchaudio
target_length	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/stable_diffusion.py	/^target_length = 1536$/;"	v
target_length	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/stable_diffusion_test.py	/^target_length = 1536$/;"	v
task_wrapper	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/utils/utils.py	/^def task_wrapper(task_func: Callable) -> Callable:$/;"	f	typeref:typename:Callable
teardown	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/data/text_mel_datamodule.py	/^    def teardown(self, stage: Optional[str] = None):$/;"	m	class:TextMelDataModule
temperature	steer_moe/tokenizer/glm4/web_demo.py	/^            temperature = gr.Number($/;"	v
tensorboard	configs/stage2.json	/^  "tensorboard": {$/;"	o
test	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/Makefile	/^test: ## Run not slow tests$/;"	t
test-full	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/Makefile	/^test-full: ## Run all tests$/;"	t
test_aligner_output_and_lb_loss	tests/test_aligner.py	/^def test_aligner_output_and_lb_loss():$/;"	f
text_input	steer_moe/tokenizer/glm4/web_demo.py	/^                text_input = gr.Textbox(label="Input text", placeholder="Enter your text here.../;"	v
text_normalize	steer_moe/tokenizer/glm4/cosyvoice/cli/frontend.py	/^    def text_normalize(self, text, split=True):$/;"	m	class:CosyVoiceFrontEnd
text_to_sequence	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/text/__init__.py	/^def text_to_sequence(text, cleaner_names):$/;"	f
text_to_token	steer_moe/tokenizer/glm4/cosyvoice/cli/model.py	/^    def text_to_token(self, text, text_len, flow_embedding, llm_embedding=torch.zeros(0, 192),$/;"	m	class:CosyVoiceModel
th_accuracy	steer_moe/tokenizer/glm4/cosyvoice/utils/common.py	/^def th_accuracy(pad_outputs: torch.Tensor, pad_targets: torch.Tensor,$/;"	f	typeref:typename:torch.Tensor
tie_or_clone_weights	steer_moe/tokenizer/glm4/cosyvoice/transformer/decoder.py	/^    def tie_or_clone_weights(self, jit_mode: bool = True):$/;"	m	class:BiTransformerDecoder
tie_or_clone_weights	steer_moe/tokenizer/glm4/cosyvoice/transformer/decoder.py	/^    def tie_or_clone_weights(self, jit_mode: bool = True):$/;"	m	class:TransformerDecoder
tmp_batch_df	whisper_train/pre_process_word_correct_data.py	/^        tmp_batch_df = pd.DataFrame(processed_batch)$/;"	v
tmp_dataset	whisper_train/pre_process_word_correct_data.py	/^        tmp_dataset = tmp_dataset.cast_column("audio", Audio(sampling_rate=16000))$/;"	v
tmp_file_path	whisper_train/generate_raw_parquet_multi_processing_word.py	/^        tmp_file_path = f"\/root\/autodl-nas\/ruitao\/data\/raw\/{batch_tag}\/"$/;"	v
to_numpy	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/utils/utils.py	/^def to_numpy(tensor):$/;"	f
to_waveform	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/cli.py	/^def to_waveform(mel, vocoder, denoiser=None):$/;"	f
token2wav	steer_moe/tokenizer/glm4/flow_inference.py	/^    def token2wav(self, token, uuid, prompt_token=torch.zeros(1, 0, dtype=torch.int32),$/;"	m	class:AudioDecoder
token_to_speech	steer_moe/tokenizer/glm4/cosyvoice/cli/model.py	/^    def token_to_speech(self, tts_speech_token, flow_embedding, llm_embedding=torch.zeros(0, 192/;"	m	class:CosyVoiceModel
tokenize	steer_moe/tokenizer/glm4/cosyvoice/dataset/processor.py	/^def tokenize(data, get_tokenizer, allowed_special, mode='train'):$/;"	f
tokenize	steer_moe/tokenizer/glm4_tokenizer.py	/^    def tokenize(self, speech=None, audio_path=None, sr=16000):$/;"	m	class:Glm4Tokenizer
tokenize_waveform	steer_moe/efficient_layer_wise_whisper.py	/^    def tokenize_waveform(self, audio, return_gating=False):$/;"	m	class:EfficientLayerWiseSteeringWhisperEncoder
tokenize_waveform	steer_moe/layer_wise_aligner.py	/^    def tokenize_waveform(self, audio, return_gating=False):$/;"	m	class:WhisperEncoderWithSteering
tokenize_waveform	steer_moe/layer_wise_whisper.py	/^    def tokenize_waveform(self, audio, return_gating=False):$/;"	m	class:LayerWiseSteeringWhisperEncoder
tokenize_waveform	steer_moe/tokenizer/whisper_Lv3/whisper.py	/^    def tokenize_waveform(self, audio, kimia_whisper_clip_silence=False):$/;"	m	class:WhisperEncoder
tokenizer	whisper_train/pre_process_word_correct_data.py	/^tokenizer = WhisperTokenizer.from_pretrained(pretrained_model_name_or_path=model_path["whisper_l/;"	v
top_modules	configs/stage2.json	/^    "top_modules": 1,$/;"	n	object:flops_profiler
top_modules	configs/stage3.json	/^    "top_modules": 1,$/;"	n	object:flops_profiler
top_p	steer_moe/tokenizer/glm4/web_demo.py	/^            top_p = gr.Number($/;"	v
total_num_steps	configs/stage3.json	/^      "total_num_steps": "auto",$/;"	s	object:scheduler.params
total_num_steps	configs/stage3_wo_offload.json	/^      "total_num_steps": "auto",$/;"	s	object:scheduler.params
tp	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^import typing as tp$/;"	I	nameref:module:typing
tp	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/dit.py	/^import typing as tp$/;"	I	nameref:module:typing
tp	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/dit_v2.py	/^import typing as tp$/;"	I	nameref:module:typing
tp	steer_moe/tokenizer/glm4/cosyvoice/hifigan/generator.py	/^import typing as tp$/;"	I	nameref:module:typing
train	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/train.py	/^def train(cfg: DictConfig) -> Tuple[Dict[str, Any], Dict[str, Any]]:$/;"	f	typeref:typename:Tuple[Dict[str,Any],Dict[str,Any]]
train	whisper_train/main_word_correct_clips.py	/^def train(parquet_dirs:list,save_dir,resume_from_checkpoint=None,resume_from_model=None,output_d/;"	f
train-ljspeech	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/Makefile	/^train-ljspeech: ## Train the model$/;"	t
train-ljspeech-min	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/Makefile	/^train-ljspeech-min: ## Train the model with minimum memory$/;"	t
train_batch_size	configs/stage3.json	/^  "train_batch_size": "auto",$/;"	s
train_batch_size	configs/stage3_wo_offload.json	/^  "train_batch_size": "auto",$/;"	s
train_dataloader	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/data/text_mel_datamodule.py	/^    def train_dataloader(self):$/;"	m	class:TextMelDataModule
train_files	whisper_train/pre_process_word_correct_data.py	/^    train_files = [file for file in train_files if file not in processed_batchs]$/;"	v
train_files	whisper_train/pre_process_word_correct_data.py	/^    train_files = os.listdir(ori_parquet_dir)$/;"	v
train_in_batch	whisper_train/main_word_correct_clips.py	/^def train_in_batch(output_dir='.\/model\/whisper_large_v2_full_checkpoint',model_name='whisper_l/;"	f
train_in_ddp	whisper_train/main_word_correct_clips.py	/^def train_in_ddp(output_dir='.\/model\/whisper_large_v2_full_checkpoint',model_name='whisper_lar/;"	f
train_layer_wise_steermoe	scripts/train_layer_wise.py	/^def train_layer_wise_steermoe(config_path: str = 'configs\/layer_wise.yaml',$/;"	f
train_lora	whisper_train/main_word_correct_clips.py	/^def train_lora():$/;"	f
train_lora_in_8bit	whisper_train/main_word_correct_clips.py	/^def train_lora_in_8bit():$/;"	f
train_micro_batch_size_per_gpu	configs/stage0.json	/^  "train_micro_batch_size_per_gpu": "auto",$/;"	s
train_micro_batch_size_per_gpu	configs/stage2.json	/^  "train_micro_batch_size_per_gpu": "auto",$/;"	s
train_micro_batch_size_per_gpu	configs/stage3.json	/^  "train_micro_batch_size_per_gpu": "auto",$/;"	s
train_micro_batch_size_per_gpu	configs/stage3_wo_offload.json	/^  "train_micro_batch_size_per_gpu": "auto",$/;"	s
train_one_epoc	steer_moe/tokenizer/glm4/cosyvoice/utils/executor.py	/^    def train_one_epoc(self, model, optimizer, scheduler, train_data_loader, cv_data_loader, wri/;"	m	class:Executor
train_with_deepspeed	scripts/train.py	/^def train_with_deepspeed(config_path='configs\/default.yaml', deepspeed_config_path='configs\/de/;"	f
training_step	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/baselightningmodule.py	/^    def training_step(self, batch: Any, batch_idx: int):$/;"	m	class:BaseLightningClass
transliteration_cleaners	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/text/cleaners.py	/^def transliteration_cleaners(text):$/;"	f
type	configs/stage3.json	/^    "type": "AdamW",$/;"	s	object:optimizer
type	configs/stage3.json	/^    "type": "WarmupDecayLR",$/;"	s	object:scheduler
type	configs/stage3_wo_offload.json	/^    "type": "AdamW",$/;"	s	object:optimizer
type	configs/stage3_wo_offload.json	/^    "type": "WarmupDecayLR",$/;"	s	object:scheduler
unbatched_synthesis	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/cli.py	/^def unbatched_synthesis(args, device, model, vocoder, denoiser, texts, spk):$/;"	f
unpad1d	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/adp.py	/^def unpad1d(x: torch.Tensor, paddings: tp.Tuple[int, int]):$/;"	f
update	steer_moe/tokenizer/glm4/cosyvoice/dataset/dataset.py	/^    def update(self):$/;"	m	class:DistributedSampler
update_data_statistics	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/baselightningmodule.py	/^    def update_data_statistics(self, data_statistics):$/;"	m	class:BaseLightningClass
update_input_interface	steer_moe/tokenizer/glm4/web_demo.py	/^    def update_input_interface(input_mode):$/;"	f
update_parameter_and_lr	steer_moe/tokenizer/glm4/cosyvoice/utils/train_utils.py	/^def update_parameter_and_lr(model, optimizer, scheduler, info_dict):$/;"	f
use_compile	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/blocks.py	/^use_compile = True$/;"	v
use_ttsfrd	steer_moe/tokenizer/glm4/cosyvoice/cli/frontend.py	/^    use_ttsfrd = False$/;"	v
use_ttsfrd	steer_moe/tokenizer/glm4/cosyvoice/cli/frontend.py	/^    use_ttsfrd = True$/;"	v
utils	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/components/text_encoder.py	/^import matcha.utils as utils$/;"	I	nameref:module:matcha.utils
v1	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/hifigan/config.py	/^v1 = {$/;"	v
val_dataloader	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/data/text_mel_datamodule.py	/^    def val_dataloader(self):$/;"	m	class:TextMelDataModule
validate_args	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/cli.py	/^def validate_args(args):$/;"	f
validate_args	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/onnx/infer.py	/^def validate_args(args):$/;"	f
validate_args_for_multispeaker_model	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/cli.py	/^def validate_args_for_multispeaker_model(args):$/;"	f
validate_args_for_single_speaker_model	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/cli.py	/^def validate_args_for_single_speaker_model(args):$/;"	f
validation_step	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/models/baselightningmodule.py	/^    def validation_step(self, batch: Any, batch_idx: int):$/;"	m	class:BaseLightningClass
vector_quantize	steer_moe/tokenizer/glm4/speech_tokenizer/modeling_whisper.py	/^def vector_quantize(inputs, codebook):$/;"	f
version	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/setup.py	/^    version = fin.read().strip()$/;"	v
vocoder	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/app.py	/^vocoder, denoiser = load_vocoder(args.vocoder, VOCODER_LOC(args.vocoder), device)$/;"	v
wall_clock_breakdown	configs/stage3.json	/^  "wall_clock_breakdown": false$/;"	b
wall_clock_breakdown	configs/stage3_wo_offload.json	/^  "wall_clock_breakdown": false$/;"	b
warmup_max_lr	configs/stage3.json	/^      "warmup_max_lr": "auto",$/;"	s	object:scheduler.params
warmup_max_lr	configs/stage3_wo_offload.json	/^      "warmup_max_lr": "auto",$/;"	s	object:scheduler.params
warmup_min_lr	configs/stage3.json	/^      "warmup_min_lr": "auto",$/;"	s	object:scheduler.params
warmup_min_lr	configs/stage3_wo_offload.json	/^      "warmup_min_lr": "auto",$/;"	s	object:scheduler.params
warmup_num_steps	configs/stage3.json	/^      "warmup_num_steps": "auto"$/;"	s	object:scheduler.params
warmup_num_steps	configs/stage3_wo_offload.json	/^      "warmup_num_steps": "auto"$/;"	s	object:scheduler.params
weight_decay	configs/stage3.json	/^      "weight_decay": "auto"$/;"	s	object:optimizer.params
weight_decay	configs/stage3_wo_offload.json	/^      "weight_decay": "auto"$/;"	s	object:optimizer.params
whisper_model	steer_moe/tokenizer/glm4/web_demo.py	/^    whisper_model, feature_extractor = None, None$/;"	v
worker	steer_moe/tokenizer/glm4/model_server.py	/^    worker = ModelWorker(args.model_path, args.dtype, args.device)$/;"	v
wrap	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/utils/utils.py	/^    def wrap(cfg: DictConfig) -> Tuple[Dict[str, Any], Dict[str, Any]]:$/;"	f	function:task_wrapper	typeref:typename:Tuple[Dict[str,Any],Dict[str,Any]]	file:
wrap_cuda_model	steer_moe/tokenizer/glm4/cosyvoice/utils/train_utils.py	/^def wrap_cuda_model(args, model):$/;"	f
write_mels	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/onnx/infer.py	/^def write_mels(model, inputs, output_dir):$/;"	f
write_wavs	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/matcha/onnx/infer.py	/^def write_wavs(model, inputs, output_dir, external_vocoder=None):$/;"	f
xm	whisper_train/main_word_correct_clips.py	/^    import torch_xla.core.xla_model as xm$/;"	I	nameref:module:torch_xla.core.xla_model
zero_allow_untested_optimizer	configs/stage2.json	/^  "zero_allow_untested_optimizer": true,$/;"	b
zero_init	steer_moe/tokenizer/glm4/cosyvoice/flow/stable/blocks.py	/^def zero_init(layer):$/;"	f
zero_optimization	configs/stage0.json	/^  "zero_optimization": {$/;"	o
zero_optimization	configs/stage2.json	/^  "zero_optimization": {$/;"	o
zero_optimization	configs/stage3.json	/^  "zero_optimization": {$/;"	o
zero_optimization	configs/stage3_wo_offload.json	/^  "zero_optimization": {$/;"	o
ÂçèËÆÆ	steer_moe/tokenizer/glm4/README.md	/^## ÂçèËÆÆ$/;"	s	chapter:GLM-4-Voice
ÂºïÁî®	steer_moe/tokenizer/glm4/README.md	/^## ÂºïÁî®$/;"	s	chapter:GLM-4-Voice
üçµ Matcha-TTS: A fast TTS architecture with conditional flow matching	steer_moe/tokenizer/glm4/third_party/Matcha-TTS/README.md	/^# üçµ Matcha-TTS: A fast TTS architecture with conditional flow matching$/;"	c
